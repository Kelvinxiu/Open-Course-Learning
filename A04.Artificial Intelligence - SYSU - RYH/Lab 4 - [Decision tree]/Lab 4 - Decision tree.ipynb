{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T20:29:57.232528Z",
     "start_time": "2017-11-13T20:29:56.865640Z"
    },
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import pdir as pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集\n",
    "\n",
    "本次数据分为 train.csv 和 test.csv。每个文件有10列，前9列为特征 （都为离散型），最后一列是标签（±1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:47:23.163805Z",
     "start_time": "2017-11-13T19:47:23.129781Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet(filePath):\n",
    "    ''' 数据集读取函数'''\n",
    "    data, label = [], []\n",
    "    # 读取数据集\n",
    "    with open(filePath) as f:\n",
    "        for line in f.readlines():\n",
    "            temp = line.strip().split(\",\")\n",
    "            data.append([float(i) for i in temp[:-1]])\n",
    "            if temp[-1] != '?':\n",
    "                temp[-1] = float(temp[-1])\n",
    "            label.append(temp[-1])\n",
    "    ##### 输出数据集相关信息 ##########\n",
    "    print(\"data dimension of dataset：\", len(data[0]))\n",
    "    print(\"number of sample in data :\", len(data))\n",
    "    print(\"label frequency:\", dict(Counter(label)))\n",
    "    ##### 输出数据集相关信息 ##########\n",
    "    return np.array(data), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:47:23.383962Z",
     "start_time": "2017-11-13T19:47:23.167809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension of dataset： 9\n",
      "number of sample in data : 787\n",
      "label frequency: {1.0: 323, -1.0: 464}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 23.,   1.,   2.,   2.,   1.,   1.,   2.,   0.,   0.],\n",
       "       [ 36.,   1.,   1.,   5.,   1.,   1.,   2.,   3.,   0.],\n",
       "       [ 33.,   1.,   3.,   3.,   1.,   1.,   2.,   3.,   0.],\n",
       "       [ 35.,   3.,   3.,   2.,   1.,   0.,   0.,   3.,   0.],\n",
       "       [ 25.,   1.,   2.,   4.,   1.,   1.,   2.,   2.,   0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet, trainSet_label = loadDataSet('.\\\\data\\\\train.csv')\n",
    "trainSet[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:47:23.490036Z",
     "start_time": "2017-11-13T19:47:23.389966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension of dataset： 9\n",
      "number of sample in data : 300\n",
      "label frequency: {'?': 300}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 32.,   3.,   3.,   3.,   0.,   1.,   0.,   3.,   0.],\n",
       "       [ 24.,   1.,   2.,   3.,   1.,   1.,   1.,   2.,   0.],\n",
       "       [ 32.,   3.,   3.,   2.,   1.,   0.,   0.,   2.,   0.],\n",
       "       [ 43.,   3.,   3.,   5.,   1.,   1.,   0.,   3.,   0.],\n",
       "       [ 46.,   3.,   3.,   1.,   0.,   1.,   0.,   3.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet, testSet_lable = loadDataSet('.\\\\data\\\\test.csv')\n",
    "testSet[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征选取\n",
    "\n",
    "## 信息增益和信息增益率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T21:29:20.255086Z",
     "start_time": "2017-11-13T21:29:20.205052Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcInfoGain_or_InfoGainRate(dataSet, label, calcInfoGainRate=False):\n",
    "    '''计算数据集每一列（特征）的信息增益或信息增益率'''\n",
    "    def calcEntropy(data):\n",
    "        '''计算单列数据的熵'''\n",
    "        probs_ = np.array(list(Counter(data).values()))/data.shape[0]\n",
    "        ans = -1*(probs_*np.log2(probs_)).sum()\n",
    "        return ans\n",
    "    #计算数据集的熵\n",
    "    dataSetEntropy = calcEntropy(label)\n",
    "    #得到数据集的 样本数 和 特征数\n",
    "    sampleNum, featureNum = dataSet.shape\n",
    "    infoGains = np.zeros(featureNum) #用于保存 信息增益的数组\n",
    "    #对于数据集的每一个特征\n",
    "    for featureId in range(featureNum):\n",
    "        #得到当前的 特征\n",
    "        curFeature = dataSet[:, featureId]\n",
    "        #得到每个取值的统计次数\n",
    "        counter = Counter(curFeature)\n",
    "        #得到所有可能的取值\n",
    "        values = list(counter.keys())\n",
    "        #得到所有可能取值的概率\n",
    "        probs = np.array(list(counter.values()))/sampleNum\n",
    "        entropys = np.zeros(len(values)) #用于保存熵的数组\n",
    "        #遍历每个可能的取值\n",
    "        for index, val in enumerate(values):\n",
    "            #得到 标签 中对应的 子数据集标签\n",
    "            subLabel = label[np.argwhere(curFeature==val)[:,0]]\n",
    "            #计算 子数据集标签 的 熵\n",
    "            entropys[index] = calcEntropy(subLabel)\n",
    "        #计算基于当前特征的 条件熵\n",
    "        condEntropy = (probs*entropys).sum()\n",
    "        #计算基于当前特征的 信息增益\n",
    "        infoGains[featureId] = dataSetEntropy - condEntropy\n",
    "        #若是计算 信息增益率，则要除以 当前特征的 熵 \n",
    "        if calcInfoGainRate:\n",
    "            denominator = calcEntropy(curFeature)\n",
    "            #当 当前特征的 熵 为0时，信息增益也为0，此处避免除零错误\n",
    "            if denominator != 0:\n",
    "                infoGains[featureId] /= calcEntropy(curFeature)\n",
    "    return infoGains\n",
    "\n",
    "def calcInfoGain(dataSet, label):\n",
    "    '''计算数据集每一列（特征）的信息增益'''\n",
    "    return calcInfoGain_or_InfoGainRate(dataSet, label, calcInfoGainRate=False)\n",
    "\n",
    "def calcInfoGainRate(dataSet, label):\n",
    "    '''计算数据集每一列（特征）的信息增益率'''\n",
    "    return calcInfoGain_or_InfoGainRate(dataSet, label, calcInfoGainRate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试信息增益计算结果的正确性\n",
    "\n",
    "使用训练集进行测试，与其他同学的结果进行对比后，可知如下结果是正确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:48:01.695692Z",
     "start_time": "2017-11-13T19:48:01.676678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个特征的计算值如下：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.08227668,  0.01368315,  0.0152763 ,  0.10408631,  0.00169982,\n",
       "        0.00107348,  0.00518738,  0.00597883,  0.00918736])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取特征的下标（从0开始）为： 3\n"
     ]
    }
   ],
   "source": [
    "ansA = calcInfoGain(trainSet, trainSet_label)\n",
    "print(\"每个特征的计算值如下：\")\n",
    "ansA\n",
    "print(\"选取特征的下标（从0开始）为：\", np.argmax(ansA) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试信息增益率计算结果的正确性\n",
    "\n",
    "使用训练集进行测试，与其他同学的结果进行对比后，可知如下结果是正确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T20:07:48.250336Z",
     "start_time": "2017-11-13T20:07:48.225320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个特征的计算值如下：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.01673974,  0.00701169,  0.00964848,  0.03349103,  0.00286384,\n",
       "        0.00129432,  0.00321961,  0.00328779,  0.01890093])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取特征的下标（从0开始）为： 3\n"
     ]
    }
   ],
   "source": [
    "ansB = calcInfoGainRate(trainSet, trainSet_label)\n",
    "print(\"每个特征的计算值如下：\")\n",
    "ansB\n",
    "print(\"选取特征的下标（从0开始）为：\", np.argmax(ansB) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基尼指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:47:24.075452Z",
     "start_time": "2017-11-13T19:47:24.001402Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcGiniIndex(dataSet, label):\n",
    "    '''计算数据集每一列（特征）的Gini指数'''\n",
    "    #得到数据集的 样本数 和 特征数\n",
    "    sampleNum, featureNum = dataSet.shape\n",
    "    giniIndexs = np.zeros(featureNum) #用于保存 信息增益的数组\n",
    "    #对于数据集的每一个特征\n",
    "    for featureId in range(featureNum):\n",
    "        #得到当前的 特征\n",
    "        curFeature = dataSet[:, featureId]\n",
    "        #得到每个取值的统计次数\n",
    "        counter = Counter(curFeature)\n",
    "        #得到所有可能的取值\n",
    "        values = list(counter.keys())\n",
    "        #得到所有可能取值的概率\n",
    "        probs = np.array(list(counter.values()))/sampleNum\n",
    "        subGiniIndexs = np.zeros(len(values)) #用于保存熵的数组\n",
    "        #遍历每个可能的取值\n",
    "        for index, val in enumerate(values):\n",
    "            #得到 标签 中对应的 子数据集\n",
    "            subLabel = label[np.argwhere(curFeature==val)[:,0]]\n",
    "            #计算 每个取值下 数据集的 gini指数\n",
    "            sub_values = np.array(list(Counter(subLabel).values()))\n",
    "            sub_probs = sub_values / subLabel.shape[0]\n",
    "            subGiniIndexs[index] = 1 - (sub_probs**2).sum()\n",
    "        #计算基于当前特征的 gini 指数\n",
    "        giniIndexs[featureId] = (probs*subGiniIndexs).sum()\n",
    "    return giniIndexs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试基尼指数计算结果的正确性\n",
    "\n",
    "使用训练集进行测试，与其他同学的结果进行对比后，可知如下结果是正确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:49:18.056035Z",
     "start_time": "2017-11-13T19:49:18.033019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个特征的计算值如下：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.43710387,  0.47500663,  0.47507976,  0.42602918,  0.48279887,\n",
       "        0.48323448,  0.4804874 ,  0.48007143,  0.47810829])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选取特征的下标（从0开始）为： 5\n"
     ]
    }
   ],
   "source": [
    "ansC = calcGiniIndex(trainSet, trainSet_label)\n",
    "print(\"每个特征的计算值如下：\")\n",
    "ansC\n",
    "print(\"选取特征的下标（从0开始）为：\", np.argmax(ansC) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选取类实现\n",
    "\n",
    "为了更方便地使用3种特征选取，这里实现特征选取类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T21:42:20.070803Z",
     "start_time": "2017-11-13T21:42:20.017764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class featureSelection:\n",
    "    '''特征选取类：根据不同特征选取方法选取最优划分特征'''\n",
    "    \n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "        \n",
    "    def getFeatureIndex(self, dataSet, label):\n",
    "        '''得到最优划分属性的下标（从0开始）'''\n",
    "        if self.method == 'ID3':\n",
    "            return np.argmax(calcInfoGain(dataSet, label))\n",
    "        elif self.method == 'C4.5':\n",
    "            return np.argmax(calcInfoGainRate(dataSet, label))\n",
    "        elif self.method == 'CART':\n",
    "            return np.argmin(calcGiniIndex(dataSet, label))\n",
    "        else:\n",
    "            print(\"ERROR: method not define!\")\n",
    "        \n",
    "##############测试程序###################\n",
    "ID3 = featureSelection('ID3')\n",
    "C45 = featureSelection('C4.5')\n",
    "CART = featureSelection('CART')\n",
    "\n",
    "a = ID3.getFeatureIndex(trainSet, trainSet_label)\n",
    "b = C45.getFeatureIndex(trainSet, trainSet_label)\n",
    "c = CART.getFeatureIndex(trainSet, trainSet_label)\n",
    "[a,b,c]\n",
    "##############测试程序###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树算法\n",
    "\n",
    "## 构建决策树的递归终止条件\n",
    "\n",
    "假设当前结点的数据集为D，特征集为A，递归终止条件及对应的处理如下：\n",
    "\n",
    "- 1.**D中的样本属于同一类别C，则将当前结点标记为C类叶结点**。\n",
    "    - 最简单的一种递归终止条件，很好理解。\n",
    "\n",
    "\n",
    "- 2.**A为空集，此时无法划分。将当前结点标记为叶结点，类别为D中出现最多的类**。\n",
    "    - 比如数据集为`[['a'],['a'],['a'],['b']]`，标签为`['yes','no','yes','no']`，则经过一次划分后，特征集就为空集了。因此便无法划分下去了。而对应分类为`'a'`的标签有`['yes','no','yes']`，因此便需选择出现最多的类为结果。\n",
    "\n",
    "\n",
    "- 3.**D中所有样本在A中所有特征上取值相同，此时无法划分。将当前结点标记为叶结点，类别为D中出现最多的类**。\n",
    "    -  比如数据集为`[['a', 'b'],['a', 'b'],['a', 'b']]`，标签为`['yes','no','yes']`。此时数据集的两个特征的各自的取值都是一样的，此时也无法划分，因此便需选择出现最多的类为结果。\n",
    "    \n",
    "   \n",
    "- 4.**D为空集，则将当前结点标记为叶结点，类别为父结点中出现最多的类**。\n",
    "    - 这种情况在本次报告暂时还没有出现过，因此在实现中忽略该条件。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树类实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T21:44:49.641436Z",
     "start_time": "2017-11-13T21:44:49.600407Z"
    }
   },
   "outputs": [],
   "source": [
    "class decisionTree:\n",
    "    '''决策树类实现'''\n",
    "    \n",
    "    def __init__(self, method):\n",
    "        self.featureSelectionMethod = featureSelection(method=method) #特征选取方法\n",
    "    \n",
    "    def __getBestSplitFeature(self, dataSet, label):\n",
    "        '''得到数据集的最优划分属性的下标'''\n",
    "        return self.featureSelectionMethod.getFeatureIndex(dataSet, label)\n",
    "    \n",
    "    def __getSubSet(self, dataSet, label, splitIndex, splitValue):\n",
    "        '''根据划分属性的某个取值来得到对应的子数据集和标签'''\n",
    "        #得到对应取值的样本下标\n",
    "        sampleIndex = np.argwhere(dataSet[:, splitIndex]==splitValue)[:, 0]\n",
    "        #得到在原数据集的基础上删除划分属性所在列对应的样本\n",
    "        subDataSet = np.delete(dataSet, splitIndex, axis=1)[sampleIndex]\n",
    "        #得到子标签\n",
    "        subLabel = label[sampleIndex]\n",
    "        return subDataSet, subLabel\n",
    "    \n",
    "    def __getMostCommonLabel(self, label):\n",
    "        '''得到标签中出现最多次的数据'''\n",
    "        return Counter(label).most_common(1)[0]\n",
    "    \n",
    "    def __buildTree(self, dataSet, label):\n",
    "        '''递归构建决策树'''\n",
    "        #递归终止条件1：若数据都属于一个类别，则返回该类别\n",
    "        if len(Counter(label)) == 1:\n",
    "            return label[0]\n",
    "        #递归终止条件2：若遍历完所有属性，则返回标签中出现次数最多的\n",
    "        if len(dataSet) == 0:\n",
    "            return self.__getMostCommonLabel(label)\n",
    "        #递归终止条件3：若所有样本在所有特征上取值相同，则返回标签中出现次数最多的\n",
    "        check = []\n",
    "        ## 遍历所有特征，得到每个特征的取值的次数\n",
    "        for featureIndex in range(dataSet.shape[1]):\n",
    "            check.append(len(Counter(dataSet[:, featureIndex])))\n",
    "        ## 若所有特征的取值都只有一个\n",
    "        if len(Counter(check)) == 1:\n",
    "            return self.__getMostCommonLabel(label)\n",
    "        \n",
    "        #得到划分属性下标\n",
    "        splitIndex = self.__getBestSplitFeature(dataSet, label)\n",
    "        #以划分属性的下标为结点构建一颗空树\n",
    "        tree = {splitIndex:{'tree':{}}} \n",
    "        #存储该结点对应的最可能出现的标签值（用于预测未知值）\n",
    "        tree[splitIndex]['defaultLabel'] = self.__getMostCommonLabel(label)\n",
    "        #遍历划分属性的所有可能取值\n",
    "        for val in set(dataSet[:, splitIndex]):\n",
    "            subDataSet, subLabel = self.__getSubSet(dataSet, label, splitIndex, val)\n",
    "            tree[splitIndex]['tree'][val] = self.__buildTree(subDataSet, subLabel)\n",
    "        return tree\n",
    "        \n",
    "    def buildTree(self, dataSet, label):\n",
    "        '''得到决策树'''\n",
    "        self.tree = self.__buildTree(dataSet, label)\n",
    "    \n",
    "    def __apply(self, tree, dataSet):\n",
    "        '''递归应用构建好的决策树对数据集进行分类'''\n",
    "        rootIndex = list(tree.keys())[0] #根结点下标\n",
    "        \n",
    "        \n",
    "    def apply(self, dataSet):\n",
    "        '''对数据集进行分类'''\n",
    "        ansLabel = np.zeros(dataSet.shape[0])\n",
    "        #遍历测试数据集的每一个样本\n",
    "        for index, sample in enumerate(dataSet):\n",
    "            ansLabel[index] = self.__apply(self.tree, sample)\n",
    "        return ansLabel\n",
    "        \n",
    "    def getTree(self):\n",
    "        '''返回训练好的以字典形式存储的决策树'''\n",
    "        return self.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T22:23:52.405898Z",
     "start_time": "2017-11-13T22:23:52.383865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [3, 5]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['1', '3no'], \n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[0,1,2],[8,2,2],[3,1,5],[0,2,4]])\n",
    "b = np.array(['1', '2','3no','4'])\n",
    "\n",
    "c,d=1,1\n",
    "e=np.argwhere(a[:,c]==d)[:,0]\n",
    "e\n",
    "\n",
    "np.delete(a,c,axis=1)[e]\n",
    "b[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "595px",
    "left": "0px",
    "right": "915.844px",
    "top": "107px",
    "width": "358px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
