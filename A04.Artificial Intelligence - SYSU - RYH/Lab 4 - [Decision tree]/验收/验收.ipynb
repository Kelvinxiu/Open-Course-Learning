{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T14:33:08.799471Z",
     "start_time": "2017-11-17T14:33:08.789528Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import pdir as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T15:32:55.780712Z",
     "start_time": "2017-11-17T15:32:55.037014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain [ 0.2473004  0.0133154  0.0784958  0.0784958]\n",
      "best one(index) 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.,  1., -1.,  1., -1.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'F0': {'defaultLabel': 1.0,\n",
       "  'tree': {1.0: {'F2': {'defaultLabel': -1.0, 'tree': {1.0: -1.0, 2.0: 1.0}}},\n",
       "   2.0: 1.0,\n",
       "   3.0: {'F3': {'defaultLabel': 1.0, 'tree': {1.0: 1.0, 2.0: -1.0}}}}}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadDataSet(filePath):\n",
    "    ''' 数据集读取函数'''\n",
    "    data, label = [], []\n",
    "    # 读取数据集\n",
    "    with open(filePath) as f:\n",
    "        for line in f.readlines():\n",
    "            temp = line.strip().split(\",\")\n",
    "            data.append([float(i) for i in temp[:-1]])\n",
    "            if temp[-1] != '?':\n",
    "                temp[-1] = float(temp[-1])\n",
    "            label.append(temp[-1])\n",
    "    ##### 输出数据集相关信息 ##########\n",
    "    print(\"data dimension of dataset：\", len(data[0]))\n",
    "    print(\"number of sample in data :\", len(data))\n",
    "    print(\"label frequency:\", dict(Counter(label)))\n",
    "    ##### 输出数据集相关信息 ##########\n",
    "    return np.array(data), np.array(label)\n",
    "\n",
    "def calcInfoGain_or_InfoGainRate(dataSet, label, calcInfoGainRate=False):\n",
    "    '''计算数据集每一列（特征）的信息增益或信息增益率'''\n",
    "    def calcEntropy(data):\n",
    "        '''计算单列数据的熵'''\n",
    "        probs_ = np.array(list(Counter(data).values()))/data.shape[0]\n",
    "        ans = -1*(probs_*np.log2(probs_)).sum()\n",
    "        return ans\n",
    "    #计算数据集的熵\n",
    "    dataSetEntropy = calcEntropy(label)\n",
    "    #得到数据集的 样本数 和 特征数\n",
    "    sampleNum, featureNum = dataSet.shape\n",
    "    infoGains = np.zeros(featureNum) #用于保存 信息增益的数组\n",
    "    #对于数据集的每一个特征\n",
    "    for featureId in range(featureNum):\n",
    "        #得到当前的 特征\n",
    "        curFeature = dataSet[:, featureId]\n",
    "        #得到每个取值的统计次数\n",
    "        counter = Counter(curFeature)\n",
    "        #得到所有可能的取值\n",
    "        values = list(counter.keys())\n",
    "        #得到所有可能取值的概率\n",
    "        probs = np.array(list(counter.values()))/sampleNum\n",
    "        entropys = np.zeros(len(values)) #用于保存熵的数组\n",
    "        #遍历每个可能的取值\n",
    "        for index, val in enumerate(values):\n",
    "            #得到 标签 中对应的 子数据集标签\n",
    "            subLabel = label[np.argwhere(curFeature==val)[:,0]]\n",
    "            #计算 子数据集标签 的 熵\n",
    "            entropys[index] = calcEntropy(subLabel)\n",
    "        #计算基于当前特征的 条件熵\n",
    "        condEntropy = (probs*entropys).sum()\n",
    "        #计算基于当前特征的 信息增益\n",
    "        infoGains[featureId] = dataSetEntropy - condEntropy\n",
    "        #若是计算 信息增益率，则要除以 当前特征的 熵 \n",
    "        if calcInfoGainRate:\n",
    "            denominator = calcEntropy(curFeature)\n",
    "            #当 当前特征的 熵 为0时，信息增益也为0，此处避免除零错误\n",
    "            if denominator != 0:\n",
    "                infoGains[featureId] /= calcEntropy(curFeature)\n",
    "    return infoGains\n",
    "\n",
    "def calcGiniIndex(dataSet, label):\n",
    "    '''计算数据集每一列（特征）的Gini指数'''\n",
    "    #得到数据集的 样本数 和 特征数\n",
    "    sampleNum, featureNum = dataSet.shape\n",
    "    giniIndexs = np.zeros(featureNum) #用于保存 信息增益的数组\n",
    "    #对于数据集的每一个特征\n",
    "    for featureId in range(featureNum):\n",
    "        #得到当前的 特征\n",
    "        curFeature = dataSet[:, featureId]\n",
    "        #得到每个取值的统计次数\n",
    "        counter = Counter(curFeature)\n",
    "        #得到所有可能的取值\n",
    "        values = list(counter.keys())\n",
    "        #得到所有可能取值的概率\n",
    "        probs = np.array(list(counter.values()))/sampleNum\n",
    "        subGiniIndexs = np.zeros(len(values)) #用于保存熵的数组\n",
    "        #遍历每个可能的取值\n",
    "        for index, val in enumerate(values):\n",
    "            #得到 标签 中对应的 子数据集\n",
    "            subLabel = label[np.argwhere(curFeature==val)[:,0]]\n",
    "            #计算 每个取值下 数据集的 gini指数\n",
    "            sub_values = np.array(list(Counter(subLabel).values()))\n",
    "            sub_probs = sub_values / subLabel.shape[0]\n",
    "            subGiniIndexs[index] = 1 - (sub_probs**2).sum()\n",
    "        #计算基于当前特征的 gini 指数\n",
    "        giniIndexs[featureId] = (probs*subGiniIndexs).sum()\n",
    "    return giniIndexs\n",
    "\n",
    "def calcInfoGain(dataSet, label):\n",
    "    '''计算数据集每一列（特征）的信息增益'''\n",
    "    return calcInfoGain_or_InfoGainRate(dataSet, label, calcInfoGainRate=False)\n",
    "\n",
    "def calcInfoGainRate(dataSet, label):\n",
    "    '''计算数据集每一列（特征）的信息增益率'''\n",
    "    return calcInfoGain_or_InfoGainRate(dataSet, label, calcInfoGainRate=True)\n",
    "\n",
    "\n",
    "class featureSelection:\n",
    "    '''特征选取类：根据不同特征选取方法选取最优划分特征'''\n",
    "    \n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "        self.flag = True #验收需要输出第一次判断特征的信息增益（给予ID3），因此用一个变量来标记是否已经进行输出\n",
    "        \n",
    "    def getFeatureIndex(self, dataSet, label):\n",
    "        '''得到最优划分属性的下标（从0开始）'''\n",
    "        if self.method == 'ID3':\n",
    "            temp = calcInfoGain(dataSet, label)\n",
    "            if self.flag:\n",
    "                print(\"info gain\", temp)\n",
    "                print(\"best one(index)\", np.argmax(temp))\n",
    "                self.flag=False\n",
    "            return np.argmax(calcInfoGain(dataSet, label))\n",
    "        elif self.method == 'C4.5':\n",
    "            return np.argmax(calcInfoGainRate(dataSet, label))\n",
    "        elif self.method == 'CART':\n",
    "            return np.argmin(calcGiniIndex(dataSet, label))\n",
    "        else:\n",
    "            print(\"ERROR: method not define!\")\n",
    "\n",
    "class decisionTree:\n",
    "    '''决策树类实现'''\n",
    "    \n",
    "    def __init__(self, method):\n",
    "        self.featureSelectionMethod = featureSelection(method=method) #特征选取方法\n",
    "    \n",
    "    def __getBestSplitFeature(self, dataSet, label):\n",
    "        '''得到数据集的最优划分属性的下标'''\n",
    "        return self.featureSelectionMethod.getFeatureIndex(dataSet, label)\n",
    "    \n",
    "    def __getSubSet(self, dataSet, label, splitIndex, splitValue):\n",
    "        '''根据划分属性的某个取值来得到对应的子数据集和标签'''\n",
    "        #得到对应取值的样本下标\n",
    "        sampleIndex = np.argwhere(dataSet[:, splitIndex]==splitValue)[:, 0]\n",
    "        #得到在原数据集的基础上删除划分属性所在列对应的样本\n",
    "        subDataSet = np.delete(dataSet, splitIndex, axis=1)[sampleIndex]\n",
    "        #得到子标签\n",
    "        subLabel = label[sampleIndex]\n",
    "        return subDataSet, subLabel\n",
    "    \n",
    "    def __getMostCommonLabel(self, label):\n",
    "        '''得到标签中出现最多次的数据'''\n",
    "        return Counter(label).most_common(1)[0][0]\n",
    "    \n",
    "    def __buildTree(self, dataSet, label, featuresName):\n",
    "        '''递归构建决策树'''\n",
    "        #递归终止条件1：若数据都属于一个类别，则返回该类别\n",
    "        if len(Counter(label)) == 1:\n",
    "            return label[0]\n",
    "        #递归终止条件2：若遍历完所有属性，则返回标签中出现次数最多的\n",
    "        if len(dataSet) == 0:\n",
    "            return self.__getMostCommonLabel(label)\n",
    "        #递归终止条件3：若所有样本在所有特征上取值相同，则返回标签中出现次数最多的\n",
    "        check = []\n",
    "        ## 遍历所有特征，得到每个特征的取值的次数\n",
    "        for featureIndex in range(dataSet.shape[1]):\n",
    "            check.append(len(Counter(dataSet[:, featureIndex])))\n",
    "        ## 若所有特征的取值都只有一个\n",
    "        if Counter(check).get(1,-1)==len(check):\n",
    "            return self.__getMostCommonLabel(label)\n",
    "        \n",
    "        #得到划分属性下标\n",
    "        splitIndex = self.__getBestSplitFeature(dataSet, label)\n",
    "        #得到划分属性\n",
    "        splitFeature = featuresName[splitIndex]\n",
    "        del(featuresName[splitIndex])\n",
    "        #以划分属性为结点构建一颗空树\n",
    "        tree = {splitFeature:{'tree':{}}} \n",
    "        #存储该结点对应的最可能出现的标签值（用于预测未知值）\n",
    "        tree[splitFeature]['defaultLabel'] = self.__getMostCommonLabel(label)\n",
    "        #遍历划分属性的所有可能取值\n",
    "        for val in set(dataSet[:, splitIndex]):\n",
    "            subDataSet, subLabel = self.__getSubSet(dataSet, label, splitIndex, val)\n",
    "            tree[splitFeature]['tree'][val] = self.__buildTree(subDataSet, subLabel, \n",
    "                                                             featuresName[:])\n",
    "        return tree\n",
    "        \n",
    "    def buildTree(self, dataSet, label, featuresName):\n",
    "        '''得到决策树'''\n",
    "        self.tree = self.__buildTree(dataSet, label, featuresName)\n",
    "    \n",
    "    def __apply(self, tree, sample, featuresName):\n",
    "        '''递归应用构建好的决策树对数据集进行分类'''\n",
    "        #得到根结点属性\n",
    "        rootFeature = list(tree.keys())[0] \n",
    "        #对应根结点的树\n",
    "        rootTree = tree[rootFeature]['tree']\n",
    "        #根据结点名称找到结点对应的下标\n",
    "        rootIndex = featuresName.index(rootFeature)\n",
    "        #遍历树的所有可能的分支\n",
    "        for val in rootTree.keys():\n",
    "            if sample[rootIndex] == val:\n",
    "                subTree = rootTree[val]\n",
    "                #若接下来是一棵树\n",
    "                if isinstance(subTree, dict):\n",
    "                    return self.__apply(subTree, sample, featuresName)\n",
    "                #若接下来是一个结点\n",
    "                else:\n",
    "                    return subTree\n",
    "        #若出现未知值，则返回默认的标签值\n",
    "        return tree[rootFeature]['defaultLabel']  \n",
    "            \n",
    "    def apply(self, dataSet, featuresName):\n",
    "        '''对数据集进行分类'''\n",
    "        ansLabel = np.zeros(dataSet.shape[0])\n",
    "        #遍历测试数据集的每一个样本\n",
    "        for index, sample in enumerate(dataSet):\n",
    "            ansLabel[index] = self.__apply(self.tree, sample, featuresName)\n",
    "        return ansLabel\n",
    "        \n",
    "    def getTree(self):\n",
    "        '''返回训练好的以字典形式存储的决策树'''\n",
    "        return self.tree         \n",
    "    \n",
    "    \n",
    "testTree = decisionTree('ID3')\n",
    "featuresName_ = ['F'+str(i) for i in list(range(trainSet.shape[1]))]\n",
    "testTree.buildTree(trainSet, trainSet_label, featuresName_[:])\n",
    "resLabel = testTree.apply(testSet, featuresName_[:])\n",
    "ansTree = testTree.getTree()\n",
    "resLabel\n",
    "ansTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T15:33:04.539086Z",
     "start_time": "2017-11-17T15:33:04.507086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info gain [ 0.2473004  0.0133154  0.0784958  0.0784958]\n",
      "best one(index) 0\n",
      "ID3: 100.000%\n"
     ]
    }
   ],
   "source": [
    "def runDecisionTree(trainSet_, trainSet_label_, validateSet_, validateSet_label_):\n",
    "    '''运行决策树函数'''\n",
    "    def run(method):\n",
    "        test = decisionTree(method)\n",
    "        featuresName_ = list(range(trainSet_.shape[1]))\n",
    "        test.buildTree(trainSet_, trainSet_label_, featuresName_[:])\n",
    "        ans = test.apply(validateSet_, featuresName_[:])\n",
    "        diff = np.argwhere(ans == validateSet_label_)\n",
    "        accur = 100*float(diff.shape[0]/validateSet_label_.shape[0])\n",
    "        print(method+\":\", \"%.3f%%\" % accur)\n",
    "        \n",
    "    for method_ in ['ID3']:\n",
    "        run(method_)\n",
    "        \n",
    "runDecisionTree(trainSet, trainSet_label, trainSet, trainSet_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T14:57:48.041249Z",
     "start_time": "2017-11-17T14:57:48.012228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension of dataset： 4\n",
      "number of sample in data : 15\n",
      "label frequency: {1.0: 9, -1.0: 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  2.,  1.],\n",
       "       [ 3.,  1.,  2.,  2.],\n",
       "       [ 1.,  3.,  1.,  1.],\n",
       "       [ 2.,  3.,  2.,  1.],\n",
       "       [ 3.,  2.,  2.,  1.],\n",
       "       [ 3.,  2.,  1.,  2.],\n",
       "       [ 1.,  2.,  2.,  2.],\n",
       "       [ 3.,  1.,  2.,  1.],\n",
       "       [ 1.,  3.,  1.,  2.],\n",
       "       [ 2.,  3.,  1.,  1.],\n",
       "       [ 1.,  2.,  1.,  1.],\n",
       "       [ 3.,  2.,  1.,  1.],\n",
       "       [ 3.,  1.,  2.,  2.],\n",
       "       [ 2.,  2.,  1.,  2.],\n",
       "       [ 2.,  1.,  2.,  2.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimension of dataset： 4\n",
      "number of sample in data : 6\n",
      "label frequency: {'?': 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  3.,  2.,  2.],\n",
       "       [ 2.,  1.,  2.,  2.],\n",
       "       [ 2.,  2.,  2.,  2.],\n",
       "       [ 1.,  1.,  1.,  1.],\n",
       "       [ 3.,  2.,  1.,  1.],\n",
       "       [ 1.,  3.,  1.,  1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet, trainSet_label = loadDataSet('.\\\\data\\\\YStrain3.csv')\n",
    "trainSet\n",
    "\n",
    "testSet, _ = loadDataSet('.\\\\data\\\\YStest3.csv')\n",
    "testSet"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
