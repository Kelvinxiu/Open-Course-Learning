{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验介绍\n",
    "\n",
    "首先介绍这次实验会用到的 **Semeval数据集**——网络公开的短文本情感信息数据集\n",
    "\n",
    "每一行即一篇文本，下面是其中的一条例子：\n",
    "\n",
    "```python\n",
    "1\tall:148 anger:22 disgust:2 fear:60 joy:0 sad:64 surprise:0\tmortar assault leav at least dead\n",
    "```\n",
    "\n",
    "每一行由下面的三项组成：\n",
    "\n",
    "- 文本编号，与下一项以tab键分隔\n",
    "\n",
    "- 总情感权值以及各情感权重，与下一项以tab键分隔\n",
    "\n",
    "- 文本内容，单词之间以空格分隔\n",
    "\n",
    "这次实验的任务为：\n",
    "\n",
    "- 1、将数据集“semeval”的数据表示成 One-hot 矩阵，TF矩阵，TF-IDF矩阵，并分别保存为“onehot.txt”，“TF.txt”，“TFIDF.txt”三个文件。\n",
    "\n",
    "- 2、将数据集的One-hot 矩阵表示成三元组矩阵，保存为“smatrix.txt”文件。\n",
    "\n",
    "- 3、实现稀疏矩阵加法运算。\n",
    "\n",
    "## 导入semeval数据集和包含所有不重复的词的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semeval文件总数： 1246\n",
      "不重复的词的总数： 2749\n"
     ]
    }
   ],
   "source": [
    "semeval = []\n",
    "allWords_semeval = []\n",
    "with open('semeval', 'r', encoding='utf-8') as f:\n",
    "    for i in f.readlines():\n",
    "        #得到每一行的文本数据并按照空格切分为单词\n",
    "        text = i.split('\\t')[2].split(' ')\n",
    "        #去除最后一个单词的换行符\n",
    "        text[-1] = text[-1].strip('\\n')  \n",
    "        semeval.append(text) \n",
    "        for word in text:\n",
    "            #若该词未出现过，则将其添加到allWords中\n",
    "            if word.lower() not in allWords_semeval: \n",
    "                #将词转换成小写来进行判断，以防出现A和a不分的情况\n",
    "                allWords_semeval.append(word.lower()) \n",
    "                \n",
    "print(\"semeval文件总数：\", len(semeval))\n",
    "print(\"不重复的词的总数：\", len(allWords_semeval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mortar', 'assault', 'leav', 'at', 'least', 'dead'],\n",
       " ['goal', 'delight', 'for', 'sheva'],\n",
       " ['nigeria', 'hostag', 'fear', 'dead', 'is', 'freed'],\n",
       " ['bomber', 'kill', 'shopper'],\n",
       " ['veget', 'not', 'fruit', 'slow', 'brain', 'declin'],\n",
       " ['pm', 'havana', 'deal', 'a', 'good', 'experi'],\n",
       " ['kate', 'is', 'marri', 'doherti'],\n",
       " ['nasa', 'revisit', 'life', 'on', 'mar', 'question'],\n",
       " ['happi', 'birthdai', 'ipod'],\n",
       " ['alonso', 'would', 'be', 'happi', 'to', 'retir', 'with', 'three', 'titl']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['mortar',\n",
       " 'assault',\n",
       " 'leav',\n",
       " 'at',\n",
       " 'least',\n",
       " 'dead',\n",
       " 'goal',\n",
       " 'delight',\n",
       " 'for',\n",
       " 'sheva']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semeval[0:10]\n",
    "allWords_semeval[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  实验原理\n",
    "\n",
    "为了更加形象地解释下面所介绍的概念，这里给出如下的一个测试数据集以供测试。\n",
    "\n",
    "```java\n",
    " 文本编号  |           词汇表            \n",
    " --------------------------------------\n",
    " 训练文本1 | 苹果 手机 好用 销售          \n",
    " 训练文本2 | 市民 买   手机 手机          \n",
    " 训练文本3 | 市民 觉得 苹果 手机 贵   好用\n",
    "```\n",
    "这次实验有如下的标准输出要求：**不重复词向量中的列对应的词汇是按照出现顺序构成的。**\n",
    "\n",
    "在这个例子中词汇的出现顺序则是：苹果、手机、好用、销售、市民、买、觉得、贵。\n",
    "\n",
    "## 导入测试数据集\n",
    "\n",
    "为了测试代码的正确性，这里也将测试数据集保存到一个list中，以供后续测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDataSet =[['苹果', '手机', '好用', '销售'],\n",
    "              ['市民', '买', '手机', '手机'],\n",
    "              ['市民', '觉得', '苹果', '手机', '贵', '好用']]\n",
    "allWords_test = ['苹果', '手机', '好用', '销售', '市民', '买', '觉得', '贵']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot 矩阵\n",
    "\n",
    "One-hot：使用一个向量表示一篇文章，向量的长度为词汇表的大小。1表示存在对应的单词，0表示不存在。\n",
    "\n",
    "对于上面的测试数据集，One-hot矩阵则为：\n",
    "\n",
    "```java\n",
    " 文本编号  |苹果 手机 好用 销售 市民 买  觉得 贵\n",
    " --------------------------------------------\n",
    " 训练文本1 | 1    1    1    1   0   0   0   0\n",
    " 训练文本2 | 0    1    0    0   1   1   0   0\n",
    " 训练文本3 | 1    1    1    0   1   0   1   1\n",
    "```\n",
    "\n",
    "### 代码实现及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 0, 0, 0, 0], [0, 1, 0, 0, 1, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getOneHot(dataSet, allWords):\n",
    "    '''得到输入数据集的one-hot矩阵'''\n",
    "    oneHot=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        oneHot.append([])\n",
    "        for word in allWords:\n",
    "            if word in doc:\n",
    "                oneHot[index].append(1)\n",
    "            else: \n",
    "                oneHot[index].append(0)\n",
    "    return oneHot\n",
    "oneHot_test = getOneHot(testDataSet, allWords_test)\n",
    "oneHot_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的输出可以看到，得到one-hot的函数实现无误，输出与预期一致。\n",
    "\n",
    "### 将semeval数据集表示成one-hot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def saveDataToFile(data, fileName):\n",
    "    '''保存数据到文件中'''\n",
    "    with open(fileName, 'w', encoding='utf-8') as f:\n",
    "        for i in data:\n",
    "            #直接将list类型的元素保存到文件比双重循环写文件更快\n",
    "            _ = f.write(str(i)+'\\n')\n",
    "    \n",
    "oneHot_semeval = getOneHot(semeval, allWords_semeval)\n",
    "saveDataToFile(oneHot_semeval, 'onehot.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TF矩阵\n",
    "\n",
    "在一份给定的文件里，**词频（term frequency，TF）**指的是某一个给定的**词语**在该文件中出现的**频率**（这个数字是**对词数(term count)的归一化**，以防止它偏向词数较多的文件，一个词语在词数较多的文件里可能会比词数较少的文件有更高的词数，而不管该词语重要与否）。对于在某一特定文件里的词语 $t_i$ 来说，它的词频可表示为：\n",
    "        $$ tf_{i,j} = \\frac{n_{i,j}}{\\sum_kn_{k,j}} $$\n",
    "其中分子$n_{i,j}$是词$t_i$在文档$d_j$出现的次数，分母$\\sum_kn_{k,j}$是文档$d_j$中所有词出现的次数。\n",
    "\n",
    "通过分析上面的式子，可以发现若词T在文档D中的词频（注意已经是对词数进行**归一化**的结果）越高，那么从某种程度上来讲，可以说词T在文档D中是比较重要的，但是这样的思路有一个bug，那就是这样计算下来，一些对文档来说重要性几乎为0的常用词（或在这个文档集合中经常出现的词）的TF值却很高。下面介绍的IDF矩阵就是为了解决这个问题而引入的。\n",
    "\n",
    "对于上面的测试数据集，TF矩阵则为：\n",
    "\n",
    "```java\n",
    " 文本编号  |苹果 手机 好用 销售 市民 买  觉得 贵\n",
    " --------------------------------------------\n",
    " 训练文本1 |1/4  1/4  1/4  1/4  0   0   0   0\n",
    " 训练文本2 | 0   1/2   0    0  1/4  1/4 0   0\n",
    " 训练文本3 |1/6  1/6  1/6   0  1/6  0   1/6 1/6\n",
    "```\n",
    "### 代码实现及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.25, 0.25, 0.25, 0.25, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0],\n",
       " [0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666,\n",
       "  0.0,\n",
       "  0.16666666666666666,\n",
       "  0.0,\n",
       "  0.16666666666666666,\n",
       "  0.16666666666666666]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    TF=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(doc)\n",
    "        for word in allWords:\n",
    "            TF[index].append(wordCounter.get(word,0)/len(doc))\n",
    "    return TF\n",
    "\n",
    "TF_test = getTF(testDataSet, allWords_test)\n",
    "TF_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的输出可以看到，得到TF的函数实现无误，输出与预期一致。\n",
    "\n",
    "### 将semeval数据集表示成TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_semeval = getTF(semeval, allWords_semeval)\n",
    "saveDataToFile(TF_semeval, 'tf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF矩阵\n",
    "\n",
    "对于词$t_i$，其**逆向文件频率(inverse document frequency，IDF) —— $idf_i$**为：总文件数目$|D|$除以包含该词语的文件的数目$|j:t_i\\in d_j|$得到的商取对数的结果，即：$$idf_i=log \\frac{|D|}{|j:t_i\\in d_j|}$$\n",
    "\n",
    "这里有一点需要注意：当词$t_i$不在文档$d_j$的时候，$|j:t_i\\in d_j|$为0，即上式除式的分母为0，因此为了避免被除数为0的异常情况，通常将上式的$|j:t_i\\in d_j|$修改为$1+|j:t_i\\in d_j|$，即：$$idf_i=log \\frac{|D|}{1+|j:t_i\\in d_j|}$$\n",
    "\n",
    "可以看到，若包含词T的文档数越少，那么词T的IDF值就越高。这就可以用来解决常用词（或在这个文档集合中经常出现的词）TF值高的问题了，因为包含这些词的文档数较多，因此它们对应的IDF值就越小，这样就可以解决TF值衡量词在文档中重要性的bug了。\n",
    "\n",
    "因此，我们可以将TF值和IDF值对应的相乘，得到一个较为客观的结果，也即是我们所说的TF-IDF矩阵：$$tfidf_{i,j}=tf_{i,j}*idf_i$$\n",
    "\n",
    "可以看到，若某一词语T在某个文档D中有较高的频率（TF值较大），同时该词语在整个文件集合中又有较低的文档频率（IDF值较大），那么对于两者相乘即可得到值较大的的TF-IDF值，从而该词语T可被认为是文件D中的较有代表新的词。因此，通过计算TF-IDF矩阵，我们可以过滤掉常见的词，而保留较重要的词，这是提取文档关键词的一个重要的方法之一。\n",
    "\n",
    "对于上面的测试数据集，IDF向量则为：\n",
    "\n",
    "```java\n",
    "     |   苹果     手机      好用      销售       市民       买      觉得      贵\n",
    " -------------------------------------------------------------------------------\n",
    " IDF |log(3/3) log(3/4)  log(3/3)  log(3/2)  log(3/3)  log(3/2) log(3/2) log(3/2)\n",
    "```\n",
    "TF-IDF矩阵则为：\n",
    "\n",
    "<img src=\"./images/3.jpg\" />\n",
    "\n",
    "### 代码实现及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " -0.4150374992788438,\n",
       " 0.0,\n",
       " 0.5849625007211562,\n",
       " 0.0,\n",
       " 0.5849625007211562,\n",
       " 0.5849625007211562,\n",
       " 0.5849625007211562]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "def getIDF(dataSet, allWords):\n",
    "    '''得到输入数据集的IDF矩阵'''\n",
    "    def calcIDF(num):\n",
    "        '''计算对应数据集的单词的IDF值'''\n",
    "        return log(len(dataSet)/(1+num),2)\n",
    "    \n",
    "    IDF=[]\n",
    "    for word in allWords:\n",
    "        cnt = 0\n",
    "        #计算词在每个文档出现的次数\n",
    "        for doc in dataSet: \n",
    "            if word in doc:\n",
    "                cnt += 1\n",
    "        IDF.append(calcIDF(cnt))\n",
    "    return IDF\n",
    "\n",
    "IDF_ans = [log(3/i,2) for i in [3,4,3,2,3,2,2,2]]\n",
    "IDF_test = getIDF(testDataSet, allWords_test)\n",
    "#用于判断结果是否正确，如果不正确则不会输出IDF_test\n",
    "assert IDF_ans == IDF_test \n",
    "IDF_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, -0.10375937481971095, 0.0, 0.14624062518028905, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, -0.2075187496394219, 0.0, 0.0, 0.0, 0.14624062518028905, 0.0, 0.0],\n",
       " [0.0,\n",
       "  -0.06917291654647396,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0974937501201927,\n",
       "  0.0974937501201927]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "def getTFIDF(TF, IDF):\n",
    "    '''得到输入数据集的TF-IDF矩阵'''\n",
    "    TF=np.array(TF)   #先将数据类型转换为numpy的array类型\n",
    "    IDF=np.array(IDF) #以便实现numpy广播运算\n",
    "    return (TF*IDF).tolist() #转换为list类型\n",
    "\n",
    "TFIDF_test = getTFIDF(TF_test, IDF_test)\n",
    "TFIDF_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的输出可以看到，得到IDF和TFIDF的函数实现无误，输出与预期一致。\n",
    "\n",
    "### 将semeval数据集表示成TF-IDF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_semeval = getTF(semeval, allWords_semeval)\n",
    "IDF_semeval = getIDF(semeval, allWords_semeval)\n",
    "TFIDF_semeval = getTFIDF(TF_semeval, IDF_semeval)\n",
    "saveDataToFile(TFIDF_semeval, 'ifidf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 稀疏矩阵转三元顺序表\n",
    "\n",
    "以One-hot矩阵为例，该矩阵中有着许多的零元素，在实际数据的存储时会浪费大量的空间，因此需要一种可以节省存储空间的方法来保存稀疏矩阵的数据，三元顺序表就是其中的一种方法。\n",
    "\n",
    "对于上面测试数据集的One-hot矩阵：\n",
    "\n",
    "```java\n",
    " 文本编号  |苹果 手机 好用 销售 市民 买  觉得 贵\n",
    " --------------------------------------------\n",
    " 训练文本1 | 1    1    1    1   0   0   0   0\n",
    " 训练文本2 | 0    1    0    0   1   1   0   0\n",
    " 训练文本3 | 1    1    1    0   1   0   1   1\n",
    "```\n",
    "\n",
    "其对应的三元顺序表为：\n",
    "\n",
    "<img src=\"./images/1.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3],\n",
       " [8],\n",
       " [13],\n",
       " [0, 0, 1],\n",
       " [0, 1, 1],\n",
       " [0, 2, 1],\n",
       " [0, 3, 1],\n",
       " [1, 1, 1],\n",
       " [1, 4, 1],\n",
       " [1, 5, 1],\n",
       " [2, 0, 1],\n",
       " [2, 1, 1],\n",
       " [2, 2, 1],\n",
       " [2, 4, 1],\n",
       " [2, 6, 1],\n",
       " [2, 7, 1]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparseMatrix2TripleTable(sMatrix):\n",
    "    '''将输入的稀疏矩阵转换为三元组'''\n",
    "    sMatrix = np.array(sMatrix) #转换为numpy的数组类型\n",
    "    tripleTable = [[0],[0],[0]]\n",
    "    tripleTable[0][0], tripleTable[1][0] = sMatrix.shape #得到行数、列数\n",
    "   \n",
    "    nonZeroIndex = np.nonzero(sMatrix) #得到矩阵非零元素的下标组成的tuple\n",
    "    \n",
    "    nonZeroNum = len(nonZeroIndex[0]) #记录非零个数\n",
    "    tripleTable[2][0] = nonZeroNum \n",
    "    \n",
    "    for i in range(nonZeroNum):\n",
    "        rowIndex = nonZeroIndex[0][i]\n",
    "        colIndex = nonZeroIndex[1][i]\n",
    "        val = sMatrix[rowIndex, colIndex]\n",
    "        tripleTable.append([rowIndex, colIndex, val])\n",
    "    return tripleTable\n",
    "        \n",
    "tripleTable_test = sparseMatrix2TripleTable(oneHot_test)\n",
    "tripleTable_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的输出可以看到，得到稀疏矩阵转三元顺序组的函数实现无误，输出与预期一致。\n",
    "\n",
    "### 将从semeval得到的one-hot矩阵转换为三元顺序组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tripleTable_semeval = sparseMatrix2TripleTable(oneHot_semeval)\n",
    "saveDataToFile(tripleTable_semeval, 'smatrix.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 稀疏矩阵加法运算实现\n",
    "\n",
    "在实际的应用中，可能会涉及到稀疏矩阵的加法运算（在矩阵的行和列相等的情况下），下面给出一个例子：\n",
    "\n",
    "<img src=\"./images/2.jpg\"/>\n",
    "\n",
    "### 代码实现及测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3],\n",
       " [7],\n",
       " [13],\n",
       " [0, 0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 5, 2],\n",
       " [0, 6, 1],\n",
       " [1, 0, 1],\n",
       " [1, 2, 1],\n",
       " [1, 3, 1],\n",
       " [1, 4, 1],\n",
       " [1, 6, 1],\n",
       " [2, 0, 2],\n",
       " [2, 1, 1],\n",
       " [2, 3, 1],\n",
       " [2, 5, 1]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def addSparseMatrix(triTable1, triTable2):\n",
    "    '''两个行和列数相等的稀疏矩阵（以三元顺序组表示）的加法'''\n",
    "    ans = triTable1\n",
    "    vistedList = [] #标记访问过的三元组的下标\n",
    "    \n",
    "    for i, val1 in enumerate(triTable1[3:]):\n",
    "        for j, val2 in enumerate(triTable2[3:]):\n",
    "            #若 j还没有被访问 且 两个矩阵在相同的位置上都有非零元素\n",
    "            if j not in vistedList and (val1[0], val1[1]) == (val2[0], val2[1]):\n",
    "                ans[i+3][-1] += val2[-1]\n",
    "                vistedList.append(j) #标记已访问\n",
    "    #得到未访问的三元组下标\n",
    "    unVistedList = [i for i in range(triTable2[2][0]) if i not in vistedList]\n",
    "    ans[2][0] += len(unVistedList)#更新结果的非零元素个数\n",
    "    #将第二个\n",
    "    for i in unVistedList:\n",
    "        ans.append(triTable2[i+3])\n",
    "    #将部分结果排好序后再返回\n",
    "    temp = ans[3:]\n",
    "    temp.sort(key = lambda x: (x[0],x[1]))\n",
    "    return ans[:3]+temp\n",
    "\n",
    "tripleTable_test1 = [[3], [7], [11],\n",
    "                    [0, 0, 1], [0, 1, 1], [0, 5, 1], [0, 6, 1], [1, 2, 1],\n",
    "                    [1, 3, 1], [1, 4, 1], [2, 0, 1], [2, 1, 1], [2, 3, 1],\n",
    "                    [2, 5, 1]]    \n",
    "tripleTable_test2 = [[3], [7], [5],\n",
    "                    [0, 1, 1], [0, 5, 1], [1, 0, 1], [1, 6, 1], [2, 0, 1]]\n",
    "\n",
    "addRes = addSparseMatrix(tripleTable_test1, tripleTable_test2)\n",
    "addRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#该段代码是平台配置代码，不用理解，可以pass\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "596px",
    "left": "0px",
    "right": "1058px",
    "top": "106px",
    "width": "214px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
