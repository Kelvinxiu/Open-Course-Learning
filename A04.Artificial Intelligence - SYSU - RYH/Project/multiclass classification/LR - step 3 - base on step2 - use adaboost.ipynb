{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:24:26.488892Z",
     "start_time": "2018-01-10T01:24:26.480890Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import pdir as pr\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "DF = pd.DataFrame\n",
    "arr = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:27:58.466121Z",
     "start_time": "2018-01-10T01:24:26.491895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43766, 1644), (18756, 1644), (8671, 1644))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((43766,), (18756,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = \"E:\\\\Code\\\\_largeData\\\\Github--Open-Course-Learning--A04\\\\Project\\\\multiclass classification\\\\data preprocessed\\\\tf-idf\"\n",
    "\n",
    "trainSet = np.loadtxt(dirPath + '\\\\train.csv', delimiter=\",\")\n",
    "validateSet = np.loadtxt(dirPath + '\\\\validate.csv', delimiter=\",\")\n",
    "testSet = np.loadtxt(dirPath + '\\\\test.csv', delimiter=\",\")\n",
    "\n",
    "\n",
    "trainSetLabel = np.loadtxt(dirPath + '\\\\train_label.csv', delimiter=\",\")\n",
    "validateSetLabel = np.loadtxt(dirPath + '\\\\validate_label.csv', delimiter=\",\")\n",
    "\n",
    "trainSet.shape, validateSet.shape, testSet.shape\n",
    "\n",
    "trainSetLabel.shape, validateSetLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:27:58.503147Z",
     "start_time": "2018-01-10T01:27:58.469126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 13606, 1.0: 18255, 2.0: 11905})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 5692, 1.0: 7802, 2.0: 5262})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(trainSetLabel)\n",
    "Counter(validateSetLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现OVO\n",
    "\n",
    "由于有OVO和OVA两种方式可选，但是在三元分类上，OVO的效果从理论上应比OVA的好，因此直接选择OVO。\n",
    "\n",
    "两者需要跑的子模型是一样的。\n",
    "\n",
    "为适应LR的模型输入，需要把不同类别的标签转换为0和1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:27:58.600803Z",
     "start_time": "2018-01-10T01:27:58.508151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0, 2: 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = {\"01\":{0:0, 1:1}, \"02\":{0:0, 2:1}, \"12\":{1:0, 2:1}}\n",
    "mp[\"01\"]\n",
    "mp[\"02\"]\n",
    "mp[\"12\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T09:39:02.864311Z",
     "start_time": "2018-01-08T09:39:02.747153Z"
    }
   },
   "source": [
    "01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:27:59.139733Z",
     "start_time": "2018-01-10T01:27:58.602801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31861, 1644), (31861,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 13606, 1.0: 18255})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_01 = np.logical_or(trainSetLabel == 0, trainSetLabel == 1)\n",
    "trainSet_01 = trainSet[idx_01]\n",
    "trainSetLabel_01 = trainSetLabel[idx_01]\n",
    "\n",
    "trainSet_01.shape, trainSetLabel_01.shape\n",
    "\n",
    "np.place(trainSetLabel_01, trainSetLabel_01==0, 0)\n",
    "np.place(trainSetLabel_01, trainSetLabel_01==1, 1)\n",
    "Counter(trainSetLabel_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:27:59.385928Z",
     "start_time": "2018-01-10T01:27:59.151748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25511, 1644), (25511,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 13606, 1.0: 11905})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_02 = np.logical_or(trainSetLabel == 0, trainSetLabel == 2)\n",
    "trainSet_02 = trainSet[idx_02]\n",
    "trainSetLabel_02 = trainSetLabel[idx_02]\n",
    "\n",
    "trainSet_02.shape, trainSetLabel_02.shape\n",
    "\n",
    "np.place(trainSetLabel_02, trainSetLabel_02==0, 0)\n",
    "np.place(trainSetLabel_02, trainSetLabel_02==2, 1)\n",
    "Counter(trainSetLabel_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:27:59.683166Z",
     "start_time": "2018-01-10T01:27:59.387928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30160, 1644), (30160,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 18255, 1.0: 11905})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_12 = np.logical_or(trainSetLabel == 1, trainSetLabel == 2)\n",
    "trainSet_12 = trainSet[idx_12]\n",
    "trainSetLabel_12 = trainSetLabel[idx_12]\n",
    "\n",
    "trainSet_12.shape, trainSetLabel_12.shape\n",
    "\n",
    "np.place(trainSetLabel_12, trainSetLabel_12==1, 0)\n",
    "np.place(trainSetLabel_12, trainSetLabel_12==2, 1)\n",
    "Counter(trainSetLabel_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算平均准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:28:04.278252Z",
     "start_time": "2018-01-10T01:28:04.267243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcAvg(predict, actual):\n",
    "    all_labels = list(set(actual))\n",
    "    tot = 0.0\n",
    "    for i in all_labels:\n",
    "        counter = Counter(predict[actual == i] == i)\n",
    "        hit_num, miss_num = counter[True], counter[False]\n",
    "        tot += hit_num / (hit_num + miss_num)\n",
    "    return tot/len(all_labels)\n",
    "\n",
    "calcAvg(arr([1,2,3]), arr([3,2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T01:28:05.463938Z",
     "start_time": "2018-01-10T01:28:05.456932Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_fig(testRange, avgs):\n",
    "    fig,ax = plt.subplots() \n",
    "    fig.set_size_inches(10, 4)\n",
    "    plt.plot(testRange, avgs, 'g')\n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('avg(%)')\n",
    "    plt.title(\"avg versus eta with Logistic Regression\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T08:57:17.075220Z",
     "start_time": "2018-01-10T08:57:16.840485Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    '''逻辑回归类实现'''\n",
    "    \n",
    "    def __addOne2Samples(self, dataSet):\n",
    "        '''给每一个样本前加一个常数1'''\n",
    "        ones = np.ones(len(dataSet))\n",
    "        return np.column_stack((ones, dataSet))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        '''sigmoid函数实现'''\n",
    "        return 1/(1+np.exp(-1*x))\n",
    "    \n",
    "    def fit(self, trainSet, label, eta=1e-3, maxRunTimes=100):\n",
    "        '''根据给定的训练集和标签训练PLA的参数 w '''\n",
    "        ######## adaboost相关 ###########\n",
    "        #初始化权重向量\n",
    "        self.u_adaboost = np.ones(trainSet.shape[0])# 注意还是不要 /trainSet.shape[0]\n",
    "        self.a_adaboost = [] #分类器的话语权\n",
    "        self.w_adaboost = [] #分类器对应的模型权重向量\n",
    "        self.train_adaboost = self.__addOne2Samples(trainSet)\n",
    "        self.label_adaboost = label.copy()\n",
    "        ######## adaboost相关 ###########\n",
    "        #设置默认的 w 全为1\n",
    "        self.w = np.mat(np.ones(trainSet.shape[1]+1)).reshape(-1,1)\n",
    "        #给训练集中每一个样本前加一个常数1，并转换为numpy矩阵\n",
    "        trainSet = np.mat(self.__addOne2Samples(trainSet))\n",
    "        #将标签转换为numpy矩阵，并将其设置为只有一列的数据的矩阵\n",
    "        label = np.mat(label).reshape(-1,1)\n",
    "        for i in tnrange(maxRunTimes, desc=\"fit\"):\n",
    "            eta_reduced = eta/(1+i)+1e-7\n",
    "            #根据矩阵运算得到整个数据集每个维度梯度\n",
    "            u_adaboost = np.mat(self.u_adaboost).reshape(-1,1)\n",
    "            gradient = trainSet.T*(np.multiply(u_adaboost, self.sigmoid(trainSet*self.w) - label))\n",
    "            #更新 w\n",
    "            self.w -= eta_reduced*gradient\n",
    "            ########################\n",
    "            #计算子模型在u下在验证集上的错误率e，以及对应的a\n",
    "            self.calc_train_error_and_update_u()\n",
    "            ########################\n",
    "        \n",
    "    def _apply(self, x):\n",
    "        '''利用训练好的 w 对输入的向量x进行分类'''\n",
    "        cnt = 0\n",
    "        for index, w in enumerate(self.w_adaboost):\n",
    "            w = arr(w)[:, 0] #转换为numpy向量，方便后续计算\n",
    "            cnt += self.a_adaboost[index] * self.sigmoid(np.dot(w, x))\n",
    "        return 1 if cnt >=0 else 0\n",
    "    \n",
    "    def apply(self, otherSet):\n",
    "        '''根据已训练出的 w 对其他数据集进行划分'''\n",
    "        otherSet = self.__addOne2Samples(otherSet)\n",
    "        outputLabel = np.zeros(otherSet.shape[0])\n",
    "        for index in tnrange(len(otherSet), desc=\"apply\"):\n",
    "            outputLabel[index] = self._apply(otherSet[index])\n",
    "        return outputLabel\n",
    "    \n",
    "    def apply2train_sample(self, x):\n",
    "        '''利用训练好的 w 对输入的向量x进行分类'''\n",
    "        w = np.array(self.w)[:,0] #转换为numpy向量，方便后续计算\n",
    "        return 1 if self.sigmoid(np.dot(w, x)) > 0.5 else 0        \n",
    "        \n",
    "    def calc_train_error_and_update_u(self):\n",
    "        '''计算当前w在训练集的误差并更新adaboost权重向量u'''\n",
    "        errorCnt = 0\n",
    "        wrongflag = []\n",
    "        rightflag = []\n",
    "        for index, sample in enumerate(self.train_adaboost):\n",
    "            if self.apply2train_sample(sample) != self.label_adaboost[index]:\n",
    "                errorCnt += 1\n",
    "                wrongflag.append(index)\n",
    "            else:\n",
    "                rightflag.append(index)\n",
    "        \n",
    "        e = errorCnt/self.train_adaboost.shape[0]\n",
    "        s = np.sqrt((1-e)/e)\n",
    "        a = np.log(s)\n",
    "\n",
    "        self.u_adaboost[wrongflag] *= s\n",
    "        self.u_adaboost[rightflag] /= s\n",
    "        \n",
    "        self.a_adaboost.append(a)\n",
    "        self.w_adaboost.append(self.w)\n",
    "          \n",
    "    def getW(self):\n",
    "        return np.array(self.w)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参\n",
    "\n",
    "暂调参数eta，暂定迭代次数为1000，不设置正则化项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T10:01:42.633123Z",
     "start_time": "2018-01-10T09:17:12.842300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestEta = 0.053\n",
    "bestRuntime = 550*4\n",
    "LR_01, LR_02, LR_12 = LogisticRegression(), LogisticRegression(), LogisticRegression()\n",
    "    \n",
    "LR_01.fit(trainSet_01, trainSetLabel_01, eta=bestEta, maxRunTimes=bestRuntime)\n",
    "LR_02.fit(trainSet_02, trainSetLabel_02, eta=bestEta, maxRunTimes=bestRuntime)\n",
    "LR_12.fit(trainSet_12, trainSetLabel_12, eta=bestEta, maxRunTimes=bestRuntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T10:18:07.326140Z",
     "start_time": "2018-01-10T10:01:42.640128Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Counter({0.0: 18756})\n",
      "Counter({0.0: 18756})\n",
      "Counter({2.0: 18756})\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]]\n",
      "Counter({0.0: 18756})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTestLabel(dataSet):   \n",
    "    ansLabel_01 = LR_01.apply(dataSet)\n",
    "#     np.place(ansLabel_01, ansLabel_01==0, 0)\n",
    "#     np.place(ansLabel_01, ansLabel_01==1, 1)\n",
    "    \n",
    "    ansLabel_02 = LR_02.apply(dataSet)\n",
    "    \n",
    "    np.place(ansLabel_02, ansLabel_02==0, 0)\n",
    "    np.place(ansLabel_02, ansLabel_02==1, 2)\n",
    "    \n",
    "    ansLabel_12 = LR_12.apply(dataSet)\n",
    "    np.place(ansLabel_12, ansLabel_12==0, 1)\n",
    "    np.place(ansLabel_12, ansLabel_12==1, 2)    \n",
    "    \n",
    "    print(Counter(ansLabel_01))\n",
    "    print(Counter(ansLabel_02))\n",
    "    print(Counter(ansLabel_12))\n",
    "    \n",
    "    labels = np.vstack([ansLabel_01, ansLabel_02, ansLabel_12])\n",
    "    print(labels)\n",
    "    ansLabel = np.zeros(labels.shape[1])\n",
    "    \n",
    "    for i in tnrange(labels.shape[1], leave=False):\n",
    "        t = Counter(labels[:, i]).most_common(2)\n",
    "        #print(t)\n",
    "        if t[0][1] == t[1][1]:\n",
    "            ansLabel[i] = 1 #默认选择MID\n",
    "        else:\n",
    "            ansLabel[i] =  t[0][0]\n",
    "    \n",
    "    print(Counter(ansLabel))\n",
    "    \n",
    "    return ansLabel\n",
    "\n",
    "calcAvg(getTestLabel(validateSet), validateSetLabel)\n",
    "\n",
    "#ansLabel = getTestLabel(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T23:43:29.946736Z",
     "start_time": "2018-01-08T23:43:29.805136Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ans = DF(ansLabel).replace(0, \"LOW\").replace(1, \"MID\").replace(2, \"HIG\")\n",
    "# ans.to_csv('.\\\\rank\\\\47_v1.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "0b57e4fbd33b45579a972d6bbd12ea3b": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "26ec88de259749039da4825a3b2d96bc": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "857f1a5f49d04dbd913024434b854c68": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "89cacec8b818452e92184e568762df7f": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "9088e5a25e72464eb65cc6bedbbf908a": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "aab9f4a83f7b4bdea1168990e49616f8": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "abb5f6531e54485c9803b4b4b7733111": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "c96d170111f14ce080c814103b4bbd40": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    },
    "cfddae105fa543b391fe9b40262f5d74": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "d97aa3fdffc84bc6a3f77f036e24e607": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
