{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:50:10.210506Z",
     "start_time": "2018-01-10T22:49:59.312796Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import pdir as pr\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "DF = pd.DataFrame\n",
    "arr = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:30.025620Z",
     "start_time": "2018-01-10T22:50:10.213507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43766, 1644), (18756, 1644), (8671, 1644))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((43766,), (18756,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = \"E:\\\\Code\\\\_largeData\\\\Github--Open-Course-Learning--A04\\\\Project\\\\multiclass classification\\\\data preprocessed\\\\tf-idf\"\n",
    "\n",
    "trainSet = np.loadtxt(dirPath + '\\\\train.csv', delimiter=\",\")\n",
    "validateSet = np.loadtxt(dirPath + '\\\\validate.csv', delimiter=\",\")\n",
    "testSet = np.loadtxt(dirPath + '\\\\test.csv', delimiter=\",\")\n",
    "\n",
    "\n",
    "trainSetLabel = np.loadtxt(dirPath + '\\\\train_label.csv', delimiter=\",\")\n",
    "validateSetLabel = np.loadtxt(dirPath + '\\\\validate_label.csv', delimiter=\",\")\n",
    "\n",
    "trainSet.shape, validateSet.shape, testSet.shape\n",
    "\n",
    "trainSetLabel.shape, validateSetLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:30.307843Z",
     "start_time": "2018-01-10T22:53:30.028623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 13606, 1.0: 18255, 2.0: 11905})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 5692, 1.0: 7802, 2.0: 5262})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(trainSetLabel)\n",
    "Counter(validateSetLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现OVO\n",
    "\n",
    "由于有OVO和OVA两种方式可选，但是在三元分类上，OVO的效果从理论上应比OVA的好，因此直接选择OVO。\n",
    "\n",
    "两者需要跑的子模型是一样的。\n",
    "\n",
    "为适应LR的模型输入，需要把不同类别的标签转换为0和1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:30.594015Z",
     "start_time": "2018-01-10T22:53:30.312845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0, 2: 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = {\"01\":{0:0, 1:1}, \"02\":{0:0, 2:1}, \"12\":{1:0, 2:1}}\n",
    "mp[\"01\"]\n",
    "mp[\"02\"]\n",
    "mp[\"12\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T09:39:02.864311Z",
     "start_time": "2018-01-08T09:39:02.747153Z"
    }
   },
   "source": [
    "01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:31.215513Z",
     "start_time": "2018-01-10T22:53:30.597998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31861, 1644), (31861,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 13606, 1.0: 18255})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_01 = np.logical_or(trainSetLabel == 0, trainSetLabel == 1)\n",
    "trainSet_01 = trainSet[idx_01]\n",
    "trainSetLabel_01 = trainSetLabel[idx_01]\n",
    "\n",
    "trainSet_01.shape, trainSetLabel_01.shape\n",
    "\n",
    "np.place(trainSetLabel_01, trainSetLabel_01==0, 0)\n",
    "np.place(trainSetLabel_01, trainSetLabel_01==1, 1)\n",
    "Counter(trainSetLabel_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:31.605671Z",
     "start_time": "2018-01-10T22:53:31.218515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25511, 1644), (25511,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 13606, 1.0: 11905})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_02 = np.logical_or(trainSetLabel == 0, trainSetLabel == 2)\n",
    "trainSet_02 = trainSet[idx_02]\n",
    "trainSetLabel_02 = trainSetLabel[idx_02]\n",
    "\n",
    "trainSet_02.shape, trainSetLabel_02.shape\n",
    "\n",
    "np.place(trainSetLabel_02, trainSetLabel_02==0, 0)\n",
    "np.place(trainSetLabel_02, trainSetLabel_02==2, 1)\n",
    "Counter(trainSetLabel_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:31.846416Z",
     "start_time": "2018-01-10T22:53:31.607669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30160, 1644), (30160,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 18255, 1.0: 11905})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_12 = np.logical_or(trainSetLabel == 1, trainSetLabel == 2)\n",
    "trainSet_12 = trainSet[idx_12]\n",
    "trainSetLabel_12 = trainSetLabel[idx_12]\n",
    "\n",
    "trainSet_12.shape, trainSetLabel_12.shape\n",
    "\n",
    "np.place(trainSetLabel_12, trainSetLabel_12==1, 0)\n",
    "np.place(trainSetLabel_12, trainSetLabel_12==2, 1)\n",
    "Counter(trainSetLabel_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算平均准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:31.904963Z",
     "start_time": "2018-01-10T22:53:31.848414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calcAvg(predict, actual):\n",
    "    all_labels = list(set(actual))\n",
    "    tot = 0.0\n",
    "    for i in all_labels:\n",
    "        counter = Counter(predict[actual == i] == i)\n",
    "        hit_num, miss_num = counter[True], counter[False]\n",
    "        tot += hit_num / (hit_num + miss_num)\n",
    "    return tot/len(all_labels)\n",
    "\n",
    "calcAvg(arr([1,2,3]), arr([3,2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T22:53:32.067093Z",
     "start_time": "2018-01-10T22:53:31.907965Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_fig(testRange, avgs):\n",
    "    fig,ax = plt.subplots() \n",
    "    fig.set_size_inches(10, 4)\n",
    "    plt.plot(testRange, avgs, 'g')\n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('avg(%)')\n",
    "    plt.title(\"avg versus eta with Logistic Regression\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T23:20:23.022864Z",
     "start_time": "2018-01-10T23:20:22.791154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    '''逻辑回归类实现'''\n",
    "    \n",
    "    def __addOne2Samples(self, dataSet):\n",
    "        '''给每一个样本前加一个常数1'''\n",
    "        ones = np.ones(len(dataSet))\n",
    "        return np.column_stack((ones, dataSet))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        '''sigmoid函数实现'''\n",
    "        return 1/(1+np.exp(-1*x))\n",
    "    \n",
    "    def fit(self, trainSet, label, eta=1e-3, maxRunTimes=100):\n",
    "        '''根据给定的训练集和标签训练PLA的参数 w '''\n",
    "        ######## adaboost相关 ###########\n",
    "        #初始化权重向量\n",
    "        self.u_adaboost = np.ones(trainSet.shape[0])# 注意还是不要 /trainSet.shape[0]\n",
    "        self.a_adaboost = [] #分类器的话语权\n",
    "        self.w_adaboost = [] #分类器对应的模型权重向量\n",
    "        self.train_adaboost = self.__addOne2Samples(trainSet)\n",
    "        self.label_adaboost = label.copy()\n",
    "        ######## adaboost相关 ###########\n",
    "        #设置默认的 w 全为1\n",
    "        self.w = np.mat(np.ones(trainSet.shape[1]+1)).reshape(-1,1)\n",
    "        #给训练集中每一个样本前加一个常数1，并转换为numpy矩阵\n",
    "        trainSet = np.mat(self.__addOne2Samples(trainSet))\n",
    "        #将标签转换为numpy矩阵，并将其设置为只有一列的数据的矩阵\n",
    "        label = np.mat(label).reshape(-1,1)\n",
    "        \n",
    "        step_adaboost = 10\n",
    "        for i in tnrange(step_adaboost, desc=\"fit-top\"):\n",
    "            for i in tnrange(maxRunTimes, desc=\"fit\", leave=False):\n",
    "                eta_reduced = eta/(1+i)+1e-7\n",
    "                #根据矩阵运算得到整个数据集每个维度梯度\n",
    "                u_adaboost = np.mat(self.u_adaboost).reshape(-1,1)\n",
    "                gradient = trainSet.T*(np.multiply(u_adaboost, self.sigmoid(trainSet*self.w) - label))\n",
    "                #更新 w\n",
    "                self.w -= eta_reduced*gradient\n",
    "            ########################\n",
    "            #计算子模型在u下在验证集上的错误率e，以及对应的a\n",
    "            self.calc_train_error_and_update_u()\n",
    "            ########################\n",
    "        print(\"\\n\\n-------------------\\n\\n\")\n",
    "        \n",
    "    def _apply(self, x):\n",
    "        '''利用训练好的 w 对输入的向量x进行分类'''\n",
    "        cnt = 0\n",
    "        for index, w in enumerate(self.w_adaboost):\n",
    "            predict = self.apply2single_sample(w, x)\n",
    "            if predict == 0:\n",
    "                predict = -1\n",
    "            cnt += self.a_adaboost[index] * predict\n",
    "        return 1 if cnt >=0 else 0\n",
    "    \n",
    "    def apply(self, otherSet):\n",
    "        '''根据已训练出的 w 对其他数据集进行划分'''\n",
    "        otherSet = self.__addOne2Samples(otherSet)\n",
    "        outputLabel = np.zeros(otherSet.shape[0])\n",
    "        for index in tnrange(len(otherSet), desc=\"apply\"):\n",
    "            outputLabel[index] = self._apply(otherSet[index])\n",
    "        return outputLabel\n",
    "    \n",
    "    def apply2single_sample(self, w_mat, x):\n",
    "        '''利用训练好的 w 对输入的向量x进行分类'''\n",
    "        w = np.array(w_mat)[:,0] #转换为numpy向量，方便后续计算\n",
    "        return 1 if self.sigmoid(np.dot(w, x)) > 0.5 else 0        \n",
    "        \n",
    "    def calc_train_error_and_update_u(self):\n",
    "        '''计算当前w在训练集的误差并更新adaboost权重向量u'''\n",
    "        errorCnt = 0\n",
    "        wrongflag = []\n",
    "        rightflag = []\n",
    "        for index, sample in enumerate(self.train_adaboost):\n",
    "            if self.apply2single_sample(self.w, sample) != self.label_adaboost[index]:\n",
    "                errorCnt += 1\n",
    "                wrongflag.append(index)\n",
    "            else:\n",
    "                rightflag.append(index)\n",
    "        \n",
    "        e = errorCnt/self.train_adaboost.shape[0]\n",
    "        s = np.sqrt((1-e)/e)\n",
    "        a = np.log(s)\n",
    "        print(e, s, a)\n",
    "        \n",
    "        self.u_adaboost[wrongflag] *= s\n",
    "        self.u_adaboost[rightflag] /= s\n",
    "        #self.normalize_u() 不对权重归一化\n",
    "        self.a_adaboost.append(a)\n",
    "        self.w_adaboost.append(self.w)\n",
    "    \n",
    "    def normalize_u(self):\n",
    "        '''归一化函数'''\n",
    "        u_max, u_min = self.u_adaboost.max(), self.u_adaboost.min()\n",
    "        if u_max == u_min:\n",
    "            self.u_adaboost = np.ones(len(self.u_adaboost))\n",
    "        else:\n",
    "            self.u_adaboost = (self.u_adaboost - u_min)/(u_max - u_min) * len(self.u_adaboost) \n",
    "    \n",
    "    def getW(self):\n",
    "        return np.array(self.w)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参\n",
    "\n",
    "暂调参数eta，暂定迭代次数为1000，不设置正则化项。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T23:42:19.239879Z",
     "start_time": "2018-01-10T23:20:31.930090Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22745676532437775 1.84294327264 0.611363898312\n",
      "0.21408618687423495 1.91598955636 0.65023422878\n",
      "0.30121465114089324 1.52311904748 0.420760237294\n",
      "0.4771978280656602 1.04669334385 0.045635998684\n",
      "0.5935155833150246 0.82757218847 -0.189258938714\n",
      "0.6605254072376887 0.716900485099 -0.332818241461\n",
      "0.6924766956467154 0.666402219832 -0.405861857055\n",
      "0.7072282728100185 0.643405487129 -0.440980135882\n",
      "0.7151062427419101 0.631184291274 -0.460157396843\n",
      "0.7188098301999309 0.625450671504 -0.469282814688\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "0.15130727921288856 2.3683469673 0.862192229641\n",
      "0.1288855787699424 2.59977305766 0.955424155703\n",
      "0.17925600721257498 2.13976952067 0.760698122611\n",
      "0.39841636940927444 1.22879495143 0.206033974868\n",
      "0.5747716671239858 0.860128664193 -0.150673291398\n",
      "0.6728862059503743 0.697234095479 -0.360634063091\n",
      "0.7315667751166164 0.60574682685 -0.501293157681\n",
      "0.7644937477950688 0.555027180415 -0.588738192714\n",
      "0.7819764023362471 0.528025537231 -0.638610630477\n",
      "0.7900121516208695 0.515561164634 -0.66249933148\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n",
      "0.2980437665782493 1.53466997289 0.428315356548\n",
      "0.2902519893899204 1.56373979828 0.447080258897\n",
      "0.3538793103448276 1.35122987241 0.301015194325\n",
      "0.4713859416445623 1.05896362214 0.0572907148858\n",
      "0.5404840848806366 0.922059238704 -0.0811458072687\n",
      "0.5842175066312998 0.843617958517 -0.170055542652\n",
      "0.6143567639257295 0.792287013152 -0.232831562472\n",
      "0.6321618037135278 0.762806326717 -0.270751111219\n",
      "0.6436671087533157 0.744041735633 -0.295658149442\n",
      "0.65 0.733799385705 -0.309519604203\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestEta = 0.053\n",
    "bestRuntime = 550\n",
    "LR_01, LR_02, LR_12 = LogisticRegression(), LogisticRegression(), LogisticRegression()\n",
    "    \n",
    "LR_01.fit(trainSet_01, trainSetLabel_01, eta=bestEta, maxRunTimes=bestRuntime)\n",
    "LR_02.fit(trainSet_02, trainSetLabel_02, eta=bestEta, maxRunTimes=bestRuntime)\n",
    "LR_12.fit(trainSet_12, trainSetLabel_12, eta=bestEta, maxRunTimes=bestRuntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T23:42:25.649785Z",
     "start_time": "2018-01-10T23:42:19.245884Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ansLabel_01 Counter({1.0: 11735, 0.0: 7021})\n",
      "ansLabel_02 Counter({2.0: 9626, 0.0: 9130})\n",
      "ansLabel_12 Counter({2.0: 18756})\n",
      "labels:\n",
      " [[ 1.  1.  0. ...,  0.  0.  1.]\n",
      " [ 2.  2.  0. ...,  0.  2.  0.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]]\n",
      "Counter({2.0: 9626, 0.0: 6049, 1.0: 3081})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.550428336508553"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTestLabel(dataSet):   \n",
    "    ansLabel_01 = LR_01.apply(dataSet)\n",
    "#     np.place(ansLabel_01, ansLabel_01==0, 0)\n",
    "#     np.place(ansLabel_01, ansLabel_01==1, 1)\n",
    "    \n",
    "    ansLabel_02 = LR_02.apply(dataSet)\n",
    "    \n",
    "    np.place(ansLabel_02, ansLabel_02==0, 0)\n",
    "    np.place(ansLabel_02, ansLabel_02==1, 2)\n",
    "    \n",
    "    ansLabel_12 = LR_12.apply(dataSet)\n",
    "    np.place(ansLabel_12, ansLabel_12==0, 1)\n",
    "    np.place(ansLabel_12, ansLabel_12==1, 2)    \n",
    "    \n",
    "    print(\"ansLabel_01\", Counter(ansLabel_01))\n",
    "    print(\"ansLabel_02\", Counter(ansLabel_02))\n",
    "    print(\"ansLabel_12\", Counter(ansLabel_12))\n",
    "    \n",
    "    labels = np.vstack([ansLabel_01, ansLabel_02, ansLabel_12])\n",
    "    print(\"labels:\\n\", labels)\n",
    "    ansLabel = np.zeros(labels.shape[1])\n",
    "    \n",
    "    for i in tnrange(labels.shape[1], leave=False):\n",
    "        t = Counter(labels[:, i]).most_common(2)\n",
    "        #print(t)\n",
    "        if t[0][1] == t[1][1]:\n",
    "            ansLabel[i] = 1 #默认选择MID\n",
    "        else:\n",
    "            ansLabel[i] =  t[0][0]\n",
    "    \n",
    "    print(Counter(ansLabel))\n",
    "    \n",
    "    return ansLabel\n",
    "\n",
    "calcAvg(getTestLabel(validateSet), validateSetLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T19:29:14.324022Z",
     "start_time": "2018-01-10T19:29:08.185072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ansLabel_01 Counter({1.0: 5463, 0.0: 3208})\n",
      "ansLabel_02 Counter({2.0: 4601, 0.0: 4070})\n",
      "ansLabel_12 Counter({2.0: 8671})\n",
      "labels:\n",
      " [[ 0.  1.  1. ...,  0.  1.  0.]\n",
      " [ 0.  0.  2. ...,  0.  2.  0.]\n",
      " [ 2.  2.  2. ...,  2.  2.  2.]]\n",
      "Counter({2.0: 4601, 0.0: 2716, 1.0: 1354})\n"
     ]
    }
   ],
   "source": [
    "ansLabel = getTestLabel(testSet)\n",
    "ans = DF(ansLabel).replace(0, \"LOW\").replace(1, \"MID\").replace(2, \"HIG\")\n",
    "ans.to_csv('.\\\\rank\\\\47_v1.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "1588bbb124fb413093c5fd1f333d786d": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "34f8fb1674914154a7a13c978e6b365d": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "3bc61791ed864f5cba626ff9c96c7da8": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "4b7b74011ae2415bb3c795937d9ac0bf": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "4d8863ddc48f48cd9def73611b8348e8": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "517570a2fdbf41fa9f53ce9dc58b00a1": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "d539f8c77cc3483e86977d220cae86ed": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "e5d845ecad494f6b889115e07a61eb24": {
     "views": [
      {
       "cell_index": 21
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
