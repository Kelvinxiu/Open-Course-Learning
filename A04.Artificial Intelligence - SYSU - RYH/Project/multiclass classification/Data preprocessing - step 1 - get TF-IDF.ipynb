{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:44:40.965965Z",
     "start_time": "2018-01-07T23:44:40.861879Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import pdir as pr\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "DF = pd.DataFrame\n",
    "arr = np.array\n",
    "\n",
    "import re\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:45:17.091102Z",
     "start_time": "2018-01-07T23:44:40.986484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62522, 8671)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadDataSet(filePath):\n",
    "    articles, labels = [], []\n",
    "    with open(filePath, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            part = line.split(\"\\t\")\n",
    "            #这里已经将标签转换为大写，数据转换成小写了\n",
    "            label, article = part[0].upper().strip(), part[2].lower().replace(\"<sssss>\", \" \").strip().split(\" \")\n",
    "            articles.append(article)\n",
    "            labels.append(label)\n",
    "    return articles, labels\n",
    "        \n",
    "\n",
    "train_articles, train_labels = loadDataSet(\".\\\\data\\\\MulLabelTrain.ss\")\n",
    "test_articles, test_labels = loadDataSet(\".\\\\data\\\\MulLabelTest.ss\")\n",
    "\n",
    "len(train_articles), len(test_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:45:17.107096Z",
     "start_time": "2018-01-07T23:45:17.094087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'went', 'on', 'a', 'sunday', 'around', '11am', 'we', 'got', 'seated', 'right', 'away', '.', '', '', 'the', 'menu', 'is', 'trying', 'to', 'be', 'like', 'a', 'new-american', 'style', 'type', 'of', 'menu', '.', '', '', 'i', 'ordered', 'chicken', 'and', 'waffles', 'and', 'the', 'bo', 'ordered', 'a', 'breakfast', 'burrito', '.', '', '', 'our', 'meals', 'took', 'around', '25', 'minutes', 'to', 'come', 'out', 'and', 'my', 'boyfriend', 'even', 'commented', 'saying', 'how', 'all', 'the', 'people', 'sitting', 'next', 'to', 'us', 'no', 'one', 'had', 'a', 'plate', 'in', 'front', 'of', 'them', '.', '', '', 'sunday', 'must', 'have', 'been', 'a', 'new', 'employee', 'training', 'day', 'because', 'there', 'was', 'so', 'many', 'kids', 'wandering', 'around', 'and', 'around', 'the', 'restaurant', 'with', 'no', 'real', 'task', 'at', 'hand', '.', '', '', 'the', 'coffee', '...', 'the', 'coffee', 'was', 'good', '.', '', '', 'then', ',', 'finally', 'our', 'food', 'came', 'out', '.', '', '', 'my', 'chicken', 'was', 'good', 'and', 'it', 'was', 'a', 'baked', 'chicken', 'breast', 'breaded', '.', '', '', 'my', 'waffle', 'was', 'half', 'a', 'waffle', '.', '', '', 'two', 'pieces', 'came', 'out', 'and', 'they', 'were', 'toasted', 'cajun', 'style', '-lrb-', 'like', 'a', 'brick', '-rrb-', 'i', 'think', 'they', 'were', 'seasoned', 'with', 'a', 'pepper', 'or', 'something', 'too', '?', '', '', 'my', 'scrambled', 'eggs', 'came', 'out', 'already', 'mixed', 'with', 'syrup', '.', '', '', 'boy', \"'s\", 'burrito', 'came', 'out', 'on', 'a', 'green', 'pita', 'wrap', 'tortilla', 'and', 'carne', 'mixed', 'with', 'eggs', 'and', 'some', 'avocado', 'on', 'the', 'side', '.', '', '', 'the', '``', 'carne', \"''\", 'or', 'meat', 'had', 'a', 'lot', 'of', 'fat', 'on', 'it', '.', '', '', 'breakfast', 'was', '$', '30', '.', '', '', 'i', 'wont', 'be', 'back', '.'] \n",
      "\n",
      " LOW\n"
     ]
    }
   ],
   "source": [
    "print(train_articles[0], \"\\n\\n\", train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:45:17.301588Z",
     "start_time": "2018-01-07T23:45:17.110098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'d\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'t\", \"'ve\", \"n't\", \"''\", '``', 'etc', 'got', 'go', 'get', 'also', 'would', 'could', 'through', 'all', 'ours', 'being', 'if', 'is', 'did', 's', 'hasn', 'only', 'against', 'each', 'how', 'nor', 'needn', 'for', 'until', 'them', 'yourself', 'ourselves', 'your', 'once', 'my', 'they', 'll', 'couldn', 'won', 're', 'him', 'had', 'me', 'further', 'such', 'too', 'are', 'our', 'can', 'where', 'same', 'am', 'why', 'the', 'yours', 'does', 'after', 'on', 'mightn', 'their', 'his', 'over', 'were', 'shouldn', 'about', 'very', 'aren', 'it', 'not', 'its', 'was', 'few', 'haven', 'because', 'theirs', 'down', 'from', 'd', 'you', 'which', 'than', 'do', 'an', 'been', 'off', 'who', 'now', 'what', 'below', 'while', 'both', 'more', 'this', 'himself', 'when', 'wouldn', 'he', 'just', 'a', 'don', 'up', 'shan', 'during', 'we', 'didn', 'or', 'o', 'y', 've', 'yourselves', 'in', 'own', 'again', 'here', 'have', 'to', 'between', 'that', 'at', 'ain', 'into', 'and', 'doesn', 'weren', 'of', 't', 'should', 'some', 'isn', 'out', 'myself', 'before', 'wasn', 'then', 'she', 'hers', 'these', 'herself', 'itself', 'themselves', 'any', 'those', 'with', 'will', 'no', 'her', 'as', 'most', 'i', 'm', 'there', 'whom', 'mustn', 'but', 'other', 'under', 'hadn', 'ma', 'by', 'having', 'so', 'has', 'doing', 'above', 'be']\n"
     ]
    }
   ],
   "source": [
    "stopwords = []\n",
    "with open(\".\\\\data\\\\stopwords-en.txt\", \"r\", encoding='utf-8') as f:\n",
    "    for i in f.readlines():\n",
    "        stopwords.append(i.lower().strip())\n",
    "        \n",
    "len(stopwords)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:45:23.959694Z",
     "start_time": "2018-01-07T23:45:17.303570Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_articles_backup = train_articles.copy()\n",
    "test_articles_backup = test_articles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:23.456415Z",
     "start_time": "2018-01-07T23:45:23.962694Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords_and_useless_words(articles):\n",
    "    \n",
    "    def is_useless(j):\n",
    "        if len(j) <= 1 and j != \"!\" and j != \"?\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    new_articles = []\n",
    "    \n",
    "    for article in articles:\n",
    "        new_articles.append([j  for j in article if j not in stopwords and not is_useless(j)])\n",
    "        \n",
    "    return new_articles\n",
    "\n",
    "train_articles = remove_stopwords_and_useless_words(train_articles_backup)\n",
    "test_articles = remove_stopwords_and_useless_words(test_articles_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:23.469382Z",
     "start_time": "2018-01-07T23:46:23.458372Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['went', 'sunday', 'around', '11am', 'seated', 'right', 'away', 'menu', 'trying', 'like', 'new-american', 'style', 'type', 'menu', 'ordered', 'chicken', 'waffles', 'bo', 'ordered', 'breakfast', 'burrito', 'meals', 'took', 'around', '25', 'minutes', 'come', 'boyfriend', 'even', 'commented', 'saying', 'people', 'sitting', 'next', 'us', 'one', 'plate', 'front', 'sunday', 'must', 'new', 'employee', 'training', 'day', 'many', 'kids', 'wandering', 'around', 'around', 'restaurant', 'real', 'task', 'hand', 'coffee', '...', 'coffee', 'good', 'finally', 'food', 'came', 'chicken', 'good', 'baked', 'chicken', 'breast', 'breaded', 'waffle', 'half', 'waffle', 'two', 'pieces', 'came', 'toasted', 'cajun', 'style', '-lrb-', 'like', 'brick', '-rrb-', 'think', 'seasoned', 'pepper', 'something', '?', 'scrambled', 'eggs', 'came', 'already', 'mixed', 'syrup', 'boy', 'burrito', 'came', 'green', 'pita', 'wrap', 'tortilla', 'carne', 'mixed', 'eggs', 'avocado', 'side', 'carne', 'meat', 'lot', 'fat', 'breakfast', '30', 'wont', 'back']\n",
      "['love', 'mojo', '!', 'evil', 'treat', 'flavors', 'yummy', '!', 'minor', 'downfall', 'mix-ins', 'sometimes', 'hard', 'reach', 'seen', 'girl', 'literally', 'put', 'whole', 'head', 'bar', 'grossed', 'idea', 'others', 'done', '...', 'aka', 'possible', 'human', 'debris', 'hair', 'yogurt', '!']\n"
     ]
    }
   ],
   "source": [
    "print(train_articles[0])\n",
    "print(test_articles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去除高频词和低频词得到所有词列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:24.194237Z",
     "start_time": "2018-01-07T23:46:23.559023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971274, 683802)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_train_mix = [j for i in train_articles for j in i]\n",
    "all_word_test_mix = [j for i in test_articles for j in i]\n",
    "\n",
    "len(all_word_train_mix), len(all_word_test_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:24.484304Z",
     "start_time": "2018-01-07T23:46:24.196744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5655076"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_mix = all_word_train_mix + all_word_test_mix\n",
    "len(all_word_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.145079Z",
     "start_time": "2018-01-07T23:46:24.489307Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>79097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>60518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-rrb-</td>\n",
       "      <td>57854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place</td>\n",
       "      <td>55116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-lrb-</td>\n",
       "      <td>52751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...</td>\n",
       "      <td>50579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>50410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>45040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>great</td>\n",
       "      <td>39185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>33928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "      <td>31716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "      <td>28683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>back</td>\n",
       "      <td>25222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service</td>\n",
       "      <td>23633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>?</td>\n",
       "      <td>21738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>love</td>\n",
       "      <td>19774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>little</td>\n",
       "      <td>19542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nice</td>\n",
       "      <td>18475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>well</td>\n",
       "      <td>18270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>menu</td>\n",
       "      <td>18262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>even</td>\n",
       "      <td>16936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pretty</td>\n",
       "      <td>16828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>try</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ordered</td>\n",
       "      <td>16662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bar</td>\n",
       "      <td>16221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chicken</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>always</td>\n",
       "      <td>15662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>us</td>\n",
       "      <td>15570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>much</td>\n",
       "      <td>15438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>order</td>\n",
       "      <td>14767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96565</th>\n",
       "      <td>world-famous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96566</th>\n",
       "      <td>delivery/take</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96567</th>\n",
       "      <td>disney-fied</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96568</th>\n",
       "      <td>salad-wiches</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96569</th>\n",
       "      <td>luxuriated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96570</th>\n",
       "      <td>45g</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96571</th>\n",
       "      <td>viticultural</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96572</th>\n",
       "      <td>time-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96573</th>\n",
       "      <td>unbaked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96574</th>\n",
       "      <td>husband/owner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96575</th>\n",
       "      <td>splender</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96576</th>\n",
       "      <td>probs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96577</th>\n",
       "      <td>creamier/silkier</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96578</th>\n",
       "      <td>slate-tiled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96579</th>\n",
       "      <td>postino/joe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96580</th>\n",
       "      <td>art-related</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96581</th>\n",
       "      <td>romney</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96582</th>\n",
       "      <td>http://www.somonews.com/article.cfm?articleid=242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96583</th>\n",
       "      <td>wine/sangria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96584</th>\n",
       "      <td>biscuits/gravy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96585</th>\n",
       "      <td>breakthroughs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96586</th>\n",
       "      <td>uum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96587</th>\n",
       "      <td>petcos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96588</th>\n",
       "      <td>cure/super</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96589</th>\n",
       "      <td>calizones</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96590</th>\n",
       "      <td>deluxe/zen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96591</th>\n",
       "      <td>partakes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96592</th>\n",
       "      <td>relish/compote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96593</th>\n",
       "      <td>in-ter-net</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96594</th>\n",
       "      <td>yaegaki</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96595 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   words  count\n",
       "0                                                      !  79097\n",
       "1                                                   good  60518\n",
       "2                                                  -rrb-  57854\n",
       "3                                                  place  55116\n",
       "4                                                  -lrb-  52751\n",
       "5                                                    ...  50579\n",
       "6                                                   food  50410\n",
       "7                                                   like  45040\n",
       "8                                                  great  39185\n",
       "9                                                    one  33928\n",
       "10                                                really  31716\n",
       "11                                                  time  28683\n",
       "12                                                  back  25222\n",
       "13                                               service  23633\n",
       "14                                                     ?  21738\n",
       "15                                                  love  19774\n",
       "16                                                little  19542\n",
       "17                                                  nice  18475\n",
       "18                                                  well  18270\n",
       "19                                                  menu  18262\n",
       "20                                                  even  16936\n",
       "21                                                pretty  16828\n",
       "22                                                   try  16798\n",
       "23                                               ordered  16662\n",
       "24                                                   bar  16221\n",
       "25                                               chicken  15716\n",
       "26                                                always  15662\n",
       "27                                                    us  15570\n",
       "28                                                  much  15438\n",
       "29                                                 order  14767\n",
       "...                                                  ...    ...\n",
       "96565                                       world-famous      1\n",
       "96566                                      delivery/take      1\n",
       "96567                                        disney-fied      1\n",
       "96568                                       salad-wiches      1\n",
       "96569                                         luxuriated      1\n",
       "96570                                                45g      1\n",
       "96571                                       viticultural      1\n",
       "96572                                            time-17      1\n",
       "96573                                            unbaked      1\n",
       "96574                                      husband/owner      1\n",
       "96575                                           splender      1\n",
       "96576                                              probs      1\n",
       "96577                                   creamier/silkier      1\n",
       "96578                                        slate-tiled      1\n",
       "96579                                        postino/joe      1\n",
       "96580                                        art-related      1\n",
       "96581                                             romney      1\n",
       "96582  http://www.somonews.com/article.cfm?articleid=242      1\n",
       "96583                                       wine/sangria      1\n",
       "96584                                     biscuits/gravy      1\n",
       "96585                                      breakthroughs      1\n",
       "96586                                                uum      1\n",
       "96587                                             petcos      1\n",
       "96588                                         cure/super      1\n",
       "96589                                          calizones      1\n",
       "96590                                         deluxe/zen      1\n",
       "96591                                           partakes      1\n",
       "96592                                     relish/compote      1\n",
       "96593                                         in-ter-net      1\n",
       "96594                                            yaegaki      1\n",
       "\n",
       "[96595 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCountDF(in_list):  \n",
    "    #根据Counter统计的词频初始化df\n",
    "    df = DF.from_dict(Counter(in_list), orient='index').reset_index()\n",
    "    #根据count值降序排序\n",
    "    df = df.rename(columns={'index':'words',\n",
    "                                  0:'count'}).sort_values([\"count\"],ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "all_word_mix_df = getCountDF(all_word_mix)\n",
    "all_word_mix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.460423Z",
     "start_time": "2018-01-07T23:46:26.147082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>79097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "      <td>60518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-rrb-</td>\n",
       "      <td>57854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place</td>\n",
       "      <td>55116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-lrb-</td>\n",
       "      <td>52751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...</td>\n",
       "      <td>50579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "      <td>50410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>45040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>great</td>\n",
       "      <td>39185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "      <td>33928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "      <td>31716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "      <td>28683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>back</td>\n",
       "      <td>25222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service</td>\n",
       "      <td>23633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>?</td>\n",
       "      <td>21738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>love</td>\n",
       "      <td>19774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>little</td>\n",
       "      <td>19542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nice</td>\n",
       "      <td>18475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>well</td>\n",
       "      <td>18270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>menu</td>\n",
       "      <td>18262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>even</td>\n",
       "      <td>16936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pretty</td>\n",
       "      <td>16828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>try</td>\n",
       "      <td>16798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ordered</td>\n",
       "      <td>16662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bar</td>\n",
       "      <td>16221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chicken</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>always</td>\n",
       "      <td>15662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>us</td>\n",
       "      <td>15570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>much</td>\n",
       "      <td>15438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>order</td>\n",
       "      <td>14767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>cabbage</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>stayed</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>relaxed</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>team</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>dj</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>stage</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>sampled</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>shell</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>sizes</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>accommodating</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>played</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>learned</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>spending</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>sharing</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>diners</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>peach</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>???</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>dropped</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>stood</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>buying</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>compare</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>culinary</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>management</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>pizzeria</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>steamed</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>wear</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>pictures</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>fault</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>fondue</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>shake</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              words  count\n",
       "0                 !  79097\n",
       "1              good  60518\n",
       "2             -rrb-  57854\n",
       "3             place  55116\n",
       "4             -lrb-  52751\n",
       "5               ...  50579\n",
       "6              food  50410\n",
       "7              like  45040\n",
       "8             great  39185\n",
       "9               one  33928\n",
       "10           really  31716\n",
       "11             time  28683\n",
       "12             back  25222\n",
       "13          service  23633\n",
       "14                ?  21738\n",
       "15             love  19774\n",
       "16           little  19542\n",
       "17             nice  18475\n",
       "18             well  18270\n",
       "19             menu  18262\n",
       "20             even  16936\n",
       "21           pretty  16828\n",
       "22              try  16798\n",
       "23          ordered  16662\n",
       "24              bar  16221\n",
       "25          chicken  15716\n",
       "26           always  15662\n",
       "27               us  15570\n",
       "28             much  15438\n",
       "29            order  14767\n",
       "...             ...    ...\n",
       "1635        cabbage    514\n",
       "1636         stayed    514\n",
       "1637        relaxed    513\n",
       "1638           team    513\n",
       "1639             dj    513\n",
       "1640          stage    513\n",
       "1641        sampled    511\n",
       "1642          shell    511\n",
       "1643          sizes    511\n",
       "1644  accommodating    511\n",
       "1645         played    510\n",
       "1646        learned    509\n",
       "1647       spending    509\n",
       "1648        sharing    507\n",
       "1649         diners    506\n",
       "1650          peach    506\n",
       "1651            ???    506\n",
       "1652        dropped    505\n",
       "1653          stood    504\n",
       "1654         buying    504\n",
       "1655        compare    504\n",
       "1656       culinary    504\n",
       "1657     management    503\n",
       "1658       pizzeria    503\n",
       "1659        steamed    502\n",
       "1660           wear    502\n",
       "1661       pictures    502\n",
       "1662          fault    502\n",
       "1663         fondue    501\n",
       "1664          shake    501\n",
       "\n",
       "[1665 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low = 500\n",
    "df2 = all_word_mix_df[low < all_word_mix_df['count']].reset_index(drop=True) \n",
    "df2.shape\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.549120Z",
     "start_time": "2018-01-07T23:46:26.463407Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-rrb-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-lrb-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      words\n",
       "0         !\n",
       "1      good\n",
       "2     -rrb-\n",
       "3     place\n",
       "4     -lrb-\n",
       "5       ...\n",
       "6      food\n",
       "7      like\n",
       "8     great\n",
       "9       one\n",
       "10   really\n",
       "11     time\n",
       "12     back\n",
       "13  service\n",
       "14        ?\n",
       "15     love\n",
       "16   little\n",
       "17     nice\n",
       "18     well\n",
       "19     menu"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.drop([\"count\"], axis=1)\n",
    "df3.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除数字以及其他无用词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.633905Z",
     "start_time": "2018-01-07T23:46:26.552120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1665,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1644,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"words\"].shape\n",
    "df4 = df3[\"words\"].apply(lambda x: re.sub(\"[0-9||\\.||\\?||!]*\", \"\", x))\n",
    "df4 = df4[df4 != \"\"]\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.699438Z",
     "start_time": "2018-01-07T23:46:26.635889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', '-rrb-', 'place', ..., 'fault', 'fondue', 'shake'], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_unique = df4.values\n",
    "all_word_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试-1\n",
    "\n",
    "检查训练集和测试集的词的不重复数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.766140Z",
     "start_time": "2018-01-07T23:46:26.702440Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_word_train = set(all_word_train_mix)\n",
    "# all_word_test = set(all_word_test_mix)\n",
    "\n",
    "# len(all_word_train), len(all_word_test), (len(all_word_train) - len(all_word_test))\n",
    "\n",
    "# diff1 = all_word_train.difference(all_word_test)\n",
    "# diff2 = all_word_test.difference(all_word_train)\n",
    "\n",
    "# print(\"number of words in train but not in test: \", len(diff1))\n",
    "# print(\"number of words in test but not in train: \", len(diff2))\n",
    "\n",
    "# all_word = all_word_train.union(all_word_test)\n",
    "# len(all_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试-2\n",
    "检查词频分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:46:26.860756Z",
     "start_time": "2018-01-07T23:46:26.769142Z"
    }
   },
   "outputs": [],
   "source": [
    "# def show_common_word_rate(lst, k):\n",
    "#     word_counter = Counter(lst)\n",
    "#     cnt = 0\n",
    "#     tot_cnt = len(lst)\n",
    "#     common_pair = word_counter.most_common(k)\n",
    "#     for key, val in common_pair:\n",
    "#         cnt += val\n",
    "#     print(\"max frequent word and count: \", common_pair[0])\n",
    "#     print(\"min frequent word and count: \", common_pair[-1])\n",
    "#     print(\"frequent word count: \", cnt)\n",
    "#     print(\"total word count: \", tot_cnt)\n",
    "#     print(\"remain word count: \", tot_cnt-cnt)\n",
    "#     print(\"rate:%.5f%%\" % (cnt/tot_cnt*100))\n",
    "\n",
    "# #测试\n",
    "# #show_common_word_rate([1,2,3,4,2,2], 2)\n",
    "# show_common_word_rate(all_word_mix, 500)\n",
    "# show_common_word_rate(all_word_mix, 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 得到TF-IDF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:48:15.825034Z",
     "start_time": "2018-01-07T23:46:26.863748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((62522, 1644), (8671, 1644))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    def safeDivide(a, b):\n",
    "        return a/b if b!=0 else 0\n",
    "    \n",
    "    TF=[]\n",
    "    for index in tnrange(len(dataSet)):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(dataSet[index])\n",
    "        for word in allWords:\n",
    "            TF[index].append(safeDivide(wordCounter.get(word,0), len(dataSet[index])))\n",
    "    return arr(TF)\n",
    "\n",
    "train_TF = getTF(train_articles, all_word_unique)\n",
    "test_TF = getTF(test_articles, all_word_unique)\n",
    "\n",
    "train_TF.shape, test_TF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T00:48:58.390542Z",
     "start_time": "2018-01-08T00:44:01.709269Z"
    }
   },
   "outputs": [],
   "source": [
    "dirPath = \"E:\\\\Code\\\\_largeData\\\\Github--Open-Course-Learning--A04\\\\Project\\\\multiclass classification\\\\data preprocessed\\\\tf-idf\"\n",
    "if not os.path.exists(dirPath):\n",
    "    os.makedirs(dirPath)\n",
    "\n",
    "    \n",
    "train_tf_DF = DF(train_TF)\n",
    "train_tf_DF.columns = all_word_unique\n",
    "\n",
    "test_tf_DF = DF(test_TF)\n",
    "test_tf_DF.columns = all_word_unique\n",
    "\n",
    "train_tf_DF.to_csv(dirPath + '\\\\train_tf.csv', index=False, header=True)\n",
    "test_tf_DF.to_csv(dirPath + '\\\\test_tf.csv', index=False, header=True)\n",
    "\n",
    "DF(all_word_unique).to_csv(dirPath + '\\\\all_word_unique.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要注意，有一些样本去掉停用词后整个都没有数据了，这时候就默认TF那一列都为0了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:53:01.452733Z",
     "start_time": "2018-01-07T23:53:01.443727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tried',\n",
       " 'place',\n",
       " 'twice',\n",
       " 'different',\n",
       " 'different',\n",
       " 'place',\n",
       " 'much',\n",
       " 'else',\n",
       " 'going']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_articles[5773]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:58:33.253921Z",
     "start_time": "2018-01-07T23:53:01.456736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1644,), (1644,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def getIDF(dataSet, allWords):\n",
    "    '''得到输入数据集的IDF矩阵'''\n",
    "    def calcIDF(num):\n",
    "        '''计算对应数据集的单词的IDF值'''\n",
    "        return math.log(len(dataSet)/(1+num), 2)\n",
    "    \n",
    "    IDF=[]\n",
    "    for i in tnrange(len(allWords)):\n",
    "        cnt = 0\n",
    "        #计算词在每个文档出现的次数\n",
    "        for doc in dataSet: \n",
    "            if allWords[i] in doc:\n",
    "                cnt += 1\n",
    "        IDF.append(calcIDF(cnt))\n",
    "    return arr(IDF)\n",
    "\n",
    "train_IDF = getIDF(train_articles, all_word_unique)\n",
    "test_IDF = getIDF(test_articles, all_word_unique)\n",
    "\n",
    "train_IDF.shape, test_IDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:58:33.871443Z",
     "start_time": "2018-01-07T23:58:33.256938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62522, 1644), (8671, 1644))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TFIDF = train_TF * train_IDF\n",
    "test_TFIDF = test_TF * test_IDF\n",
    "\n",
    "train_TFIDF.shape, test_TFIDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:58:33.922979Z",
     "start_time": "2018-01-07T23:58:33.874447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43766, 1644), (18756, 1644))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分比例\n",
    "splitRate = 0.3\n",
    "#划分的数目\n",
    "splitNum = int(train_TFIDF.shape[0]*splitRate) \n",
    "#得到 训练集 和验证集\n",
    "trainSet = train_TFIDF[:-splitNum]\n",
    "validateSet = train_TFIDF[-splitNum:]\n",
    "\n",
    "trainSet.shape, validateSet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:58:34.287825Z",
     "start_time": "2018-01-07T23:58:33.925486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43766,), (18756,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = arr(train_labels)\n",
    "test_labels = arr(test_labels)\n",
    "\n",
    "trainSetLabel = train_labels[:-splitNum]\n",
    "validateSetLabel = train_labels[-splitNum:]\n",
    "\n",
    "trainSetLabel.shape, validateSetLabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T23:58:34.459701Z",
     "start_time": "2018-01-07T23:58:34.289820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0   0\n",
       "1   2\n",
       "2   0\n",
       "3   2\n",
       "4   0\n",
       "5   0\n",
       "6   1\n",
       "7   1\n",
       "8   0\n",
       "9   0\n",
       "10  1\n",
       "11  0\n",
       "12  1\n",
       "13  0\n",
       "14  0\n",
       "15  2\n",
       "16  0\n",
       "17  1\n",
       "18  0\n",
       "19  0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF(trainSetLabel[0:20]).replace(\"LOW\",0).replace(\"MID\",1).replace(\"HIG\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T00:30:34.760194Z",
     "start_time": "2018-01-08T00:25:35.183400Z"
    }
   },
   "outputs": [],
   "source": [
    "DF(trainSet).to_csv(dirPath + '\\\\train.csv', index=False, header=False)\n",
    "DF(validateSet).to_csv(dirPath + '\\\\validate.csv', index=False, header=False)\n",
    "DF(test_TFIDF).to_csv(dirPath + '\\\\test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出标签映射为数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T00:30:34.997358Z",
     "start_time": "2018-01-08T00:30:34.762690Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainSetLabel = DF(trainSetLabel).replace(\"LOW\",0).replace(\"MID\",1).replace(\"HIG\",2)\n",
    "validateSetLabel = DF(validateSetLabel).replace(\"LOW\",0).replace(\"MID\",1).replace(\"HIG\",2)\n",
    "\n",
    "DF(trainSetLabel).to_csv(dirPath + '\\\\train_label.csv', index=False, header=False)\n",
    "DF(validateSetLabel).to_csv(dirPath + '\\\\validate_label.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "788px",
    "left": "0px",
    "right": "1175px",
    "top": "107px",
    "width": "299px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "state": {
    "09353b0b60854243b180c8ee4f870265": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "3f334775746b4389b33b75687d120001": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "95313b98d38c47118b86112bf44c30a6": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "aeec4584345b494f862398b192ac4082": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "c6e5a454af6b47aa989cc975b0241733": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    },
    "f80f1e37dffb4ba0b1fe8f46655eb0e8": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
