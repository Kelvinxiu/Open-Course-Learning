{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:47.278486Z",
     "start_time": "2018-01-07T17:30:47.268480Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import pdir as pr\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "\n",
    "DF = pd.DataFrame\n",
    "arr = np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.376485Z",
     "start_time": "2018-01-07T17:30:47.280994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13625, 60), (2990, 60), (742, 59))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'------'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((13625, 59), (2990, 59))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = \"data preprocessed\\\\keep-all-necessary-feature\\\\normalized-[z-score]\"\n",
    "\n",
    "#means, stds = eval(open(dirPath + \"\\\\means_and_stds_about_trainset.py\").read())\n",
    "\n",
    "trainSet_origin = np.loadtxt(dirPath + '\\\\train.csv', delimiter=\",\")\n",
    "validateSet_origin = np.loadtxt(dirPath + '\\\\validate.csv', delimiter=\",\")\n",
    "testSet = np.loadtxt(dirPath + '\\\\test.csv', delimiter=\",\")\n",
    "\n",
    "trainSet_origin.shape, validateSet_origin.shape, testSet.shape\n",
    "\n",
    "'------'\n",
    "\n",
    "trainSet, trainSetLabel = trainSet_origin[:, :-1], trainSet_origin[:, -1]\n",
    "validateSet, validateSetLabel = validateSet_origin[:, :-1], validateSet_origin[:, -1]\n",
    "\n",
    "trainSet.shape, validateSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两种数据集的测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.391888Z",
     "start_time": "2018-01-07T17:30:49.381881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dirPath = \".\\\\data preprocessed2\"\n",
    "\n",
    "# #means, stds = eval(open(dirPath + \"\\\\means_and_stds_about_trainset.py\").read())\n",
    "\n",
    "# trainSet = np.loadtxt(dirPath + '\\\\train.csv', delimiter=\",\")\n",
    "# trainSetLabel = np.loadtxt(dirPath + '\\\\train_label.csv', delimiter=\",\")\n",
    "\n",
    "# # validateSet = np.loadtxt(dirPath + '\\\\validate.csv', delimiter=\",\")\n",
    "# # validateSetLabel = np.loadtxt(dirPath + '\\\\validate_label.csv', delimiter=\",\")\n",
    "\n",
    "# dirPath2 = \"data preprocessed\\\\normalized-[min-max]\\\\remove-feature-[day+atemp]\"\n",
    "\n",
    "# testSet = np.loadtxt(dirPath2 + '\\\\test.csv', delimiter=\",\")\n",
    "\n",
    "# validateSet_origin = np.loadtxt(dirPath2 + '\\\\validate.csv', delimiter=\",\")\n",
    "# validateSet, validateSetLabel = validateSet_origin[:, :-1], validateSet_origin[:, -1]\n",
    "\n",
    "# trainSet.shape, validateSet.shape, testSet.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改训练集的大小\n",
    "\n",
    "用于测试训练集大小是否会影响算法表现的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.494552Z",
     "start_time": "2018-01-07T17:30:49.394892Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split_line = 24*300\n",
    "# trainSet = trainSet[:split_line, :]\n",
    "# trainSetLabel = trainSetLabel[:split_line]\n",
    "\n",
    "# trainSet.shape, trainSetLabel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 归一化预测标签值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.594157Z",
     "start_time": "2018-01-07T17:30:49.497555Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_of_cnt, std_of_cnt = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.682228Z",
     "start_time": "2018-01-07T17:30:49.601162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.48080733944954, 164.98361847646188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSetLabel.mean(), trainSetLabel.std() #处理前的均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.827340Z",
     "start_time": "2018-01-07T17:30:49.687232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean_of_cnt, std_of_cnt = trainSetLabel.mean(), trainSetLabel.std()\n",
    "\n",
    "# trainSetLabel = (trainSetLabel - mean_of_cnt)/std_of_cnt\n",
    "# validateSetLabel = (validateSetLabel - mean_of_cnt)/std_of_cnt\n",
    "\n",
    "# pd.concat([DF(trainSetLabel).describe(), DF(validateSetLabel).describe()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分验证集最后21天进行测试\n",
    "\n",
    "由于之前划分验证集时是直接取原有数据集的后18%作为验证集的，这里取验证集的后21天作为测试也相当于取原有数据集的后21天作为测试，保存了数据在时间上的连续性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:49.949446Z",
     "start_time": "2018-01-07T17:30:49.831344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((504,), (504,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 21*24 # 数据个数\n",
    "last21Days_range = np.arange(num) #样本范围\n",
    "last21Days_features, last21Days_labels_origin = validateSet[-num:], validateSetLabel[-num:]\n",
    "\n",
    "last21Days_labels_origin.shape, last21Days_range.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数实现\n",
    "\n",
    "这里实现损失函数来衡量算法的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:50.049525Z",
     "start_time": "2018-01-07T17:30:49.955449Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcLoss(predict, label):\n",
    "    '''计算预测值相对于标签值的损失值，默认使用均方误差'''\n",
    "    def RMeanSquareError(a, b):\n",
    "        '''计算均方误差'''\n",
    "        return np.sqrt(np.mean((a - b)**2))\n",
    "    \n",
    "    return RMeanSquareError(predict, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:50.901112Z",
     "start_time": "2018-01-07T17:30:50.053529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.24591518],\n",
       "       [ 10.25418779],\n",
       "       [ 10.32819634],\n",
       "       ..., \n",
       "       [ 10.08410781],\n",
       "       [ 10.02915564],\n",
       "       [ 10.09066102]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(object):\n",
    "    '''神经网络类实现'''\n",
    "    def __init__(self, n_input, n_hidden, n_output, learning_rate, lambad, SGD_batch_size=-1):\n",
    "        '''初始化函数'''\n",
    "        #设置 输入层、隐藏层、输出层结点个数\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        #设置 学习率\n",
    "        self.lr = learning_rate\n",
    "        #设置 激活函数\n",
    "        self.activation_function = lambda x : 1/(1+np.exp(-x))\n",
    "        #设置随机梯度下降每次抽取的样本个数，-1代表使用 批梯度下降\n",
    "        self.SGD_batch_size = SGD_batch_size\n",
    "        \n",
    "        #初始化 输入层到隐藏层、隐藏层到输出层的权重矩阵为正态分布\n",
    "        self.weights_input_to_hidden = np.random.normal(0, self.n_input**(-0.5),\n",
    "                                                        (self.n_input+1, self.n_hidden))\n",
    "        \n",
    "        self.weights_hidden_to_hidden = np.random.normal(0, self.n_hidden**(-0.5),\n",
    "                                                         (self.n_hidden+1, self.n_hidden))\n",
    "        \n",
    "        self.weights_hidden_to_output = np.random.normal(0, self.n_hidden**(-0.5),\n",
    "                                                         (self.n_hidden+1, self.n_output))\n",
    "        self.lambad = lambad\n",
    "        \n",
    "    def addOne2Rows(self, dataSet):\n",
    "        '''给每一个样本前加一个常数1'''\n",
    "        ones = np.ones(len(dataSet))\n",
    "        return np.column_stack((ones, dataSet))\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        '''根据训练集训练算法'''\n",
    "        #得到样本总数\n",
    "        totSampleNum = features.shape[0]\n",
    "        #初始化 权重步长矩阵\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_h = np.zeros(self.weights_hidden_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "        #选取用于训练的样本\n",
    "        sampleDatas, sampleLabels = features.copy(), labels.copy()\n",
    "        if self.SGD_batch_size != -1:\n",
    "            #从训练集中随机均匀无重复地抽取一定样本\n",
    "            sampleIdxes = np.random.choice(totSampleNum, SGD_batch_size, replace=False)\n",
    "            #得到采样后的一部分数据\n",
    "            sampleDatas, sampleLabels = features[sampleIdxes], labels[sampleIdxes]\n",
    "        #给训练集的每个样本前加上一\n",
    "        sampleDatas = self.addOne2Rows(sampleDatas)\n",
    "        #遍历\n",
    "        for X, y in zip(sampleDatas, sampleLabels):\n",
    "            ### 前向传播过程 ###\n",
    "            #计算 隐藏层 输入和输出\n",
    "            hidden_inputs_1 = np.dot(X, self.weights_input_to_hidden)\n",
    "            hidden_outputs_1 = self.activation_function(hidden_inputs_1)\n",
    "            hidden_outputs_1 = np.insert(hidden_outputs_1, 0, 1)\n",
    "            \n",
    "            hidden_inputs_2 = np.dot(hidden_outputs_1, self.weights_hidden_to_hidden)\n",
    "            hidden_outputs_2 = self.activation_function(hidden_inputs_2)\n",
    "            hidden_outputs_2 = np.insert(hidden_outputs_2, 0, 1)\n",
    "            \n",
    "            #计算 输出层 输入和输出\n",
    "            final_inputs = np.dot(hidden_outputs_2, self.weights_hidden_to_output)\n",
    "            final_outputs = final_inputs #final_outputs=f(final_inputs)=final_inputs\n",
    "        \n",
    "            ###########################################################\n",
    "            ### 后向传播过程 ###\n",
    "            ######## 隐藏层到输出层 ########\n",
    "            #计算 输出层输出 和 目标标签值 的误差\n",
    "            error = y - final_outputs\n",
    "            #计算 输出层 误差梯度\n",
    "            output_error_term = error # = error*1\n",
    "            #更新 隐藏层到输出层 的 权重步长矩阵(广播运算，或者外积）\n",
    "            delta_weights_h_o += hidden_outputs_2.reshape(-1,1)*output_error_term\n",
    "            \n",
    "            ######## 隐藏层1到隐藏层2 ########\n",
    "            hidden2_error = np.dot(self.weights_hidden_to_output[1:, :], output_error_term)\n",
    "            hidden2_error_term = hidden2_error*hidden_outputs_2[1:]*(1-hidden_outputs_2[1:])\n",
    "            delta_weights_h_h += hidden_outputs_1.reshape(-1,1)*hidden2_error_term\n",
    "                \n",
    "            ######## 输入层到隐藏层 ########\n",
    "            #计算 传播到 隐藏层 的误差\n",
    "            hidden1_error = np.dot(self.weights_hidden_to_hidden[1:, :], hidden2_error_term)\n",
    "            #计算 隐藏层 误差梯度\n",
    "            hidden1_error_term = hidden1_error*hidden_outputs_1[1:]*(1-hidden_outputs_1[1:])\n",
    "            # 更新 输入层到隐藏层 的 权重步长矩阵(广播运算，或者外积）\n",
    "            delta_weights_i_h += X.reshape(-1,1)*hidden1_error_term\n",
    "            ###########################################################\n",
    "            \n",
    "        #正则化项\n",
    "        delta_weights_i_h[1:,:] += self.lambad*self.weights_input_to_hidden[1:,:]\n",
    "        delta_weights_h_h[1:,:] += self.lambad*self.weights_hidden_to_hidden[1:,:]\n",
    "        delta_weights_h_o[1:,:] += self.lambad*self.weights_hidden_to_output[1:,:]\n",
    "        \n",
    "        #更新 权重矩阵\n",
    "        self.weights_hidden_to_output += self.lr*delta_weights_h_o/totSampleNum\n",
    "        self.weights_hidden_to_hidden += self.lr*delta_weights_h_h/totSampleNum\n",
    "        self.weights_input_to_hidden  += self.lr*delta_weights_i_h/totSampleNum       \n",
    " \n",
    "    def apply(self, features):\n",
    "        '''应用训练好的参数到输入数据集上'''\n",
    "        features = self.addOne2Rows(features)\n",
    "        hidden_inputs_1 = np.dot(features, self.weights_input_to_hidden)\n",
    "        hidden_outputs_1 = self.activation_function(hidden_inputs_1)\n",
    "        hidden_outputs_1 = self.addOne2Rows(hidden_outputs_1)\n",
    "        \n",
    "        hidden_inputs_2 = np.dot(hidden_outputs_1, self.weights_hidden_to_hidden)\n",
    "        hidden_outputs_2 = self.activation_function(hidden_inputs_2)\n",
    "        hidden_outputs_2 = self.addOne2Rows(hidden_outputs_2)\n",
    "        \n",
    "        final_inputs = np.dot(hidden_outputs_2, self.weights_hidden_to_output)\n",
    "        final_outputs = final_inputs \n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "### 需调参的参数 ###\n",
    "learning_rate = 0.5\n",
    "n_hidden = 22\n",
    "SGD_batch_size = 256\n",
    "runTime = 1000\n",
    "lambad = 0.05\n",
    "### 不需调参的参数 ###\n",
    "n_output = 1\n",
    "n_input = trainSet.shape[1]\n",
    "\n",
    "network = NeuralNetwork(n_input, n_hidden, n_output, learning_rate, lambad, SGD_batch_size)\n",
    "network.fit(trainSet, trainSetLabel)\n",
    "network.apply(trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参\n",
    "\n",
    "参考[神经网络学习之参数的设置原则][神经网络学习之参数的设置原则]进行调参。需要调参的参数有：学习率、隐藏层个数、随机梯度下降使用的样本的个数。\n",
    "\n",
    "[神经网络学习之参数的设置原则]:https://www.cnblogs.com/sunfie/p/5519604.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制损失值随迭代此时变化的曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:50.931133Z",
     "start_time": "2018-01-07T17:30:50.903112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_loss_fig(test_range, train_loss, validate_loss, fileName=\"test_loss.png\", showFig=True):\n",
    "    fig, ax = plt.subplots() \n",
    "    fig.set_size_inches(10.5, 4)\n",
    "    plt.plot(test_range, train_loss, 'r', label=\"Training loss\")\n",
    "    plt.plot(test_range, validate_loss, 'g', label=\"Validation loss\")\n",
    "    plt.xlabel('run time')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title(\"loss versus rum time in Neural Network\")\n",
    "    plt.legend(bbox_to_anchor=(0, -0.1), loc=2, borderaxespad=0., fontsize='small')\n",
    "    if showFig:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fileName)\n",
    "    plt.close()\n",
    "\n",
    "# show_loss_fig(testRange, trainLosses*std_of_cnt+mean_of_cnt,\n",
    "#               validationLosses*std_of_cnt+mean_of_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制对验证集后21天的预测值与实际值的对比图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:51.021206Z",
     "start_time": "2018-01-07T17:30:50.938145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_last21Days_fig(test_range, predict, label, fileName=\"test_last21Days.png\", showFig=True):\n",
    "    fig, ax = plt.subplots() \n",
    "    fig.set_size_inches(10.5, 4)\n",
    "    plt.plot(test_range, predict, 'r', label=\"prediction\")\n",
    "    plt.plot(test_range, label, 'g', label=\"data\")\n",
    "    ax.set_xlim(right=num)\n",
    "    ax.set_xticks(np.arange(0, num+24, 24))\n",
    "    ax.set_xticklabels(np.arange(0, 22, 1))\n",
    "    plt.xlabel('day')\n",
    "    plt.ylabel('count of total rental bikes')\n",
    "    plt.title(\"count of total rental bikes versus time\")\n",
    "    plt.legend(bbox_to_anchor=(0, -0.1), loc=2, borderaxespad=0., fontsize='small')\n",
    "    if showFig:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fileName)\n",
    "    plt.close()\n",
    "\n",
    "# #使用算法进行预测\n",
    "# last21Days_predicts = network.apply(last21Days_features)\n",
    "# #还原归一化后的数据\n",
    "# last21Days_predicts = (last21Days_predicts.flatten()*std_of_cnt + mean_of_cnt).astype('int64')\n",
    "# last21Days_labels = (last21Days_labels_origin.flatten()*std_of_cnt + mean_of_cnt).astype('int64')\n",
    "\n",
    "# show_last21Days_fig(last21Days_range, last21Days_predicts, last21Days_labels)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制损失函数变化曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:51.138314Z",
     "start_time": "2018-01-07T17:30:51.026207Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_cost_fig(test_range, train_costs, validate_costs, fileName=\"test_last21Days.png\", showFig=True):\n",
    "    fig, ax = plt.subplots() \n",
    "    fig.set_size_inches(10.5, 4)\n",
    "    plt.plot(test_range, train_costs, 'r', label=\"train\")\n",
    "    plt.plot(test_range, validate_costs, 'g', label=\"validate\")\n",
    "    plt.xlabel('run time')\n",
    "    plt.ylabel('cost')\n",
    "    if showFig:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fileName)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算正则化项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-07T17:30:51.241420Z",
     "start_time": "2018-01-07T17:30:51.143318Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcCostFunc(weight_input_to_hidden, weight_hidden_to_output, lambad, error):\n",
    "    a = 1/2*np.mean(error**2)\n",
    "    b = lambad/2*(np.sum(weight_input_to_hidden[1:,:]**2) + np.sum(weight_hidden_to_output[1:,:]**2))\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多次迭代运行算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-07T10:06:46.922Z"
    }
   },
   "outputs": [],
   "source": [
    "### 需调参的参数 ###\n",
    "learning_rate = 0.11\n",
    "n_hidden = 25\n",
    "SGD_batch_size = 256\n",
    "runTime = 1000\n",
    "lambad = 0.01\n",
    "### 不需调参的参数 ###\n",
    "n_output = 1\n",
    "n_input = trainSet.shape[1]\n",
    "\n",
    "network = NeuralNetwork(n_input, n_hidden, n_output, learning_rate, lambad, SGD_batch_size)\n",
    "\n",
    "\n",
    "testRange = range(1, runTime+1)\n",
    "trainLosses, validationLosses= np.zeros(runTime), np.zeros(runTime)\n",
    "trainCosts, validationCosts= np.zeros(runTime), np.zeros(runTime)\n",
    "for i in tnrange(runTime):\n",
    "    #使用数据训练算法\n",
    "    network.fit(trainSet, trainSetLabel)\n",
    "    #得到算法对 训练集 和 验证集 的预测标签\n",
    "    trainPredictLabel = network.apply(trainSet).T\n",
    "    validPredictLabel = network.apply(validateSet).T\n",
    "    #计算 损失值 并 保存 损失值结果\n",
    "    trainLosses[i] = calcLoss(trainPredictLabel, trainSetLabel)\n",
    "    validationLosses[i] = calcLoss(validPredictLabel, validateSetLabel)\n",
    "    #计算损失函数\n",
    "    trainCosts[i] = calcCostFunc(network.weights_input_to_hidden,\n",
    "                            network.weights_input_to_hidden, lambad, trainPredictLabel-trainSetLabel)\n",
    "    #计算损失函数\n",
    "    validationCosts[i] = calcCostFunc(network.weights_input_to_hidden,\n",
    "                            network.weights_input_to_hidden, lambad, validateSetLabel-validPredictLabel)\n",
    "\n",
    "show_cost_fig(testRange, trainCosts, validationCosts)    \n",
    "show_loss_fig(testRange, trainLosses*std_of_cnt+mean_of_cnt, validationLosses*std_of_cnt+mean_of_cnt)\n",
    "\n",
    "#使用算法进行预测\n",
    "last21Days_predicts = network.apply(last21Days_features)\n",
    "#还原归一化后的数据\n",
    "last21Days_predicts_back = np.round(last21Days_predicts.flatten()*std_of_cnt + mean_of_cnt)\n",
    "last21Days_labels = np.round(last21Days_labels_origin.flatten()*std_of_cnt + mean_of_cnt)\n",
    "\n",
    "show_last21Days_fig(last21Days_range, last21Days_predicts_back, last21Days_labels)    \n",
    "\n",
    "ansLabel = network.apply(testSet).flatten()*std_of_cnt + mean_of_cnt\n",
    "ansLabel = np.round(ansLabel)\n",
    "np.savetxt('.\\\\rank\\\\47_v1.csv', ansLabel, fmt=\"%d\", delimiter=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用算法到测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多次测试调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T22:06:32.476452Z",
     "start_time": "2017-12-27T22:06:32.316322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirPath = \".\\\\out\\\\21days\"\n",
    "if not os.path.exists(dirPath):\n",
    "    os.makedirs(dirPath)\n",
    "dirPath = \".\\\\out\\\\loss\"\n",
    "if not os.path.exists(dirPath):\n",
    "    os.makedirs(dirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-27T22:06:32.674610Z",
     "start_time": "2017-12-27T22:06:32.480453Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'lambad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-ea8340f2e1c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hiddens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtestManyTimes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hiddens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-ea8340f2e1c6>\u001b[0m in \u001b[0;36mtestManyTimes\u001b[0;34m(learning_rate, n_hidden)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mn_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGD_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrunTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2500\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'lambad'"
     ]
    }
   ],
   "source": [
    "def testManyTimes(learning_rate, n_hidden):\n",
    "    ### 需调参的参数 ###\n",
    "    #learning_rate = 0.8\n",
    "    #n_hidden = 5\n",
    "    ### 不需调参的参数 ###\n",
    "    #SGD_batch_size = -1\n",
    "    n_output = 1\n",
    "    n_input = trainSet.shape[1]\n",
    "    \n",
    "    network = NeuralNetwork(n_input, n_hidden, n_output, learning_rate, SGD_batch_size=256)\n",
    "\n",
    "    runTime = 2500\n",
    "    testRange = range(1, runTime+1)\n",
    "    trainLosses, validationLosses = np.zeros(runTime), np.zeros(runTime)\n",
    "    for i in tnrange(runTime, leave=False):\n",
    "        #使用数据训练算法\n",
    "        network.fit(trainSet, trainSetLabel)\n",
    "        #得到算法对 训练集 和 验证集 的预测标签\n",
    "        trainPredictLabel = network.apply(trainSet).T\n",
    "        validPredictLabel = network.apply(validateSet).T\n",
    "        #计算 损失值 并 保存 损失值结果\n",
    "        trainLosses[i] = calcLoss(trainPredictLabel, trainSetLabel)\n",
    "        validationLosses[i] = calcLoss(validPredictLabel, validateSetLabel)\n",
    "    \n",
    "    outName = str(learning_rate) + \"-\" + str(n_hidden)+\".png\"\n",
    "    show_loss_fig(testRange, trainLosses, validationLosses, \".\\\\out\\\\loss\\\\\" + outName, showFig=False)\n",
    "    #使用算法进行预测\n",
    "    last21Days_predicts = network.apply(last21Days_features)\n",
    "    #还原归一化后的数据\n",
    "    last21Days_predicts = np.round(last21Days_predicts.flatten()*std_of_cnt + mean_of_cnt)\n",
    "    last21Days_labels = np.round(last21Days_labels_origin.flatten()*std_of_cnt + mean_of_cnt)\n",
    "\n",
    "    show_last21Days_fig(last21Days_range, last21Days_predicts, last21Days_labels, \".\\\\out\\\\21days\\\\\" + outName, showFig=False)   \n",
    "\n",
    "\n",
    "learning_rates = [0.1] #np.arange(0.1, 1, 0.1)\n",
    "n_hiddens = np.arange(6, 20, 2)\n",
    "\n",
    "for i in tnrange(len(learning_rates)):\n",
    "    for j in tnrange(len(n_hiddens), leave=False):\n",
    "        testManyTimes(learning_rates[i], n_hiddens[j])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "45ef2a9398654d58932fc755a02b1aeb": {
     "views": [
      {
       "cell_index": 27
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
