{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验内容\n",
    "\n",
    "```\n",
    "data\n",
    "├─classification_dataset\n",
    "│      15351234_Sample_KNN_classification.csv\n",
    "│      15351234_Sample_NB_classification.csv\n",
    "│      test_set.csv\n",
    "│      train_set.csv\n",
    "│      validation_set.csv\n",
    "│\n",
    "└─regression_dataset\n",
    "        15351234_Sample_KNN_regression.csv\n",
    "        15351234_Sample_NB_regression.csv\n",
    "        test_set.csv\n",
    "        train_set.csv\n",
    "        validation_set.csv\n",
    "        validation相关度评估.xlsx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类\n",
    "\n",
    "## 数据预处理及分析\n",
    "\n",
    "\n",
    "### 数据读取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.106112Z",
     "start_time": "2017-10-17T22:39:46.081095Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = list(df['label'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words (split by space)'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【one line\\'s data preview】:')\n",
    "    display(df.head(1))\n",
    "    #输出所有label的分布\n",
    "    print('【count of all kind of labels】:\\n')\n",
    "    print(df['label'].value_counts())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.288181Z",
     "start_time": "2017-10-17T22:39:46.110114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe retain trophy with big win</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Words (split by space) label\n",
       "0  europe retain trophy with big win   joy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy         222\n",
      "sad         132\n",
      "surprise    113\n",
      "fear         95\n",
      "anger        41\n",
      "disgust      20\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  2087\n",
      "【number of texts】:  623\n"
     ]
    }
   ],
   "source": [
    "dataPath = '.\\\\data\\\\classification_dataset\\\\'\n",
    "trainSet, trainSet_label, allWords_trainSet = loadDataSet(dataPath+'train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.413273Z",
     "start_time": "2017-10-17T22:39:46.294185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marijuana helps ease hiv nerve pain study says</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words (split by space)     label\n",
       "0  marijuana helps ease hiv nerve pain study says  surprise"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy         112\n",
      "sad          65\n",
      "fear         54\n",
      "surprise     46\n",
      "anger        21\n",
      "disgust      13\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  1235\n",
      "【number of texts】:  311\n"
     ]
    }
   ],
   "source": [
    "validatePath = dataPath+'validation_set.csv'\n",
    "validateSet, validateSet_label, allWords_validateSet = loadDataSet(validatePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.623420Z",
     "start_time": "2017-10-17T22:39:46.417272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textid</th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>senator carl krueger thinks ipods can kill you</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   textid                          Words (split by space) label\n",
       "0       1  senator carl krueger thinks ipods can kill you     ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "?    312\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  1273\n",
      "【number of texts】:  312\n"
     ]
    }
   ],
   "source": [
    "testSet, _ , allWords_testSet = loadDataSet(dataPath+'test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并三个数据集的所有不重复的词，供后续得到onehot和TF矩阵使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.649438Z",
     "start_time": "2017-10-17T22:39:46.627423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 2771)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords_train_validate = list(set(allWords_trainSet).union(allWords_validateSet))\n",
    "allWords_train_test = list(set(allWords_trainSet).union(allWords_testSet))\n",
    "len(allWords_train_validate), len(allWords_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T19:23:29.452507Z",
     "start_time": "2017-10-11T19:23:29.439993Z"
    }
   },
   "source": [
    "### 得到3个数据集的onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:48.768905Z",
     "start_time": "2017-10-17T22:39:46.652440Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneHot(dataSet, allWords):\n",
    "    '''得到输入数据集的one-hot矩阵'''\n",
    "    oneHot=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        oneHot.append([])\n",
    "        for word in allWords:\n",
    "            if word in doc:\n",
    "                oneHot[index].append(1)\n",
    "            else: \n",
    "                oneHot[index].append(0)\n",
    "    return oneHot\n",
    "\n",
    "#得到训练集、验证集、测试集的onehot矩阵\n",
    "oneHot_trainSet = getOneHot(trainSet, allWords_train_validate)\n",
    "oneHot_validateSet = getOneHot(validateSet, allWords_train_validate)\n",
    "\n",
    "oneHot_trainSet_ = getOneHot(trainSet, allWords_train_test)\n",
    "oneHot_testSet = getOneHot(testSet, allWords_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到3个数据集的TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:50.985123Z",
     "start_time": "2017-10-17T22:39:48.768905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    TF=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(doc)\n",
    "        for word in allWords:\n",
    "            TF[index].append(wordCounter.get(word,0)/len(doc))\n",
    "    return TF\n",
    "\n",
    "#得到训练集、验证集、测试集的TF矩阵\n",
    "TF_trainSet = getTF(trainSet, allWords_train_validate)\n",
    "TF_validateSet = getTF(validateSet, allWords_train_validate)\n",
    "\n",
    "TF_trainSet_ = getTF(trainSet, allWords_train_test)\n",
    "TF_testSet = getTF(testSet, allWords_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到3个数据集的频次矩阵\n",
    "\n",
    "该矩阵用于NB的分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T23:25:19.316222Z",
     "start_time": "2017-10-17T23:25:19.311219Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getFreq(trainSet, allWordsNum_train, otherSet, allWords_train_other, \n",
    "            trainSet_label, Laplace_Smoothing=True):\n",
    "    '''得到输入数据集的频次矩阵'''\n",
    "    def calcProbs(numerator, denominator):\n",
    "        '''根据输入的分子和分母计算先验概率值'''\n",
    "        if Laplace_Smoothing:\n",
    "            return (numerator+1)/(denominator+allWordsNum_train)\n",
    "        else:\n",
    "            return numerator/denominator\n",
    "        \n",
    "    trainSet = np.array(trainSet)\n",
    "    trainSet_label = np.array(trainSet_label)\n",
    "    \n",
    "    #得到所有可能的标签\n",
    "    allLabels = list(set(trainSet_label))\n",
    "    ans = dict()\n",
    "    #遍历所有标签\n",
    "    for label in allLabels:\n",
    "        #找到所有标签为 label 的 documents\n",
    "        allDocs_with_label = trainSet[np.argwhere(trainSet_label==label)[:,0]]\n",
    "        #得到上面的所有 documents 中的所有词\n",
    "        allWords_with_label = [j for i in list(allDocs_with_label) for j in i]\n",
    "        #词频统计\n",
    "        wordCounter = Counter(allWords_with_label)\n",
    "        #预分配内存\n",
    "        ans[label] = [0]*len(allWords_train_other)\n",
    "        for index, word in enumerate(allWords_train_other):\n",
    "            ans[label][index] = calcProbs(wordCounter.get(word,0), len(allWords_with_label))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn分类算法\n",
    "\n",
    "### 分类函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:34:12.320822Z",
     "start_time": "2017-10-13T13:34:12.286283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_classify(dataSet, labels, k, inputVector):\n",
    "    '''使用knn对输入的向量进行分类，使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    #得到 K个近邻的下标\n",
    "    kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "    #返回分类结果\n",
    "    return Counter(np.array(labels)[kNeighborsIndex]).most_common(1)[0][0]\n",
    "\n",
    "knn_classify([[1,1,0,0],\n",
    "              [0,1,1,1],\n",
    "              [1,0,0,1]],['positive','negative','positive'], 3, [0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T08:50:52.270142Z",
     "start_time": "2017-10-12T08:50:52.242140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'manhattan'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'cosine'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'euclidean'\n",
    "'manhattan'\n",
    "'cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参\n",
    "#### 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T16:39:14.409360Z",
     "start_time": "2017-10-13T15:34:57.939901Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 : accuracy: 37.29904%\n",
      "k =  2 : accuracy: 26.04502%\n",
      "k =  3 : accuracy: 37.62058%\n",
      "k =  4 : accuracy: 32.47588%\n",
      "k =  5 : accuracy: 32.15434%\n",
      "k =  6 : accuracy: 32.47588%\n",
      "k =  7 : accuracy: 36.33441%\n",
      "k =  8 : accuracy: 36.01286%\n",
      "k =  9 : accuracy: 37.29904%\n",
      "k = 10 : accuracy: 39.87138%\n",
      "k = 11 : accuracy: 39.54984%\n",
      "k = 12 : accuracy: 39.22830%\n",
      "k = 13 : accuracy: 40.83601%\n",
      "k = 14 : accuracy: 42.44373%\n",
      "k = 15 : accuracy: 39.54984%\n",
      "k = 16 : accuracy: 41.15756%\n",
      "k = 17 : accuracy: 40.51447%\n",
      "k = 18 : accuracy: 38.58521%\n",
      "k = 19 : accuracy: 38.26367%\n",
      "k = 20 : accuracy: 38.90675%\n",
      "k = 21 : accuracy: 38.58521%\n",
      "k = 22 : accuracy: 38.26367%\n",
      "k = 23 : accuracy: 37.94212%\n",
      "k = 24 : accuracy: 37.94212%\n",
      "k = 25 : accuracy: 37.94212%\n",
      "k = 26 : accuracy: 37.62058%\n",
      "k = 27 : accuracy: 36.97749%\n",
      "k = 28 : accuracy: 37.29904%\n",
      "k = 29 : accuracy: 37.94212%\n",
      "k = 30 : accuracy: 37.29904%\n",
      "k = 31 : accuracy: 36.65595%\n",
      "k = 32 : accuracy: 37.29904%\n",
      "k = 33 : accuracy: 37.94212%\n",
      "k = 34 : accuracy: 38.58521%\n",
      "k = 35 : accuracy: 38.26367%\n",
      "k = 36 : accuracy: 38.90675%\n",
      "k = 37 : accuracy: 38.26367%\n",
      "k = 38 : accuracy: 38.90675%\n",
      "k = 39 : accuracy: 38.90675%\n",
      "k = 40 : accuracy: 39.22830%\n",
      "k = 41 : accuracy: 38.58521%\n",
      "k = 42 : accuracy: 38.58521%\n",
      "k = 43 : accuracy: 38.58521%\n",
      "k = 44 : accuracy: 38.26367%\n",
      "k = 45 : accuracy: 37.62058%\n",
      "k = 46 : accuracy: 37.62058%\n",
      "k = 47 : accuracy: 37.94212%\n",
      "k = 48 : accuracy: 37.29904%\n",
      "k = 49 : accuracy: 37.29904%\n"
     ]
    }
   ],
   "source": [
    "def run_knn_classify1(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    hitNum = 0\n",
    "    for index, wordVector in enumerate(oneHot_validateSet):\n",
    "        ans = knn_classify(oneHot_trainSet, trainSet_label, k, wordVector)\n",
    "        if  ans == validateSet_label[index]:\n",
    "            hitNum +=1\n",
    "    print(\"k = %2d : accuracy: %.5f%%\" % (k, 100*hitNum/len(validateSet)))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_classify1(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T17:01:10.011344Z",
     "start_time": "2017-10-13T16:41:11.519457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 : accuracy: 32.47588%\n",
      "k =  2 : accuracy: 25.72347%\n",
      "k =  3 : accuracy: 24.75884%\n",
      "k =  4 : accuracy: 25.08039%\n",
      "k =  5 : accuracy: 23.47267%\n",
      "k =  6 : accuracy: 25.40193%\n",
      "k =  7 : accuracy: 26.36656%\n",
      "k =  8 : accuracy: 27.97428%\n",
      "k =  9 : accuracy: 27.97428%\n",
      "k = 10 : accuracy: 25.72347%\n",
      "k = 11 : accuracy: 26.36656%\n",
      "k = 12 : accuracy: 26.68810%\n",
      "k = 13 : accuracy: 29.26045%\n",
      "k = 14 : accuracy: 29.58199%\n",
      "k = 15 : accuracy: 30.54662%\n",
      "k = 16 : accuracy: 30.86817%\n",
      "k = 17 : accuracy: 28.29582%\n",
      "k = 18 : accuracy: 28.29582%\n",
      "k = 19 : accuracy: 26.36656%\n",
      "k = 20 : accuracy: 27.97428%\n",
      "k = 21 : accuracy: 27.33119%\n",
      "k = 22 : accuracy: 28.29582%\n",
      "k = 23 : accuracy: 28.29582%\n",
      "k = 24 : accuracy: 27.97428%\n",
      "k = 25 : accuracy: 27.97428%\n",
      "k = 26 : accuracy: 28.61736%\n",
      "k = 27 : accuracy: 29.26045%\n",
      "k = 28 : accuracy: 27.65273%\n",
      "k = 29 : accuracy: 28.29582%\n",
      "k = 30 : accuracy: 28.29582%\n",
      "k = 31 : accuracy: 27.65273%\n",
      "k = 32 : accuracy: 27.00965%\n",
      "k = 33 : accuracy: 27.00965%\n",
      "k = 34 : accuracy: 27.00965%\n",
      "k = 35 : accuracy: 27.65273%\n",
      "k = 36 : accuracy: 26.36656%\n",
      "k = 37 : accuracy: 26.68810%\n",
      "k = 38 : accuracy: 29.26045%\n",
      "k = 39 : accuracy: 28.61736%\n",
      "k = 40 : accuracy: 27.97428%\n",
      "k = 41 : accuracy: 27.65273%\n",
      "k = 42 : accuracy: 27.65273%\n",
      "k = 43 : accuracy: 28.93891%\n",
      "k = 44 : accuracy: 28.93891%\n",
      "k = 45 : accuracy: 29.58199%\n",
      "k = 46 : accuracy: 30.22508%\n",
      "k = 47 : accuracy: 29.26045%\n",
      "k = 48 : accuracy: 30.22508%\n",
      "k = 49 : accuracy: 28.93891%\n"
     ]
    }
   ],
   "source": [
    "def run_knn_classify2(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    hitNum = 0\n",
    "    for index, wordVector in enumerate(TF_validateSet):\n",
    "        ans = knn_classify(TF_trainSet, trainSet_label, k, wordVector)\n",
    "        if  ans == validateSet_label[index]:\n",
    "            hitNum +=1\n",
    "    print(\"k = %2d : accuracy: %.5f%%\" % (k, 100*hitNum/len(validateSet)))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_classify2(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集进行分类\n",
    "#### 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:15:43.037470Z",
     "start_time": "2017-10-13T18:15:00.246364Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFileName = \"15352220_linzecheng_KNN_classification_onehot.csv\"\n",
    "bestK = 14\n",
    "textid_and_label = []\n",
    "for index, wordVector in enumerate(oneHot_testSet):\n",
    "        ans = knn_classify(oneHot_trainSet_, trainSet_label, bestK, wordVector)\n",
    "        textid_and_label.append((index+1, ans))\n",
    "        \n",
    "res = pd.DataFrame(textid_and_label, columns=['textid','label'])\n",
    "res.to_csv(outputFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:16:55.535198Z",
     "start_time": "2017-10-13T18:16:55.528188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         218\n",
       "fear         57\n",
       "sad          35\n",
       "surprise      2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:17:49.616292Z",
     "start_time": "2017-10-13T18:17:25.187665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFileName = \"15352220_linzecheng_KNN_classification_TF.csv\"\n",
    "bestK = 16\n",
    "textid_and_label = []\n",
    "for index, wordVector in enumerate(TF_testSet):\n",
    "        ans = knn_classify(TF_trainSet_, trainSet_label, bestK, wordVector)\n",
    "        textid_and_label.append((index+1, ans))\n",
    "        \n",
    "res2 = pd.DataFrame(textid_and_label, columns=['textid','label'])\n",
    "res2.to_csv(outputFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:17:49.640106Z",
     "start_time": "2017-10-13T18:17:49.620291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise    186\n",
       "joy          49\n",
       "sad          32\n",
       "fear         23\n",
       "anger        22\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归\n",
    "\n",
    "## 数据预处理及分析\n",
    "\n",
    "### 数据读取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:20:41.849383Z",
     "start_time": "2017-10-13T18:20:41.804319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet2(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = dict()\n",
    "    label['anger'] = list(df['anger'].values)  \n",
    "    label['disgust'] = list(df['disgust'].values)  \n",
    "    label['fear'] = list(df['fear'].values)\n",
    "    label['joy'] = list(df['joy'].values)  \n",
    "    label['sad'] = list(df['sad'].values)  \n",
    "    label['surprise'] = list(df['surprise'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words (split by space)'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【one line\\'s data preview】:')\n",
    "    display(df.head(1))\n",
    "    #输出所有情感值的一些统计数据\n",
    "    print('【some summary statistics of labels】:')\n",
    "    print(df[['anger','disgust','fear','joy','sad','surprise']].describe())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:22:09.729414Z",
     "start_time": "2017-10-13T18:22:09.413687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe retain trophy with big win</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Words (split by space)  anger  disgust  fear     joy  sad  \\\n",
       "0  europe retain trophy with big win    0.0      0.0   0.0  0.8721  0.0   \n",
       "\n",
       "   surprise  \n",
       "0    0.1279  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "            anger     disgust        fear         joy         sad    surprise\n",
      "count  623.000000  623.000000  623.000000  623.000000  623.000000  623.000000\n",
      "mean     0.086573    0.052949    0.157176    0.281344    0.191442    0.230517\n",
      "std      0.123334    0.090709    0.174959    0.317420    0.206464    0.199993\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.090100\n",
      "50%      0.022700    0.000000    0.115400    0.130800    0.142900    0.176500\n",
      "75%      0.144950    0.083300    0.255450    0.566950    0.293450    0.326750\n",
      "max      0.753400    0.571400    0.895800    1.000000    1.000000    1.000000\n",
      "【number of all words】:  2087\n",
      "【number of texts】:  623\n"
     ]
    }
   ],
   "source": [
    "dataPath2 = '.\\\\data\\\\regression_dataset\\\\'\n",
    "trainPath = dataPath2+'train_set.csv'\n",
    "trainSet2, trainSet_label2, allWords_trainSet2 = loadDataSet2(trainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:23:18.888599Z",
     "start_time": "2017-10-13T18:23:18.831552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marijuana helps ease hiv nerve pain study says</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.5537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words (split by space)  anger  disgust    fear  \\\n",
       "0  marijuana helps ease hiv nerve pain study says    0.0      0.0  0.0744   \n",
       "\n",
       "      joy     sad  surprise  \n",
       "0  0.2727  0.0992    0.5537  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "            anger     disgust        fear         joy         sad    surprise\n",
      "count  311.000000  311.000000  311.000000  311.000000  311.000000  311.000000\n",
      "mean     0.085478    0.062534    0.151173    0.287755    0.194680    0.218382\n",
      "std      0.125672    0.110057    0.175016    0.310162    0.208836    0.189515\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.073650\n",
      "50%      0.012200    0.000000    0.088900    0.177800    0.138900    0.181800\n",
      "75%      0.150600    0.098400    0.245550    0.553650    0.300900    0.320900\n",
      "max      0.777800    0.785700    0.815400    1.000000    0.903200    1.000000\n",
      "【number of all words】:  1235\n",
      "【number of texts】:  311\n"
     ]
    }
   ],
   "source": [
    "validatePath = dataPath2+'validation_set.csv'\n",
    "validateSet2, validateSet_label2, allWords_validateSet2 = loadDataSet2(validatePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:22:38.178433Z",
     "start_time": "2017-10-13T18:22:38.040812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textid</th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>senator carl krueger thinks ipods can kill you</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   textid                          Words (split by space) anger disgust fear  \\\n",
       "0       1  senator carl krueger thinks ipods can kill you     ?       ?    ?   \n",
       "\n",
       "  joy sad surprise  \n",
       "0   ?   ?        ?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "       anger disgust fear  joy  sad surprise\n",
      "count    312     312  312  312  312      312\n",
      "unique     1       1    1    1    1        1\n",
      "top        ?       ?    ?    ?    ?        ?\n",
      "freq     312     312  312  312  312      312\n",
      "【number of all words】:  1273\n",
      "【number of texts】:  312\n"
     ]
    }
   ],
   "source": [
    "testSet2, _ , allWords_testSet2 = loadDataSet2(dataPath2+'test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:23:22.542069Z",
     "start_time": "2017-10-13T18:23:22.530554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 2771)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords_train_validate2 = list(set(allWords_trainSet2).union(allWords_validateSet2))\n",
    "allWords_train_test2 = list(set(allWords_trainSet2).union(allWords_testSet2))\n",
    "len(allWords_train_validate2), len(allWords_train_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  得到3个数据集的onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:28:28.293897Z",
     "start_time": "2017-10-13T18:28:26.570353Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#得到训练集、验证集、测试集的onehot矩阵\n",
    "oneHot_trainSet2 = getOneHot(trainSet2, allWords_train_validate2)\n",
    "oneHot_validateSet2 = getOneHot(validateSet2, allWords_train_validate2)\n",
    "\n",
    "oneHot_trainSet2_ = getOneHot(trainSet2, allWords_train_test2)\n",
    "oneHot_testSet2 = getOneHot(testSet2, allWords_train_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到3个数据集的TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:29:18.409108Z",
     "start_time": "2017-10-13T18:29:15.981280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    TF=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(doc)\n",
    "        for word in allWords:\n",
    "            TF[index].append(wordCounter.get(word,0)/len(doc))\n",
    "    return TF\n",
    "\n",
    "#得到训练集、验证集、测试集的TF矩阵\n",
    "TF_trainSet2 = getTF(trainSet2, allWords_train_validate2)\n",
    "TF_validateSet2 = getTF(validateSet2, allWords_train_validate2)\n",
    "\n",
    "TF_trainSet2_ = getTF(trainSet2, allWords_train_test2)\n",
    "TF_testSet2 = getTF(testSet2, allWords_train_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn回归算法\n",
    "\n",
    "### 权值归一化函数实现\n",
    "\n",
    "不同意PPT里的权值归一化的说法，下面这个函数暂时不会使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T21:38:44.674179Z",
     "start_time": "2017-10-12T21:38:44.608632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.22474487,  0.        ,  1.22474487])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weightNormalize(weight, method='min-max'):\n",
    "    '''权值归一化函数，输入权值类型为numpy.array'''\n",
    "    if len(weight) == 1:\n",
    "        return weight\n",
    "    elif method == 'min-max':\n",
    "        return (weight-weight.min())/(weight.max()-weight.min())\n",
    "    elif method == 'z-score':\n",
    "        return (weight-weight.mean())/weight.std()\n",
    "\n",
    "weightNormalize(np.array([1,2,3]))\n",
    "weightNormalize(np.array([1,2,3]),'z-score')\n",
    "\n",
    "weightNormalize(np.array([5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:31:05.237630Z",
     "start_time": "2017-10-13T18:31:04.995629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0.078289990098415738,\n",
       " 'disgust': 0.10324103798366886,\n",
       " 'fear': 0.45049113784014211,\n",
       " 'joy': 0.06570327996502047,\n",
       " 'sad': 0.19903351612908382,\n",
       " 'surprise': 0.10324103798366886}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_regress(dataSet, labels, k, inputVector):\n",
    "    '''使用knn对输入的向量进行回归，先默认使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    \n",
    "    #要输出的label\n",
    "    outputLabel = dict() \n",
    "    #label中每个分量的概率值\n",
    "    probs = np.zeros((1,len(labels.keys())))\n",
    "    #若距离中存在0，则直接拷贝距离为0对应元素的label\n",
    "    if 0 in distances:\n",
    "        zeroIndex = distances.tolist().index(0)\n",
    "        for index, i in enumerate(labels.keys()):\n",
    "            outputLabel[i] = labels[i][zeroIndex]\n",
    "            probs[0,index] = outputLabel[i]\n",
    "    else:\n",
    "        #得到 K个近邻的下标\n",
    "        kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "        #用label值除以距离并求和，更新输出的 label\n",
    "        weight = 1/distances[kNeighborsIndex]\n",
    "        \n",
    "        for index, i in enumerate(labels.keys()):\n",
    "            #得到 K个近邻的标签\n",
    "            topKLabel = np.array(labels[i])[kNeighborsIndex]\n",
    "            outputLabel[i] = (topKLabel*weight).sum()\n",
    "            #保存当前概率值，用于后续归一化\n",
    "            probs[0,index] = outputLabel[i]\n",
    "    \n",
    "    #将所有概率值的和调整为1\n",
    "    for i in outputLabel.keys():\n",
    "        outputLabel[i] = outputLabel[i] / probs.sum()\n",
    "    return outputLabel\n",
    "\n",
    "# knn_regress([[1,1,0,0],[0,1,1,1],[1,0,0,1]],\n",
    "#             {'happy':[0.4,0.5,0.1], \n",
    "#              'sad':[0.2,0.3,0.2], \n",
    "#              'calm':[0.1,0.25,0.8]}, 2, [0,1,1,0])\n",
    "\n",
    "a = oneHot_validateSet2[0]\n",
    "knn_regress(oneHot_trainSet2, trainSet_label2, 2, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参\n",
    "#### 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T19:06:32.699829Z",
     "start_time": "2017-10-13T18:31:08.420320Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1：\n",
      "disgust:0.06974 fear:0.20246 anger:0.17641 surprise:0.26274 sad:0.23562 joy:0.22842 \n",
      "average:0.19590\n",
      "k = 2：\n",
      "disgust:0.14951 fear:0.18935 anger:0.21867 surprise:0.26140 sad:0.25384 joy:0.21249 \n",
      "average:0.21421\n",
      "k = 3：\n",
      "disgust:0.17165 fear:0.30999 anger:0.26360 surprise:0.30961 sad:0.27188 joy:0.36031 \n",
      "average:0.28117\n",
      "k = 4：\n",
      "disgust:0.12803 fear:0.25003 anger:0.23949 surprise:0.29278 sad:0.30006 joy:0.26669 \n",
      "average:0.24618\n",
      "k = 5：\n",
      "disgust:0.18701 fear:0.27019 anger:0.21457 surprise:0.26512 sad:0.28487 joy:0.27987 \n",
      "average:0.25027\n",
      "k = 6：\n",
      "disgust:0.15457 fear:0.25380 anger:0.20465 surprise:0.26812 sad:0.29012 joy:0.25840 \n",
      "average:0.23828\n",
      "k = 7：\n",
      "disgust:0.12378 fear:0.23897 anger:0.20549 surprise:0.25716 sad:0.28532 joy:0.24048 \n",
      "average:0.22520\n",
      "k = 8：\n",
      "disgust:0.13491 fear:0.27800 anger:0.18004 surprise:0.25414 sad:0.30558 joy:0.27249 \n",
      "average:0.23753\n",
      "k = 9：\n",
      "disgust:0.10519 fear:0.28046 anger:0.18512 surprise:0.26503 sad:0.32458 joy:0.27891 \n",
      "average:0.23988\n",
      "k =10：\n",
      "disgust:0.14604 fear:0.26491 anger:0.18036 surprise:0.26319 sad:0.33416 joy:0.27371 \n",
      "average:0.24373\n",
      "k =11：\n",
      "disgust:0.12069 fear:0.25838 anger:0.17312 surprise:0.24188 sad:0.33632 joy:0.26551 \n",
      "average:0.23265\n",
      "k =12：\n",
      "disgust:0.13303 fear:0.26830 anger:0.18226 surprise:0.24049 sad:0.33809 joy:0.27549 \n",
      "average:0.23961\n",
      "k =13：\n",
      "disgust:0.14771 fear:0.28021 anger:0.20547 surprise:0.25149 sad:0.34059 joy:0.30852 \n",
      "average:0.25567\n",
      "k =14：\n",
      "disgust:0.17787 fear:0.29880 anger:0.21852 surprise:0.24553 sad:0.32591 joy:0.30625 \n",
      "average:0.26215\n",
      "k =15：\n",
      "disgust:0.18321 fear:0.28714 anger:0.20825 surprise:0.25253 sad:0.31663 joy:0.31423 \n",
      "average:0.26033\n",
      "k =16：\n",
      "disgust:0.18352 fear:0.27125 anger:0.21662 surprise:0.24447 sad:0.31119 joy:0.30215 \n",
      "average:0.25487\n",
      "k =17：\n",
      "disgust:0.17434 fear:0.26840 anger:0.20811 surprise:0.25672 sad:0.30391 joy:0.30852 \n",
      "average:0.25333\n",
      "k =18：\n",
      "disgust:0.17026 fear:0.26193 anger:0.21566 surprise:0.23840 sad:0.29903 joy:0.31063 \n",
      "average:0.24932\n",
      "k =19：\n",
      "disgust:0.14440 fear:0.24877 anger:0.22231 surprise:0.23795 sad:0.29679 joy:0.30395 \n",
      "average:0.24236\n",
      "k =20：\n",
      "disgust:0.12379 fear:0.25170 anger:0.22080 surprise:0.23335 sad:0.30211 joy:0.30940 \n",
      "average:0.24019\n",
      "k =21：\n",
      "disgust:0.13172 fear:0.26511 anger:0.22674 surprise:0.24319 sad:0.31045 joy:0.31716 \n",
      "average:0.24906\n",
      "k =22：\n",
      "disgust:0.11053 fear:0.26269 anger:0.23088 surprise:0.24042 sad:0.31800 joy:0.31700 \n",
      "average:0.24659\n",
      "k =23：\n",
      "disgust:0.11181 fear:0.25776 anger:0.23960 surprise:0.24342 sad:0.30892 joy:0.31787 \n",
      "average:0.24656\n",
      "k =24：\n",
      "disgust:0.13780 fear:0.27675 anger:0.23277 surprise:0.25330 sad:0.30897 joy:0.32873 \n",
      "average:0.25639\n",
      "k =25：\n",
      "disgust:0.13924 fear:0.27147 anger:0.23281 surprise:0.25188 sad:0.31253 joy:0.33053 \n",
      "average:0.25641\n",
      "k =26：\n",
      "disgust:0.13132 fear:0.27424 anger:0.23270 surprise:0.26380 sad:0.31902 joy:0.33972 \n",
      "average:0.26013\n",
      "k =27：\n",
      "disgust:0.13480 fear:0.26516 anger:0.22610 surprise:0.25945 sad:0.29808 joy:0.32687 \n",
      "average:0.25174\n",
      "k =28：\n",
      "disgust:0.15239 fear:0.26506 anger:0.23298 surprise:0.25688 sad:0.28799 joy:0.32463 \n",
      "average:0.25332\n",
      "k =29：\n",
      "disgust:0.14241 fear:0.26210 anger:0.23696 surprise:0.25915 sad:0.27620 joy:0.31128 \n",
      "average:0.24802\n",
      "k =30：\n",
      "disgust:0.14487 fear:0.25611 anger:0.23294 surprise:0.25589 sad:0.27433 joy:0.30574 \n",
      "average:0.24498\n",
      "k =31：\n",
      "disgust:0.13798 fear:0.25449 anger:0.22702 surprise:0.24404 sad:0.27141 joy:0.31168 \n",
      "average:0.24110\n",
      "k =32：\n",
      "disgust:0.15149 fear:0.24303 anger:0.23097 surprise:0.24139 sad:0.28192 joy:0.30589 \n",
      "average:0.24245\n",
      "k =33：\n",
      "disgust:0.14559 fear:0.23594 anger:0.23410 surprise:0.23694 sad:0.28398 joy:0.30202 \n",
      "average:0.23976\n",
      "k =34：\n",
      "disgust:0.15633 fear:0.25141 anger:0.23918 surprise:0.24600 sad:0.27389 joy:0.30310 \n",
      "average:0.24498\n",
      "k =35：\n",
      "disgust:0.16521 fear:0.26447 anger:0.24355 surprise:0.24567 sad:0.27818 joy:0.30084 \n",
      "average:0.24965\n",
      "k =36：\n",
      "disgust:0.16416 fear:0.26248 anger:0.24097 surprise:0.23507 sad:0.27152 joy:0.30028 \n",
      "average:0.24574\n",
      "k =37：\n",
      "disgust:0.15127 fear:0.26217 anger:0.23531 surprise:0.23579 sad:0.27359 joy:0.30238 \n",
      "average:0.24342\n",
      "k =38：\n",
      "disgust:0.15499 fear:0.25994 anger:0.23565 surprise:0.23620 sad:0.26823 joy:0.29764 \n",
      "average:0.24211\n",
      "k =39：\n",
      "disgust:0.14609 fear:0.24547 anger:0.24308 surprise:0.23382 sad:0.27316 joy:0.29228 \n",
      "average:0.23898\n",
      "k =40：\n",
      "disgust:0.14838 fear:0.23823 anger:0.24573 surprise:0.23284 sad:0.26781 joy:0.28697 \n",
      "average:0.23666\n",
      "k =41：\n",
      "disgust:0.14685 fear:0.24121 anger:0.25098 surprise:0.23420 sad:0.25767 joy:0.28516 \n",
      "average:0.23601\n",
      "k =42：\n",
      "disgust:0.15952 fear:0.24534 anger:0.24943 surprise:0.22791 sad:0.25550 joy:0.28665 \n",
      "average:0.23739\n",
      "k =43：\n",
      "disgust:0.15962 fear:0.24832 anger:0.25031 surprise:0.22975 sad:0.25109 joy:0.28496 \n",
      "average:0.23734\n",
      "k =44：\n",
      "disgust:0.17003 fear:0.25118 anger:0.25259 surprise:0.23880 sad:0.25591 joy:0.29057 \n",
      "average:0.24318\n",
      "k =45：\n",
      "disgust:0.17973 fear:0.24789 anger:0.25296 surprise:0.23730 sad:0.25757 joy:0.29613 \n",
      "average:0.24526\n",
      "k =46：\n",
      "disgust:0.17483 fear:0.25017 anger:0.25492 surprise:0.23657 sad:0.25955 joy:0.29655 \n",
      "average:0.24543\n",
      "k =47：\n",
      "disgust:0.17927 fear:0.24926 anger:0.25616 surprise:0.23688 sad:0.25590 joy:0.29043 \n",
      "average:0.24465\n",
      "k =48：\n",
      "disgust:0.18261 fear:0.24154 anger:0.25702 surprise:0.23231 sad:0.25492 joy:0.28719 \n",
      "average:0.24260\n",
      "k =49：\n",
      "disgust:0.17860 fear:0.24498 anger:0.25382 surprise:0.23462 sad:0.25527 joy:0.29083 \n",
      "average:0.24302\n"
     ]
    }
   ],
   "source": [
    "def run_knn_regress1(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    ansLabel = dict()\n",
    "    for i in validateSet_label2.keys():\n",
    "        ansLabel[i]=[]\n",
    "    for index, wordVector in enumerate(oneHot_validateSet2):\n",
    "        ans = knn_regress(oneHot_trainSet2, trainSet_label2, k, wordVector)\n",
    "        ######### nan 值的debug代码#########################\n",
    "#         flag = False\n",
    "#         for i in validateSet_label2.keys():\n",
    "#             if  np.isnan(ans[i]):\n",
    "#                 print('nan value found in %d' % (index))\n",
    "#                 print('terminate..')\n",
    "#                 flag = True\n",
    "#         if flag: break\n",
    "        ########## nan 值的debug代码#########################\n",
    "        for i in ans.keys():\n",
    "            ansLabel[i].append(ans[i])\n",
    "    \n",
    "    print('k =%2d：' % k)\n",
    "    tot = 0\n",
    "    for i in ansLabel.keys():\n",
    "        corr = np.corrcoef(ansLabel[i],validateSet_label2[i])[0,1]\n",
    "        tot += corr\n",
    "        print('%s:%.5f' % (i, corr), end=' ')\n",
    "    print('\\naverage:%.5f' % (tot/len(ansLabel.keys())))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_regress1(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T19:28:12.789947Z",
     "start_time": "2017-10-13T19:07:28.832198Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1：\n",
      "disgust:0.18534 fear:0.18922 anger:0.19106 surprise:0.25044 sad:0.33920 joy:0.29835 \n",
      "average:0.24227\n",
      "k = 2：\n",
      "disgust:0.15857 fear:0.24805 anger:0.20038 surprise:0.28051 sad:0.35063 joy:0.32682 \n",
      "average:0.26083\n",
      "k = 3：\n",
      "disgust:0.15783 fear:0.23621 anger:0.26758 surprise:0.33853 sad:0.36212 joy:0.32767 \n",
      "average:0.28165\n",
      "k = 4：\n",
      "disgust:0.16518 fear:0.28809 anger:0.27425 surprise:0.32473 sad:0.35045 joy:0.32369 \n",
      "average:0.28773\n",
      "k = 5：\n",
      "disgust:0.17754 fear:0.26132 anger:0.28459 surprise:0.34263 sad:0.33851 joy:0.32733 \n",
      "average:0.28865\n",
      "k = 6：\n",
      "disgust:0.19088 fear:0.27623 anger:0.24732 surprise:0.33194 sad:0.34177 joy:0.33144 \n",
      "average:0.28660\n",
      "k = 7：\n",
      "disgust:0.20926 fear:0.28102 anger:0.24311 surprise:0.33335 sad:0.34708 joy:0.31564 \n",
      "average:0.28824\n",
      "k = 8：\n",
      "disgust:0.19627 fear:0.27130 anger:0.23438 surprise:0.32511 sad:0.35790 joy:0.32447 \n",
      "average:0.28490\n",
      "k = 9：\n",
      "disgust:0.21269 fear:0.27335 anger:0.24752 surprise:0.32384 sad:0.35081 joy:0.32749 \n",
      "average:0.28928\n",
      "k =10：\n",
      "disgust:0.19288 fear:0.27461 anger:0.24724 surprise:0.31550 sad:0.33523 joy:0.31900 \n",
      "average:0.28074\n",
      "k =11：\n",
      "disgust:0.18964 fear:0.29131 anger:0.23958 surprise:0.30956 sad:0.32721 joy:0.31837 \n",
      "average:0.27928\n",
      "k =12：\n",
      "disgust:0.16947 fear:0.28306 anger:0.24940 surprise:0.30983 sad:0.31694 joy:0.31065 \n",
      "average:0.27323\n",
      "k =13：\n",
      "disgust:0.18577 fear:0.28743 anger:0.26604 surprise:0.29785 sad:0.32257 joy:0.32204 \n",
      "average:0.28028\n",
      "k =14：\n",
      "disgust:0.17002 fear:0.29364 anger:0.26618 surprise:0.30549 sad:0.32675 joy:0.32791 \n",
      "average:0.28167\n",
      "k =15：\n",
      "disgust:0.16540 fear:0.29973 anger:0.26534 surprise:0.31255 sad:0.32741 joy:0.31663 \n",
      "average:0.28118\n",
      "k =16：\n",
      "disgust:0.17166 fear:0.28516 anger:0.27079 surprise:0.31289 sad:0.33741 joy:0.31690 \n",
      "average:0.28247\n",
      "k =17：\n",
      "disgust:0.17032 fear:0.27181 anger:0.27278 surprise:0.31076 sad:0.33908 joy:0.29951 \n",
      "average:0.27738\n",
      "k =18：\n",
      "disgust:0.18575 fear:0.26559 anger:0.27210 surprise:0.30462 sad:0.34055 joy:0.30999 \n",
      "average:0.27977\n",
      "k =19：\n",
      "disgust:0.18367 fear:0.26340 anger:0.27021 surprise:0.30281 sad:0.33211 joy:0.31722 \n",
      "average:0.27824\n",
      "k =20：\n",
      "disgust:0.20621 fear:0.27713 anger:0.27287 surprise:0.30982 sad:0.33821 joy:0.31765 \n",
      "average:0.28698\n",
      "k =21：\n",
      "disgust:0.19134 fear:0.27912 anger:0.27795 surprise:0.29953 sad:0.34413 joy:0.32254 \n",
      "average:0.28577\n",
      "k =22：\n",
      "disgust:0.21967 fear:0.27313 anger:0.28345 surprise:0.28847 sad:0.33642 joy:0.32631 \n",
      "average:0.28791\n",
      "k =23：\n",
      "disgust:0.22100 fear:0.26195 anger:0.29026 surprise:0.29078 sad:0.32646 joy:0.32644 \n",
      "average:0.28615\n",
      "k =24：\n",
      "disgust:0.22382 fear:0.26590 anger:0.29625 surprise:0.28852 sad:0.31377 joy:0.32572 \n",
      "average:0.28566\n",
      "k =25：\n",
      "disgust:0.21399 fear:0.26786 anger:0.28809 surprise:0.28388 sad:0.32208 joy:0.31883 \n",
      "average:0.28246\n",
      "k =26：\n",
      "disgust:0.21410 fear:0.26656 anger:0.28437 surprise:0.29108 sad:0.31328 joy:0.31250 \n",
      "average:0.28031\n",
      "k =27：\n",
      "disgust:0.21882 fear:0.26169 anger:0.28700 surprise:0.28846 sad:0.30809 joy:0.31379 \n",
      "average:0.27964\n",
      "k =28：\n",
      "disgust:0.21160 fear:0.26333 anger:0.28639 surprise:0.28145 sad:0.30255 joy:0.31633 \n",
      "average:0.27694\n",
      "k =29：\n",
      "disgust:0.21019 fear:0.25321 anger:0.28122 surprise:0.27712 sad:0.28511 joy:0.30134 \n",
      "average:0.26803\n",
      "k =30：\n",
      "disgust:0.21913 fear:0.26201 anger:0.27731 surprise:0.27046 sad:0.27149 joy:0.29420 \n",
      "average:0.26577\n",
      "k =31：\n",
      "disgust:0.22719 fear:0.24256 anger:0.28155 surprise:0.26815 sad:0.27209 joy:0.28262 \n",
      "average:0.26236\n",
      "k =32：\n",
      "disgust:0.21553 fear:0.23836 anger:0.28311 surprise:0.26966 sad:0.27145 joy:0.27819 \n",
      "average:0.25938\n",
      "k =33：\n",
      "disgust:0.21268 fear:0.24321 anger:0.27654 surprise:0.26488 sad:0.26678 joy:0.27931 \n",
      "average:0.25723\n",
      "k =34：\n",
      "disgust:0.21120 fear:0.24191 anger:0.27545 surprise:0.26684 sad:0.26155 joy:0.27552 \n",
      "average:0.25541\n",
      "k =35：\n",
      "disgust:0.20637 fear:0.24336 anger:0.27306 surprise:0.26691 sad:0.26872 joy:0.27324 \n",
      "average:0.25528\n",
      "k =36：\n",
      "disgust:0.19254 fear:0.23706 anger:0.27030 surprise:0.26356 sad:0.26836 joy:0.27034 \n",
      "average:0.25036\n",
      "k =37：\n",
      "disgust:0.19890 fear:0.22780 anger:0.26768 surprise:0.26318 sad:0.25999 joy:0.26775 \n",
      "average:0.24755\n",
      "k =38：\n",
      "disgust:0.19446 fear:0.22835 anger:0.26538 surprise:0.26584 sad:0.26196 joy:0.27377 \n",
      "average:0.24830\n",
      "k =39：\n",
      "disgust:0.18809 fear:0.22919 anger:0.26343 surprise:0.25839 sad:0.25387 joy:0.26923 \n",
      "average:0.24370\n",
      "k =40：\n",
      "disgust:0.17962 fear:0.22148 anger:0.26457 surprise:0.25227 sad:0.24856 joy:0.26547 \n",
      "average:0.23866\n",
      "k =41：\n",
      "disgust:0.17006 fear:0.21835 anger:0.26415 surprise:0.25287 sad:0.25578 joy:0.26388 \n",
      "average:0.23751\n",
      "k =42：\n",
      "disgust:0.15801 fear:0.21880 anger:0.26097 surprise:0.24771 sad:0.25195 joy:0.26232 \n",
      "average:0.23329\n",
      "k =43：\n",
      "disgust:0.14234 fear:0.21473 anger:0.26562 surprise:0.24707 sad:0.25037 joy:0.26535 \n",
      "average:0.23091\n",
      "k =44：\n",
      "disgust:0.15409 fear:0.21492 anger:0.26659 surprise:0.24348 sad:0.25321 joy:0.26308 \n",
      "average:0.23256\n",
      "k =45：\n",
      "disgust:0.15830 fear:0.21713 anger:0.26703 surprise:0.24651 sad:0.25338 joy:0.26342 \n",
      "average:0.23430\n",
      "k =46：\n",
      "disgust:0.17373 fear:0.21054 anger:0.27107 surprise:0.25346 sad:0.25595 joy:0.26105 \n",
      "average:0.23763\n",
      "k =47：\n",
      "disgust:0.17440 fear:0.20601 anger:0.26483 surprise:0.24243 sad:0.25372 joy:0.26030 \n",
      "average:0.23362\n",
      "k =48：\n",
      "disgust:0.17422 fear:0.20178 anger:0.26568 surprise:0.24070 sad:0.24882 joy:0.26760 \n",
      "average:0.23313\n",
      "k =49：\n",
      "disgust:0.17920 fear:0.20812 anger:0.26922 surprise:0.24406 sad:0.25016 joy:0.27180 \n",
      "average:0.23709\n"
     ]
    }
   ],
   "source": [
    "def run_knn_regress2(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    ansLabel = dict()\n",
    "    for i in validateSet_label2.keys():\n",
    "        ansLabel[i]=[]\n",
    "    for index, wordVector in enumerate(TF_validateSet2):\n",
    "        ans = knn_regress(TF_trainSet2, trainSet_label2, k, wordVector)\n",
    "        ######### nan 值的debug代码#########################\n",
    "#         flag = False\n",
    "#         for i in validateSet_label2.keys():\n",
    "#             if  np.isnan(ans[i]):\n",
    "#                 print('nan value found in %d' % (index))\n",
    "#                 print('terminate..')\n",
    "#                 flag = True\n",
    "#         if flag: break\n",
    "        ########## nan 值的debug代码#########################\n",
    "        for i in ans.keys():\n",
    "            ansLabel[i].append(ans[i])\n",
    "    \n",
    "    print('k =%2d：' % k)\n",
    "    tot = 0\n",
    "    for i in ansLabel.keys():\n",
    "        corr = np.corrcoef(ansLabel[i],validateSet_label2[i])[0,1]\n",
    "        tot += corr\n",
    "        print('%s:%.5f' % (i, corr), end=' ')\n",
    "    print('\\naverage:%.5f' % (tot/len(ansLabel.keys())))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_regress2(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录\n",
    "\n",
    "## 参考资料\n",
    "\n",
    "1.[stackoverflow : how-to-get-indices-of-n-maximum-values-in-a-numpy-array][1]\n",
    "\n",
    "2.[stackoverflow : show-dataframe-as-table-in-ipython-notebook][2]\n",
    "\n",
    "3.[Machine Learning-Normalization][3]\n",
    "\n",
    "4.[为什么一些机器学习模型需要对数据进行归一化？][4]\n",
    "\n",
    "5.[stackexchange : Standardizing some features in K-Means][5]\n",
    "\n",
    "[1]:https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "[2]:https://stackoverflow.com/questions/26873127/show-dataframe-as-table-in-ipython-notebook\n",
    "[3]:http://www.csuldw.com/2015/11/15/2015-11-15%20normalization/?utm_source=tuicool&utm_medium=referral\n",
    "[4]:http://www.cnblogs.com/LBSer/p/4440590.html\n",
    "[5]:https://stats.stackexchange.com/questions/223289/standardizing-some-features-in-k-means/223355#223355\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T11:51:36.355116Z",
     "start_time": "2017-10-12T11:51:36.351113Z"
    }
   },
   "source": [
    "## 相关函数测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **-------------------------------------------平台配置代码--------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:35.790893Z",
     "start_time": "2017-10-17T22:39:35.783887Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# from IPython.display import Image\n",
    "# 其对应的三元顺序表为=Image(\"./images/1.jpg\")\n",
    "# 稀疏矩阵例子为=Image(\"./images/2.jpg\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "596px",
    "left": "0px",
    "right": "916px",
    "top": "106px",
    "width": "356px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
