{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验内容\n",
    "\n",
    "```\n",
    "data\n",
    "├─classification_dataset\n",
    "│      15351234_Sample_KNN_classification.csv\n",
    "│      15351234_Sample_NB_classification.csv\n",
    "│      test_set.csv\n",
    "│      train_set.csv\n",
    "│      validation_set.csv\n",
    "│\n",
    "└─regression_dataset\n",
    "        15351234_Sample_KNN_regression.csv\n",
    "        15351234_Sample_NB_regression.csv\n",
    "        test_set.csv\n",
    "        train_set.csv\n",
    "        validation_set.csv\n",
    "        validation相关度评估.xlsx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类\n",
    "\n",
    "## 数据预处理及分析\n",
    "\n",
    "\n",
    "### 数据读取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:10:53.615760Z",
     "start_time": "2017-10-12T10:10:53.592744Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = list(df['label'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words (split by space)'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【one line\\'s data preview】:')\n",
    "    display(df.head(1))\n",
    "    #输出所有label的分布\n",
    "    print('【count of all kind of labels】:\\n')\n",
    "    print(df['label'].value_counts())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:10:55.647864Z",
     "start_time": "2017-10-12T10:10:55.623852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe retain trophy with big win</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Words (split by space) label\n",
       "0  europe retain trophy with big win   joy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy         222\n",
      "sad         132\n",
      "surprise    113\n",
      "fear         95\n",
      "anger        41\n",
      "disgust      20\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  2087\n",
      "【number of texts】:  623\n"
     ]
    }
   ],
   "source": [
    "dataPath = '.\\\\data\\\\classification_dataset\\\\'\n",
    "trainSet, trainSet_label, allWords_trainSet = loadDataSet(dataPath+'train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:15:26.261113Z",
     "start_time": "2017-10-12T10:15:26.239593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marijuana helps ease hiv nerve pain study says</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words (split by space)     label\n",
       "0  marijuana helps ease hiv nerve pain study says  surprise"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy         112\n",
      "sad          65\n",
      "fear         54\n",
      "surprise     46\n",
      "anger        21\n",
      "disgust      13\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  1235\n",
      "【number of texts】:  311\n"
     ]
    }
   ],
   "source": [
    "validateSet, validateSet_label, _ = loadDataSet(dataPath+'validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:15:33.699341Z",
     "start_time": "2017-10-12T10:15:33.680313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textid</th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>senator carl krueger thinks ipods can kill you</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   textid                          Words (split by space) label\n",
       "0       1  senator carl krueger thinks ipods can kill you     ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "?    312\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  1273\n",
      "【number of texts】:  312\n"
     ]
    }
   ],
   "source": [
    "testSet, _ , _ = loadDataSet(dataPath+'test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T19:23:29.452507Z",
     "start_time": "2017-10-11T19:23:29.439993Z"
    }
   },
   "source": [
    "### 得到3个数据集的onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T07:55:57.042718Z",
     "start_time": "2017-10-12T07:55:56.172014Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneHot(dataSet, allWords):\n",
    "    '''得到输入数据集的one-hot矩阵'''\n",
    "    oneHot=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        oneHot.append([])\n",
    "        for word in allWords:\n",
    "            if word in doc:\n",
    "                oneHot[index].append(1)\n",
    "            else: \n",
    "                oneHot[index].append(0)\n",
    "    return oneHot\n",
    "\n",
    "#得到训练集、验证集、测试集的onehot矩阵\n",
    "oneHot_trainSet = getOneHot(trainSet, allWords_trainSet)\n",
    "oneHot_validateSet = getOneHot(validateSet, allWords_trainSet)\n",
    "oneHot_testSet = getOneHot(testSet, allWords_trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn分类算法\n",
    "\n",
    "### 分类函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T07:56:00.505072Z",
     "start_time": "2017-10-12T07:56:00.481067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_classify(dataSet, labels, k, inputVector):\n",
    "    '''使用knn对输入的向量进行分类，使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    #得到 K个近邻的下标\n",
    "    kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "    #返回分类结果\n",
    "    return Counter(np.array(labels)[kNeighborsIndex]).most_common(1)[0][0]\n",
    "\n",
    "knn_classify([[1,1,0,0],\n",
    "              [0,1,1,1],\n",
    "              [1,0,0,1]],['positive','negative','positive'], 3, [0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T08:50:52.270142Z",
     "start_time": "2017-10-12T08:50:52.242140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'manhattan'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'cosine'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'euclidean'\n",
    "'manhattan'\n",
    "'cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:14:07.530246Z",
     "start_time": "2017-10-11T23:49:44.026052Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 : accuray: 37.29904%\n",
      "k =  2 : accuray: 25.72347%\n",
      "k =  3 : accuray: 32.79743%\n",
      "k =  4 : accuray: 30.54662%\n",
      "k =  5 : accuray: 32.79743%\n",
      "k =  6 : accuray: 32.47588%\n",
      "k =  7 : accuray: 34.08360%\n",
      "k =  8 : accuray: 36.01286%\n",
      "k =  9 : accuray: 36.33441%\n",
      "k = 10 : accuray: 38.26367%\n",
      "k = 11 : accuray: 38.58521%\n",
      "k = 12 : accuray: 39.54984%\n",
      "k = 13 : accuray: 39.22830%\n",
      "k = 14 : accuray: 42.12219%\n",
      "k = 15 : accuray: 40.19293%\n",
      "k = 16 : accuray: 41.15756%\n",
      "k = 17 : accuray: 38.90675%\n",
      "k = 18 : accuray: 37.94212%\n",
      "k = 19 : accuray: 37.29904%\n",
      "k = 20 : accuray: 38.58521%\n",
      "k = 21 : accuray: 38.58521%\n",
      "k = 22 : accuray: 38.90675%\n",
      "k = 23 : accuray: 37.62058%\n",
      "k = 24 : accuray: 37.94212%\n",
      "k = 25 : accuray: 37.62058%\n",
      "k = 26 : accuray: 37.62058%\n",
      "k = 27 : accuray: 37.62058%\n",
      "k = 28 : accuray: 37.62058%\n",
      "k = 29 : accuray: 37.94212%\n",
      "k = 30 : accuray: 37.29904%\n",
      "k = 31 : accuray: 37.29904%\n",
      "k = 32 : accuray: 37.62058%\n",
      "k = 33 : accuray: 38.90675%\n",
      "k = 34 : accuray: 39.54984%\n",
      "k = 35 : accuray: 39.54984%\n",
      "k = 36 : accuray: 39.54984%\n",
      "k = 37 : accuray: 38.90675%\n",
      "k = 38 : accuray: 38.26367%\n",
      "k = 39 : accuray: 38.58521%\n",
      "k = 40 : accuray: 38.90675%\n",
      "k = 41 : accuray: 38.90675%\n",
      "k = 42 : accuray: 38.58521%\n",
      "k = 43 : accuray: 38.90675%\n",
      "k = 44 : accuray: 37.94212%\n",
      "k = 45 : accuray: 37.62058%\n",
      "k = 46 : accuray: 37.62058%\n",
      "k = 47 : accuray: 37.62058%\n",
      "k = 48 : accuray: 37.29904%\n",
      "k = 49 : accuray: 37.29904%\n"
     ]
    }
   ],
   "source": [
    "def run_knn_classify(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    hitNum = 0\n",
    "    for index, wordVector in enumerate(dataSet):\n",
    "        ans = knn_classify(oneHot_trainSet, trainSet_label, k, wordVector)\n",
    "        if  ans == validateSet_label[index]:\n",
    "            hitNum +=1\n",
    "    print(\"k = %2d : accuracy: %.5f%%\" % (k, 100*hitNum/len(oneHot_validateSet)))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_classify(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T08:13:23.165843Z",
     "start_time": "2017-10-12T08:12:54.944529Z"
    }
   },
   "outputs": [],
   "source": [
    "outputFileName = \"15352220_linzecheng_KNN_classification.csv\"\n",
    "bestK = 14\n",
    "textid_and_label = []\n",
    "for index, wordVector in enumerate(oneHot_testSet):\n",
    "        ans = knn_classify(oneHot_trainSet, trainSet_label, bestK, wordVector)\n",
    "        textid_and_label.append((index+1, ans))\n",
    "        \n",
    "res = pd.DataFrame(textid_and_label, columns=['textid','label'])\n",
    "res.to_csv(outputFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T08:16:13.950284Z",
     "start_time": "2017-10-12T08:16:13.934282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         259\n",
       "fear         32\n",
       "sad          20\n",
       "surprise      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归\n",
    "\n",
    "## 数据预处理及分析\n",
    "\n",
    "### 数据读取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:10:41.346504Z",
     "start_time": "2017-10-12T10:10:41.306469Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet2(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = dict()\n",
    "    label['anger'] = list(df['anger'].values)  \n",
    "    label['disgust'] = list(df['disgust'].values)  \n",
    "    label['fear'] = list(df['fear'].values)\n",
    "    label['joy'] = list(df['joy'].values)  \n",
    "    label['sad'] = list(df['sad'].values)  \n",
    "    label['surprise'] = list(df['surprise'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words (split by space)'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【one line\\'s data preview】:')\n",
    "    display(df.head(1))\n",
    "    #输出所有情感值的一些统计数据\n",
    "    print('【some summary statistics of labels】:')\n",
    "    print(df[['anger','disgust','fear','joy','sad','surprise']].describe())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:13:51.631743Z",
     "start_time": "2017-10-12T10:13:51.587689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe retain trophy with big win</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Words (split by space)  anger  disgust  fear     joy  sad  \\\n",
       "0  europe retain trophy with big win    0.0      0.0   0.0  0.8721  0.0   \n",
       "\n",
       "   surprise  \n",
       "0    0.1279  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "            anger     disgust        fear         joy         sad    surprise\n",
      "count  623.000000  623.000000  623.000000  623.000000  623.000000  623.000000\n",
      "mean     0.086573    0.052949    0.157176    0.281344    0.191442    0.230517\n",
      "std      0.123334    0.090709    0.174959    0.317420    0.206464    0.199993\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.090100\n",
      "50%      0.022700    0.000000    0.115400    0.130800    0.142900    0.176500\n",
      "75%      0.144950    0.083300    0.255450    0.566950    0.293450    0.326750\n",
      "max      0.753400    0.571400    0.895800    1.000000    1.000000    1.000000\n",
      "【number of all words】:  2087\n",
      "【number of texts】:  623\n"
     ]
    }
   ],
   "source": [
    "dataPath2 = '.\\\\data\\\\regression_dataset\\\\'\n",
    "trainSet2, trainSet_label2, allWords_trainSet2 = loadDataSet2(dataPath2+'train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:13:53.442657Z",
     "start_time": "2017-10-12T10:13:53.396623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marijuana helps ease hiv nerve pain study says</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.5537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words (split by space)  anger  disgust    fear  \\\n",
       "0  marijuana helps ease hiv nerve pain study says    0.0      0.0  0.0744   \n",
       "\n",
       "      joy     sad  surprise  \n",
       "0  0.2727  0.0992    0.5537  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "            anger     disgust        fear         joy         sad    surprise\n",
      "count  311.000000  311.000000  311.000000  311.000000  311.000000  311.000000\n",
      "mean     0.085478    0.062534    0.151173    0.287755    0.194680    0.218382\n",
      "std      0.125672    0.110057    0.175016    0.310162    0.208836    0.189515\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.073650\n",
      "50%      0.012200    0.000000    0.088900    0.177800    0.138900    0.181800\n",
      "75%      0.150600    0.098400    0.245550    0.553650    0.300900    0.320900\n",
      "max      0.777800    0.785700    0.815400    1.000000    0.903200    1.000000\n",
      "【number of all words】:  1235\n",
      "【number of texts】:  311\n"
     ]
    }
   ],
   "source": [
    "validateSet2, validateSet_label2, _ = loadDataSet2(dataPath2+'validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:27:09.293797Z",
     "start_time": "2017-10-12T10:27:09.249260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textid</th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>senator carl krueger thinks ipods can kill you</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   textid                          Words (split by space) anger disgust fear  \\\n",
       "0       1  senator carl krueger thinks ipods can kill you     ?       ?    ?   \n",
       "\n",
       "  joy sad surprise  \n",
       "0   ?   ?        ?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "       anger disgust fear  joy  sad surprise\n",
      "count    312     312  312  312  312      312\n",
      "unique     1       1    1    1    1        1\n",
      "top        ?       ?    ?    ?    ?        ?\n",
      "freq     312     312  312  312  312      312\n",
      "【number of all words】:  1273\n",
      "【number of texts】:  312\n"
     ]
    }
   ],
   "source": [
    "testSet2, _ , _ = loadDataSet2(dataPath2+'test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  得到3个数据集的onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T10:28:06.536229Z",
     "start_time": "2017-10-12T10:28:05.706121Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#得到训练集、验证集、测试集的onehot矩阵\n",
    "oneHot_trainSet2 = getOneHot(trainSet2, allWords_trainSet2)\n",
    "oneHot_validateSet2 = getOneHot(validateSet2, allWords_trainSet2)\n",
    "oneHot_testSet2 = getOneHot(testSet2, allWords_trainSet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn回归算法\n",
    "\n",
    "### 权值归一化函数实现\n",
    "\n",
    "不同意PPT里的权值归一化的说法，下面这个函数暂时不会使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T21:38:44.674179Z",
     "start_time": "2017-10-12T21:38:44.608632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.22474487,  0.        ,  1.22474487])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weightNormalize(weight, method='min-max'):\n",
    "    '''权值归一化函数，输入权值类型为numpy.array'''\n",
    "    if len(weight) == 1:\n",
    "        return weight\n",
    "    elif method == 'min-max':\n",
    "        return (weight-weight.min())/(weight.max()-weight.min())\n",
    "    elif method == 'z-score':\n",
    "        return (weight-weight.mean())/weight.std()\n",
    "\n",
    "weightNormalize(np.array([1,2,3]))\n",
    "weightNormalize(np.array([1,2,3]),'z-score')\n",
    "\n",
    "weightNormalize(np.array([5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T22:33:32.537347Z",
     "start_time": "2017-10-12T22:33:32.316999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0.078309831097408536,\n",
       " 'disgust': 0.10168682639590204,\n",
       " 'fear': 0.45530074296635226,\n",
       " 'joy': 0.064714169422640258,\n",
       " 'sad': 0.19830160372179506,\n",
       " 'surprise': 0.10168682639590204}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_regress(dataSet, labels, k, inputVector):\n",
    "    '''使用knn对输入的向量进行回归，先默认使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    \n",
    "    #要输出的label\n",
    "    outputLabel = dict() \n",
    "    #label中每个分量的概率值\n",
    "    probs = np.zeros((1,len(labels.keys())))\n",
    "    #若距离中存在0，则直接拷贝距离为0对应元素的label\n",
    "    if 0 in distances:\n",
    "        zeroIndex = distances.tolist().index(0)\n",
    "        for index, i in enumerate(labels.keys()):\n",
    "            outputLabel[i] = labels[i][zeroIndex]\n",
    "            probs[0,index] = outputLabel[i]\n",
    "    else:\n",
    "        #得到 K个近邻的下标\n",
    "        kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "        #用label值除以距离并求和，更新输出的 label\n",
    "        weight = 1/distances[kNeighborsIndex]\n",
    "        \n",
    "        for index, i in enumerate(labels.keys()):\n",
    "            #得到 K个近邻的标签\n",
    "            topKLabel = np.array(labels[i])[kNeighborsIndex]\n",
    "            outputLabel[i] = (topKLabel*weight).sum()\n",
    "            #保存当前概率值，用于后续归一化\n",
    "            probs[0,index] = outputLabel[i]\n",
    "    \n",
    "    #将所有概率值的和调整为1\n",
    "    for i in outputLabel.keys():\n",
    "        outputLabel[i] = outputLabel[i] / probs.sum()\n",
    "    return outputLabel\n",
    "\n",
    "# knn_regress([[1,1,0,0],[0,1,1,1],[1,0,0,1]],\n",
    "#             {'happy':[0.4,0.5,0.1], \n",
    "#              'sad':[0.2,0.3,0.2], \n",
    "#              'calm':[0.1,0.25,0.8]}, 2, [0,1,1,0])\n",
    "\n",
    "a = oneHot_validateSet2[0]\n",
    "knn_regress(oneHot_trainSet2, trainSet_label2, 2, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T22:28:37.292639Z",
     "start_time": "2017-10-12T21:56:25.806727Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1\n",
      "joy:0.22842 surprise:0.26274 fear:0.20246 sad:0.23562 disgust:0.06974 anger:0.17641 \n",
      "average:0.19590\n",
      "k = 2\n",
      "joy:0.21322 surprise:0.26072 fear:0.18911 sad:0.25692 disgust:0.15061 anger:0.21899 \n",
      "average:0.21493\n",
      "k = 3\n",
      "joy:0.36226 surprise:0.30836 fear:0.30815 sad:0.27993 disgust:0.17402 anger:0.26653 \n",
      "average:0.28321\n",
      "k = 4\n",
      "joy:0.26868 surprise:0.29273 fear:0.24991 sad:0.30863 disgust:0.13378 anger:0.24317 \n",
      "average:0.24948\n",
      "k = 5\n",
      "joy:0.28134 surprise:0.26604 fear:0.27038 sad:0.29301 disgust:0.19281 anger:0.21913 \n",
      "average:0.25378\n",
      "k = 6\n",
      "joy:0.26018 surprise:0.26954 fear:0.25520 sad:0.29588 disgust:0.16202 anger:0.21047 \n",
      "average:0.24221\n",
      "k = 7\n",
      "joy:0.24262 surprise:0.25867 fear:0.24043 sad:0.29207 disgust:0.12813 anger:0.21039 \n",
      "average:0.22872\n",
      "k = 8\n",
      "joy:0.27573 surprise:0.25542 fear:0.27874 sad:0.31438 disgust:0.14025 anger:0.18576 \n",
      "average:0.24171\n",
      "k = 9\n",
      "joy:0.28284 surprise:0.26718 fear:0.28126 sad:0.33442 disgust:0.11200 anger:0.19155 \n",
      "average:0.24487\n",
      "k =10\n",
      "joy:0.27750 surprise:0.26591 fear:0.26628 sad:0.34350 disgust:0.15206 anger:0.18686 \n",
      "average:0.24868\n",
      "k =11\n",
      "joy:0.26953 surprise:0.24546 fear:0.25980 sad:0.34571 disgust:0.12824 anger:0.17951 \n",
      "average:0.23804\n",
      "k =12\n",
      "joy:0.28046 surprise:0.24399 fear:0.26955 sad:0.34849 disgust:0.14151 anger:0.18881 \n",
      "average:0.24547\n",
      "k =13\n",
      "joy:0.31202 surprise:0.25521 fear:0.28078 sad:0.35118 disgust:0.15699 anger:0.21008 \n",
      "average:0.26104\n",
      "k =14\n",
      "joy:0.30946 surprise:0.25003 fear:0.29943 sad:0.33760 disgust:0.18592 anger:0.22299 \n",
      "average:0.26757\n",
      "k =15\n",
      "joy:0.31703 surprise:0.25662 fear:0.28789 sad:0.32626 disgust:0.19166 anger:0.21309 \n",
      "average:0.26542\n",
      "k =16\n",
      "joy:0.30519 surprise:0.24815 fear:0.27267 sad:0.32196 disgust:0.19068 anger:0.22074 \n",
      "average:0.25990\n",
      "k =17\n",
      "joy:0.31223 surprise:0.26006 fear:0.26937 sad:0.31577 disgust:0.18269 anger:0.21286 \n",
      "average:0.25883\n",
      "k =18\n",
      "joy:0.31425 surprise:0.24215 fear:0.26309 sad:0.31193 disgust:0.17924 anger:0.21945 \n",
      "average:0.25502\n",
      "k =19\n",
      "joy:0.30762 surprise:0.24160 fear:0.25007 sad:0.30754 disgust:0.15485 anger:0.22592 \n",
      "average:0.24793\n",
      "k =20\n",
      "joy:0.31281 surprise:0.23718 fear:0.25300 sad:0.31291 disgust:0.13443 anger:0.22408 \n",
      "average:0.24573\n",
      "k =21\n",
      "joy:0.32010 surprise:0.24695 fear:0.26639 sad:0.32097 disgust:0.14102 anger:0.22968 \n",
      "average:0.25419\n",
      "k =22\n",
      "joy:0.32055 surprise:0.24429 fear:0.26379 sad:0.32919 disgust:0.12080 anger:0.23391 \n",
      "average:0.25209\n",
      "k =23\n",
      "joy:0.32146 surprise:0.24794 fear:0.25870 sad:0.32114 disgust:0.12257 anger:0.24248 \n",
      "average:0.25238\n",
      "k =24\n",
      "joy:0.33274 surprise:0.25786 fear:0.27733 sad:0.32211 disgust:0.14830 anger:0.23619 \n",
      "average:0.26242\n",
      "k =25\n",
      "joy:0.33445 surprise:0.25633 fear:0.27255 sad:0.32527 disgust:0.15019 anger:0.23636 \n",
      "average:0.26253\n",
      "k =26\n",
      "joy:0.34308 surprise:0.26782 fear:0.27540 sad:0.33147 disgust:0.14121 anger:0.23594 \n",
      "average:0.26582\n",
      "k =27\n",
      "joy:0.33116 surprise:0.26349 fear:0.26627 sad:0.31184 disgust:0.14504 anger:0.22986 \n",
      "average:0.25794\n",
      "k =28\n",
      "joy:0.32866 surprise:0.26108 fear:0.26616 sad:0.30219 disgust:0.16124 anger:0.23604 \n",
      "average:0.25923\n",
      "k =29\n",
      "joy:0.31572 surprise:0.26290 fear:0.26311 sad:0.29091 disgust:0.15080 anger:0.23963 \n",
      "average:0.25385\n",
      "k =30\n",
      "joy:0.30991 surprise:0.26024 fear:0.25732 sad:0.28949 disgust:0.15350 anger:0.23585 \n",
      "average:0.25105\n",
      "k =31\n",
      "joy:0.31587 surprise:0.24857 fear:0.25591 sad:0.28702 disgust:0.14730 anger:0.23033 \n",
      "average:0.24750\n",
      "k =32\n",
      "joy:0.31065 surprise:0.24594 fear:0.24433 sad:0.29787 disgust:0.16066 anger:0.23428 \n",
      "average:0.24896\n",
      "k =33\n",
      "joy:0.30665 surprise:0.24124 fear:0.23734 sad:0.29950 disgust:0.15391 anger:0.23692 \n",
      "average:0.24593\n",
      "k =34\n",
      "joy:0.30805 surprise:0.25031 fear:0.25264 sad:0.29024 disgust:0.16472 anger:0.24193 \n",
      "average:0.25132\n",
      "k =35\n",
      "joy:0.30563 surprise:0.24986 fear:0.26561 sad:0.29322 disgust:0.17361 anger:0.24603 \n",
      "average:0.25566\n",
      "k =36\n",
      "joy:0.30541 surprise:0.23955 fear:0.26346 sad:0.28725 disgust:0.17296 anger:0.24368 \n",
      "average:0.25205\n",
      "k =37\n",
      "joy:0.30716 surprise:0.23990 fear:0.26398 sad:0.28936 disgust:0.16091 anger:0.23839 \n",
      "average:0.24995\n",
      "k =38\n",
      "joy:0.30261 surprise:0.24049 fear:0.26163 sad:0.28473 disgust:0.16478 anger:0.23876 \n",
      "average:0.24883\n",
      "k =39\n",
      "joy:0.29745 surprise:0.23881 fear:0.24709 sad:0.29003 disgust:0.15652 anger:0.24602 \n",
      "average:0.24599\n",
      "k =40\n",
      "joy:0.29230 surprise:0.23853 fear:0.23969 sad:0.28543 disgust:0.15903 anger:0.24868 \n",
      "average:0.24394\n",
      "k =41\n",
      "joy:0.29034 surprise:0.24020 fear:0.24280 sad:0.27564 disgust:0.15780 anger:0.25370 \n",
      "average:0.24342\n",
      "k =42\n",
      "joy:0.29154 surprise:0.23394 fear:0.24671 sad:0.27203 disgust:0.17026 anger:0.25231 \n",
      "average:0.24447\n",
      "k =43\n",
      "joy:0.29012 surprise:0.23588 fear:0.24951 sad:0.26816 disgust:0.17064 anger:0.25317 \n",
      "average:0.24458\n",
      "k =44\n",
      "joy:0.29523 surprise:0.24447 fear:0.25238 sad:0.27188 disgust:0.18097 anger:0.25529 \n",
      "average:0.25004\n",
      "k =45\n",
      "joy:0.30079 surprise:0.24294 fear:0.24890 sad:0.27385 disgust:0.19048 anger:0.25556 \n",
      "average:0.25209\n",
      "k =46\n",
      "joy:0.30153 surprise:0.24216 fear:0.25102 sad:0.27631 disgust:0.18601 anger:0.25751 \n",
      "average:0.25242\n",
      "k =47\n",
      "joy:0.29542 surprise:0.24232 fear:0.25015 sad:0.27289 disgust:0.18989 anger:0.25835 \n",
      "average:0.25150\n",
      "k =48\n",
      "joy:0.29253 surprise:0.23792 fear:0.24237 sad:0.27247 disgust:0.19333 anger:0.25924 \n",
      "average:0.24964\n",
      "k =49\n",
      "joy:0.29574 surprise:0.24021 fear:0.24596 sad:0.27284 disgust:0.18943 anger:0.25600 \n",
      "average:0.25003\n"
     ]
    }
   ],
   "source": [
    "def run_knn_regress(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    ansLabel = dict()\n",
    "    for i in validateSet_label2.keys():\n",
    "        ansLabel[i]=[]\n",
    "    for index, wordVector in enumerate(oneHot_validateSet2):\n",
    "        ans = knn_regress(oneHot_trainSet2, trainSet_label2, k, wordVector)\n",
    "        ######### nan 值的debug代码#########################\n",
    "#         flag = False\n",
    "#         for i in validateSet_label2.keys():\n",
    "#             if  np.isnan(ans[i]):\n",
    "#                 print('nan value found in %d' % (index))\n",
    "#                 print('terminate..')\n",
    "#                 flag = True\n",
    "#         if flag: break\n",
    "        ########## nan 值的debug代码#########################\n",
    "        for i in ans.keys():\n",
    "            ansLabel[i].append(ans[i])\n",
    "    \n",
    "    print('k =%2d：' % k)\n",
    "    tot = 0\n",
    "    for i in ansLabel.keys():\n",
    "        corr = np.corrcoef(ansLabel[i],validateSet_label2[i])[0,1]\n",
    "        tot += corr\n",
    "        print('%s:%.5f' % (i, corr), end=' ')\n",
    "    print('\\naverage:%.5f' % (tot/len(ansLabel.keys())))\n",
    "for k in range(1,50):\n",
    "    run_knn_regress(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录\n",
    "\n",
    "## 参考资料\n",
    "\n",
    "1.[stackoverflow : how-to-get-indices-of-n-maximum-values-in-a-numpy-array][1]\n",
    "\n",
    "2.[stackoverflow : show-dataframe-as-table-in-ipython-notebook][2]\n",
    "\n",
    "3.[Machine Learning-Normalization][3]\n",
    "\n",
    "4.[为什么一些机器学习模型需要对数据进行归一化？][4]\n",
    "\n",
    "5.[stackexchange : Standardizing some features in K-Means][5]\n",
    "\n",
    "[1]:https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "[2]:https://stackoverflow.com/questions/26873127/show-dataframe-as-table-in-ipython-notebook\n",
    "[3]:http://www.csuldw.com/2015/11/15/2015-11-15%20normalization/?utm_source=tuicool&utm_medium=referral\n",
    "[4]:http://www.cnblogs.com/LBSer/p/4440590.html\n",
    "[5]:https://stats.stackexchange.com/questions/223289/standardizing-some-features-in-k-means/223355#223355\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T11:51:36.355116Z",
     "start_time": "2017-10-12T11:51:36.351113Z"
    }
   },
   "source": [
    "## 相关函数测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **-------------------------------------------平台配置代码--------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T07:55:32.309085Z",
     "start_time": "2017-10-12T07:55:32.297083Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# from IPython.display import Image\n",
    "# 其对应的三元顺序表为=Image(\"./images/1.jpg\")\n",
    "# 稀疏矩阵例子为=Image(\"./images/2.jpg\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "636px",
    "left": "0px",
    "right": "916px",
    "top": "66px",
    "width": "356px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
