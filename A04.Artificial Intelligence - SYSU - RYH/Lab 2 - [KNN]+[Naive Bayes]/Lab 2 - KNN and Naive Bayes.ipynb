{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验内容\n",
    "\n",
    "```\n",
    "data\n",
    "├─classification_dataset\n",
    "│      15351234_Sample_KNN_classification.csv\n",
    "│      15351234_Sample_NB_classification.csv\n",
    "│      test_set.csv\n",
    "│      train_set.csv\n",
    "│      validation_set.csv\n",
    "│\n",
    "└─regression_dataset\n",
    "        15351234_Sample_KNN_regression.csv\n",
    "        15351234_Sample_NB_regression.csv\n",
    "        test_set.csv\n",
    "        train_set.csv\n",
    "        validation_set.csv\n",
    "        validation相关度评估.xlsx\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类\n",
    "\n",
    "## 数据预处理及分析\n",
    "\n",
    "\n",
    "### 数据读取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.106112Z",
     "start_time": "2017-10-17T22:39:46.081095Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = list(df['label'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words (split by space)'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【one line\\'s data preview】:')\n",
    "    display(df.head(1))\n",
    "    #输出所有label的分布\n",
    "    print('【count of all kind of labels】:\\n')\n",
    "    print(df['label'].value_counts())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.288181Z",
     "start_time": "2017-10-17T22:39:46.110114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe retain trophy with big win</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Words (split by space) label\n",
       "0  europe retain trophy with big win   joy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy         222\n",
      "sad         132\n",
      "surprise    113\n",
      "fear         95\n",
      "anger        41\n",
      "disgust      20\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  2087\n",
      "【number of texts】:  623\n"
     ]
    }
   ],
   "source": [
    "dataPath = '.\\\\data\\\\classification_dataset\\\\'\n",
    "trainSet, trainSet_label, allWords_trainSet = loadDataSet(dataPath+'train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T10:47:48.273599Z",
     "start_time": "2017-10-18T10:47:48.233598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marijuana helps ease hiv nerve pain study says</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words (split by space)     label\n",
       "0  marijuana helps ease hiv nerve pain study says  surprise"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy         112\n",
      "sad          65\n",
      "fear         54\n",
      "surprise     46\n",
      "anger        21\n",
      "disgust      13\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  1235\n",
      "【number of texts】:  311\n"
     ]
    }
   ],
   "source": [
    "validatePath = dataPath+'validation_set.csv'\n",
    "validateSet, validateSet_label, allWords_validateSet = loadDataSet(validatePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.623420Z",
     "start_time": "2017-10-17T22:39:46.417272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textid</th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>senator carl krueger thinks ipods can kill you</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   textid                          Words (split by space) label\n",
       "0       1  senator carl krueger thinks ipods can kill you     ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "?    312\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  1273\n",
      "【number of texts】:  312\n"
     ]
    }
   ],
   "source": [
    "testSet, _ , allWords_testSet = loadDataSet(dataPath+'test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并三个数据集的所有不重复的词，供后续得到onehot和TF矩阵使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:46.649438Z",
     "start_time": "2017-10-17T22:39:46.627423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 2771)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords_train_validate = list(set(allWords_trainSet).union(allWords_validateSet))\n",
    "allWords_train_test = list(set(allWords_trainSet).union(allWords_testSet))\n",
    "len(allWords_train_validate), len(allWords_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn分类算法\n",
    "\n",
    "### 得到3个数据集的onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T08:40:19.209110Z",
     "start_time": "2017-10-18T08:40:16.993450Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOneHot(dataSet, allWords):\n",
    "    '''得到输入数据集的one-hot矩阵'''\n",
    "    oneHot=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        oneHot.append([])\n",
    "        for word in allWords:\n",
    "            if word in doc:\n",
    "                oneHot[index].append(1)\n",
    "            else: \n",
    "                oneHot[index].append(0)\n",
    "    return oneHot\n",
    "\n",
    "#得到训练集、验证集、测试集的onehot矩阵\n",
    "oneHot_trainSet = getOneHot(trainSet, allWords_train_validate)\n",
    "oneHot_validateSet = getOneHot(validateSet, allWords_train_validate)\n",
    "\n",
    "oneHot_trainSet_ = getOneHot(trainSet, allWords_train_test)\n",
    "oneHot_testSet = getOneHot(testSet, allWords_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到3个数据集的TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T08:41:02.426072Z",
     "start_time": "2017-10-18T08:40:59.921383Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    TF=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(doc)\n",
    "        for word in allWords:\n",
    "            TF[index].append(wordCounter.get(word,0)/len(doc))\n",
    "    return TF\n",
    "\n",
    "#得到训练集、验证集、测试集的TF矩阵\n",
    "TF_trainSet = getTF(trainSet, allWords_train_validate)\n",
    "TF_validateSet = getTF(validateSet, allWords_train_validate)\n",
    "\n",
    "TF_trainSet_ = getTF(trainSet, allWords_train_test)\n",
    "TF_testSet = getTF(testSet, allWords_train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:34:12.320822Z",
     "start_time": "2017-10-13T13:34:12.286283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_classify(dataSet, labels, k, inputVector):\n",
    "    '''使用knn对输入的向量进行分类，使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    #得到 K个近邻的下标\n",
    "    kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "    #返回分类结果\n",
    "    return Counter(np.array(labels)[kNeighborsIndex]).most_common(1)[0][0]\n",
    "\n",
    "knn_classify([[1,1,0,0],\n",
    "              [0,1,1,1],\n",
    "              [1,0,0,1]],['positive','negative','positive'], 3, [0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T08:50:52.270142Z",
     "start_time": "2017-10-12T08:50:52.242140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'euclidean'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'manhattan'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'cosine'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'euclidean'\n",
    "'manhattan'\n",
    "'cosine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参\n",
    "#### 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T16:39:14.409360Z",
     "start_time": "2017-10-13T15:34:57.939901Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 : accuracy: 37.29904%\n",
      "k =  2 : accuracy: 26.04502%\n",
      "k =  3 : accuracy: 37.62058%\n",
      "k =  4 : accuracy: 32.47588%\n",
      "k =  5 : accuracy: 32.15434%\n",
      "k =  6 : accuracy: 32.47588%\n",
      "k =  7 : accuracy: 36.33441%\n",
      "k =  8 : accuracy: 36.01286%\n",
      "k =  9 : accuracy: 37.29904%\n",
      "k = 10 : accuracy: 39.87138%\n",
      "k = 11 : accuracy: 39.54984%\n",
      "k = 12 : accuracy: 39.22830%\n",
      "k = 13 : accuracy: 40.83601%\n",
      "k = 14 : accuracy: 42.44373%\n",
      "k = 15 : accuracy: 39.54984%\n",
      "k = 16 : accuracy: 41.15756%\n",
      "k = 17 : accuracy: 40.51447%\n",
      "k = 18 : accuracy: 38.58521%\n",
      "k = 19 : accuracy: 38.26367%\n",
      "k = 20 : accuracy: 38.90675%\n",
      "k = 21 : accuracy: 38.58521%\n",
      "k = 22 : accuracy: 38.26367%\n",
      "k = 23 : accuracy: 37.94212%\n",
      "k = 24 : accuracy: 37.94212%\n",
      "k = 25 : accuracy: 37.94212%\n",
      "k = 26 : accuracy: 37.62058%\n",
      "k = 27 : accuracy: 36.97749%\n",
      "k = 28 : accuracy: 37.29904%\n",
      "k = 29 : accuracy: 37.94212%\n",
      "k = 30 : accuracy: 37.29904%\n",
      "k = 31 : accuracy: 36.65595%\n",
      "k = 32 : accuracy: 37.29904%\n",
      "k = 33 : accuracy: 37.94212%\n",
      "k = 34 : accuracy: 38.58521%\n",
      "k = 35 : accuracy: 38.26367%\n",
      "k = 36 : accuracy: 38.90675%\n",
      "k = 37 : accuracy: 38.26367%\n",
      "k = 38 : accuracy: 38.90675%\n",
      "k = 39 : accuracy: 38.90675%\n",
      "k = 40 : accuracy: 39.22830%\n",
      "k = 41 : accuracy: 38.58521%\n",
      "k = 42 : accuracy: 38.58521%\n",
      "k = 43 : accuracy: 38.58521%\n",
      "k = 44 : accuracy: 38.26367%\n",
      "k = 45 : accuracy: 37.62058%\n",
      "k = 46 : accuracy: 37.62058%\n",
      "k = 47 : accuracy: 37.94212%\n",
      "k = 48 : accuracy: 37.29904%\n",
      "k = 49 : accuracy: 37.29904%\n"
     ]
    }
   ],
   "source": [
    "def run_knn_classify1(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    hitNum = 0\n",
    "    for index, wordVector in enumerate(oneHot_validateSet):\n",
    "        ans = knn_classify(oneHot_trainSet, trainSet_label, k, wordVector)\n",
    "        if  ans == validateSet_label[index]:\n",
    "            hitNum +=1\n",
    "    print(\"k = %2d : accuracy: %.5f%%\" % (k, 100*hitNum/len(validateSet)))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_classify1(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T17:01:10.011344Z",
     "start_time": "2017-10-13T16:41:11.519457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  1 : accuracy: 32.47588%\n",
      "k =  2 : accuracy: 25.72347%\n",
      "k =  3 : accuracy: 24.75884%\n",
      "k =  4 : accuracy: 25.08039%\n",
      "k =  5 : accuracy: 23.47267%\n",
      "k =  6 : accuracy: 25.40193%\n",
      "k =  7 : accuracy: 26.36656%\n",
      "k =  8 : accuracy: 27.97428%\n",
      "k =  9 : accuracy: 27.97428%\n",
      "k = 10 : accuracy: 25.72347%\n",
      "k = 11 : accuracy: 26.36656%\n",
      "k = 12 : accuracy: 26.68810%\n",
      "k = 13 : accuracy: 29.26045%\n",
      "k = 14 : accuracy: 29.58199%\n",
      "k = 15 : accuracy: 30.54662%\n",
      "k = 16 : accuracy: 30.86817%\n",
      "k = 17 : accuracy: 28.29582%\n",
      "k = 18 : accuracy: 28.29582%\n",
      "k = 19 : accuracy: 26.36656%\n",
      "k = 20 : accuracy: 27.97428%\n",
      "k = 21 : accuracy: 27.33119%\n",
      "k = 22 : accuracy: 28.29582%\n",
      "k = 23 : accuracy: 28.29582%\n",
      "k = 24 : accuracy: 27.97428%\n",
      "k = 25 : accuracy: 27.97428%\n",
      "k = 26 : accuracy: 28.61736%\n",
      "k = 27 : accuracy: 29.26045%\n",
      "k = 28 : accuracy: 27.65273%\n",
      "k = 29 : accuracy: 28.29582%\n",
      "k = 30 : accuracy: 28.29582%\n",
      "k = 31 : accuracy: 27.65273%\n",
      "k = 32 : accuracy: 27.00965%\n",
      "k = 33 : accuracy: 27.00965%\n",
      "k = 34 : accuracy: 27.00965%\n",
      "k = 35 : accuracy: 27.65273%\n",
      "k = 36 : accuracy: 26.36656%\n",
      "k = 37 : accuracy: 26.68810%\n",
      "k = 38 : accuracy: 29.26045%\n",
      "k = 39 : accuracy: 28.61736%\n",
      "k = 40 : accuracy: 27.97428%\n",
      "k = 41 : accuracy: 27.65273%\n",
      "k = 42 : accuracy: 27.65273%\n",
      "k = 43 : accuracy: 28.93891%\n",
      "k = 44 : accuracy: 28.93891%\n",
      "k = 45 : accuracy: 29.58199%\n",
      "k = 46 : accuracy: 30.22508%\n",
      "k = 47 : accuracy: 29.26045%\n",
      "k = 48 : accuracy: 30.22508%\n",
      "k = 49 : accuracy: 28.93891%\n"
     ]
    }
   ],
   "source": [
    "def run_knn_classify2(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    hitNum = 0\n",
    "    for index, wordVector in enumerate(TF_validateSet):\n",
    "        ans = knn_classify(TF_trainSet, trainSet_label, k, wordVector)\n",
    "        if  ans == validateSet_label[index]:\n",
    "            hitNum +=1\n",
    "    print(\"k = %2d : accuracy: %.5f%%\" % (k, 100*hitNum/len(validateSet)))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_classify2(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集进行分类\n",
    "#### 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:15:43.037470Z",
     "start_time": "2017-10-13T18:15:00.246364Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFileName = \"15352220_linzecheng_KNN_classification_onehot.csv\"\n",
    "bestK = 14\n",
    "textid_and_label = []\n",
    "for index, wordVector in enumerate(oneHot_testSet):\n",
    "        ans = knn_classify(oneHot_trainSet_, trainSet_label, bestK, wordVector)\n",
    "        textid_and_label.append((index+1, ans))\n",
    "        \n",
    "res = pd.DataFrame(textid_and_label, columns=['textid','label'])\n",
    "res.to_csv(outputFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:16:55.535198Z",
     "start_time": "2017-10-13T18:16:55.528188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         218\n",
       "fear         57\n",
       "sad          35\n",
       "surprise      2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:17:49.616292Z",
     "start_time": "2017-10-13T18:17:25.187665Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputFileName = \"15352220_linzecheng_KNN_classification_TF.csv\"\n",
    "bestK = 16\n",
    "textid_and_label = []\n",
    "for index, wordVector in enumerate(TF_testSet):\n",
    "        ans = knn_classify(TF_trainSet_, trainSet_label, bestK, wordVector)\n",
    "        textid_and_label.append((index+1, ans))\n",
    "        \n",
    "res2 = pd.DataFrame(textid_and_label, columns=['textid','label'])\n",
    "res2.to_csv(outputFileName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:17:49.640106Z",
     "start_time": "2017-10-13T18:17:49.620291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surprise    186\n",
       "joy          49\n",
       "sad          32\n",
       "fear         23\n",
       "anger        22\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB分类算法\n",
    "\n",
    "### 得到3个数据集的频次矩阵\n",
    "\n",
    "该矩阵用于NB的分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T10:45:27.471152Z",
     "start_time": "2017-10-18T10:45:27.395149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['a', 'b'], ['b', 'c']], 3, [['e', 'a'], ['c', 'f']])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(['e', 'b', 'f', 'c', 'a'], ['good', 'bad'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "({'bad': [0.2, 0.4, 0.2, 0.4, 0.2], 'good': [0.2, 0.4, 0.2, 0.2, 0.4]},\n",
       " ['good', 'bad'],\n",
       " {'bad': 0.5, 'good': 0.5})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getFreq(trainSet, trainSet_label, allWordsNum_train,\n",
    "            allWords_train_other, lambda_):\n",
    "    '''得到输入训练集的频次矩阵、所有可能的标签、对应的标签的概率'''\n",
    "    def calcProbs(numerator, denominator):\n",
    "        '''根据输入的分子和分母计算先验概率值'''\n",
    "        return (numerator+lambda_) / (denominator+lambda_*allWordsNum_train)\n",
    "    #先将数据类型转为numpy.array\n",
    "    trainSet = np.array(trainSet)\n",
    "    trainSet_label = np.array(trainSet_label)\n",
    "    \n",
    "    #得到所有可能的标签\n",
    "    allLabels = list(set(trainSet_label))\n",
    "    freqMat = dict() #要返回的频次矩阵\n",
    "    labelPros = dict() #要返回的标签的概率\n",
    "    #遍历所有标签\n",
    "    for label in allLabels:\n",
    "        #找到所有标签为 label 的 documents\n",
    "        allDocs_with_label = trainSet[np.argwhere(trainSet_label==label)[:,0]]\n",
    "        #计算每个 label 出现的概率\n",
    "        labelPros[label] = len(allDocs_with_label)/len(trainSet)\n",
    "        #得到上面的所有 documents 中的所有词\n",
    "        allWords_with_label = [j for i in list(allDocs_with_label) for j in i]\n",
    "        #词频统计\n",
    "        wordCounter = Counter(allWords_with_label)\n",
    "        #预分配内存\n",
    "        freqMat[label] = [0]*len(allWords_train_other)\n",
    "        #求先验概率时的分母\n",
    "        denominator_ = len(allWords_with_label)\n",
    "        #遍历所有词，计算在标签为label的前提下词出现的概率\n",
    "        for index, word in enumerate(allWords_train_other):\n",
    "            freqMat[label][index] = calcProbs(wordCounter.get(word,0), denominator_)\n",
    "            \n",
    "    return freqMat, allLabels, labelPros\n",
    "\n",
    "####################测试程序#################\n",
    "a = [['a','b'], ['b','c']]              #trainSet\n",
    "b = len(set([j for i in a for j in i])) #allWordsNum_train\n",
    "c = [['e','a'], ['c','f']]              #otherSet\n",
    "                                        #allWords_train_other\n",
    "d = list(set([j for i in a for j in i]).union([j for i in c for j in i]))\n",
    "e = ['good', 'bad']                     #trainSet_label\n",
    "a, b, c\n",
    "d, e\n",
    "getFreq(a, e, b, d, lambda_=1)          #使用拉普拉斯平滑\n",
    "####################测试程序#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里给出了一个例子测试该函数的正确性：\n",
    "\n",
    "给定的训练集`a=[['a', 'b'], ['b', 'c']]`, 对应的lable为`e=['good', 'bad']`, b为a中的所有不重复词的长度3。\n",
    "\n",
    "给定测试集（或验证集）`c=[['e','a'], ['c','f']]`, 可得两个数据集中所有不重复的词的向量为：\n",
    "\n",
    "`d=['e', 'b', 'f', 'c', 'a']`\n",
    "\n",
    "因此，选择拉普拉斯平滑的多项式模型计算，对应的频次矩阵为：\n",
    "\n",
    "```\n",
    "{'bad': [(0+1)/(2+3), (1+1)/(2+3), (0+1)/(2+3), (1+1)/(2+3), (0+1)/(2+3)],\n",
    "\n",
    "'good': [ [(0+1)/(2+3), (1+1)/(2+3), (0+1)/(2+3), (0+1)/(2+3), (1+1)/(2+3)]}\n",
    "```\n",
    "\n",
    "即为：\n",
    "```\n",
    "         'e'  'b'  'f'  'c'  'a'\n",
    "{'bad': [0.2, 0.4, 0.2, 0.4, 0.2],\n",
    "'good': [0.2, 0.4, 0.2, 0.2, 0.4]}\n",
    "```\n",
    "\n",
    "而根据训练集得到的每个label的概率P(label)为:`P(good)=1/2=0.5=P(bad)`\n",
    "\n",
    "可见，输出结果正确，该函数功能正常。\n",
    "\n",
    "对于需要预测分类的数据集：`c=[['e','a'], ['c','f']]`, 有：\n",
    "\n",
    "```\n",
    "P('good'|['e','a']) = P('e'|'good') * P('a'|'good') * P('good')\n",
    "                    = 0.2 * 0.4 * 0.5 = 0.04\n",
    "                    \n",
    "P('bad'|['e','a']) = P('e'|'bad') * P('a'|'bad') * P('bad')\n",
    "                    = 0.2 * 0.2 * 0.5 = 0.02\n",
    "\n",
    "P('good'|['c','f']) = P('c'|'good') * P('f'|'good') * P('good')\n",
    "                    = 0.2 * 0.2 * 0.5 = 0.02\n",
    "                    \n",
    "P('bad'|['c','f'] = P('c'|'bad') * P('f'|'bad') * P('bad')\n",
    "                    = 0.4 * 0.2 * 0.5 = 0.04 \n",
    "```\n",
    "\n",
    "因此，`['e','a']`的分类为`'good'`；而`['c','f']`的分类为`'bad'`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T10:47:21.593990Z",
     "start_time": "2017-10-18T10:47:21.561987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'bad']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def NB_classify(trainSet, trainSet_label, allWordsNum_train, allWords_train_other,\n",
    "                otherSet, lambda_):\n",
    "    #得到频次矩阵、所有可能的标签、标签概率\n",
    "    freqMat_, allLabels_, labelPros_ = getFreq(trainSet, trainSet_label, \n",
    "                    allWordsNum_train,allWords_train_other, lambda_=lambda_)\n",
    "    ans = [] #存储每行数据对应的最终预测分类\n",
    "    allWords_ = np.array(allWords_train_other)\n",
    "    ####print(\"所有词：\", allWords_)\n",
    "    for data in otherSet:\n",
    "        #得到当前的一行数据中词在所有词向量allWords_的下标\n",
    "        matchIndex = np.array([np.argwhere(allWords_ == word)[0][0] \n",
    "                                                    for word in data])\n",
    "        temp = []\n",
    "        ####print(\"当前测试文本：\", data)\n",
    "        ####print(\"在所有词中下标：\", matchIndex)\n",
    "        for label in allLabels_:\n",
    "            #得到对应label的所有词的概率列表\n",
    "            probs = np.array(freqMat_[label])\n",
    "            #得到基于label的概率值\n",
    "            p = reduce(lambda x,y:x*y, probs[matchIndex]) * labelPros_[label]\n",
    "            #保存概率结果和对应的label值\n",
    "            temp.append((p, label))\n",
    "        #得到概率值最大时对应的label值\n",
    "        ####print(\"分为不同类的概率：\\n\", temp)\n",
    "        ans.append(max(temp)[1])\n",
    "    #返回结果\n",
    "    return ans\n",
    "\n",
    "NB_classify(a, e, b, d, c, lambda_=1) #使用拉普拉斯平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T10:46:47.104983Z",
     "start_time": "2017-10-18T10:46:47.088978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有词： ['e' 'b' 'f' 'c' 'a']\n",
      "当前测试文本： ['e', 'a']\n",
      "在所有词中下标： [0 4]\n",
      "分为不同类的概率：\n",
      " [(0.040000000000000008, 'good'), (0.020000000000000004, 'bad')]\n",
      "当前测试文本： ['c', 'f']\n",
      "在所有词中下标： [3 2]\n",
      "分为不同类的概率：\n",
      " [(0.020000000000000004, 'good'), (0.040000000000000008, 'bad')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good', 'bad']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################测试程序#################\n",
    "NB_classify(a, e, b, d, c, lambda_=1) #使用拉普拉斯平滑\n",
    "####################测试程序#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里输出表明`['e','a']`的分类为`'good'`；而`['c','f']`的分类为`'bad'`，与预期想符合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参\n",
    "\n",
    "这里需要调参的地方就是：平滑系数 $\\lambda$ 的选择了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T11:28:32.381250Z",
     "start_time": "2017-10-18T11:27:59.119183Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy is 45.65916% when lambda is 1.20000\n"
     ]
    }
   ],
   "source": [
    "def run_NB_classify(lambda_):\n",
    "    '''使用验证集得到分类准确率，进行调参''' \n",
    "    #调用 NB 分类函数\n",
    "    predictLabel = NB_classify(trainSet, trainSet_label, len(allWords_trainSet),\n",
    "                               allWords_train_validate, validateSet, lambda_)\n",
    "    predictLabel = np.array(predictLabel)\n",
    "    validateSet_label_ = np.array(validateSet_label)\n",
    "    hitRate = len(predictLabel[predictLabel==validateSet_label_])/len(validateSet)\n",
    "    #print(\"lambda = %.5f : accuracy: %.5f%%\" % (lambda_, 100*hitRate))\n",
    "    return hitRate\n",
    "    \n",
    "maxHitRate, bestLambda = 0, 0\n",
    "\n",
    "testRange =  np.arange(0,3.1,0.05)\n",
    "hitRates = np.zeros((1, len(testRange))).flatten()\n",
    "\n",
    "for index, lambda_ in enumerate(testRange):\n",
    "    hitRate = run_NB_classify(lambda_) * 100\n",
    "    hitRates[index] = hitRate\n",
    "    if hitRate > maxHitRate:\n",
    "        maxHitRate = hitRate\n",
    "        bestLambda = lambda_\n",
    "\n",
    "print('max accuracy is %.5f%% when lambda is %.5f' % (maxHitRate, bestLambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，在 $\\lambda$ 为1.2时，分类率最高，为45.65916%。 下面来绘制随着 $\\lambda$ 改变，NB分类准确率的变化图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T18:40:47.707084Z",
     "start_time": "2017-10-18T18:40:47.438985Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGHCAYAAAD7t4thAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20ad2e231d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.plot(testRange, hitRates)\n",
    "_ = plt.xlabel('lambda')\n",
    "_ = plt.ylabel('accuracy(%)')\n",
    "_ = plt.title(\"NB classification accuracy versus lambda\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T11:35:53.091666Z",
     "start_time": "2017-10-18T11:35:52.471946Z"
    }
   },
   "outputs": [],
   "source": [
    "outputFileName = \"15352220_linzecheng_NB_classification.csv\"\n",
    "\n",
    "#调用 NB 分类函数\n",
    "predictLabel = NB_classify(trainSet, trainSet_label, len(allWords_trainSet),\n",
    "                           allWords_train_test, testSet, bestLambda)\n",
    "        \n",
    "textid_and_label = [(i, j) for i in np.arange(1,len(testSet)+1) for j in predictLabel]\n",
    "res = pd.DataFrame(textid_and_label, columns=['textid','label'])\n",
    "res.to_csv(outputFileName, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归\n",
    "\n",
    "## 数据预处理及分析\n",
    "\n",
    "### 数据读取函数实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T16:14:54.949995Z",
     "start_time": "2017-10-18T16:14:54.913971Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet2(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = dict()\n",
    "    label['anger'] = list(df['anger'].values)  \n",
    "    label['disgust'] = list(df['disgust'].values)  \n",
    "    label['fear'] = list(df['fear'].values)\n",
    "    label['joy'] = list(df['joy'].values)  \n",
    "    label['sad'] = list(df['sad'].values)  \n",
    "    label['surprise'] = list(df['surprise'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words (split by space)'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【one line\\'s data preview】:')\n",
    "    display(df.head(1))\n",
    "    #输出所有情感值的一些统计数据\n",
    "    print('【some summary statistics of labels】:')\n",
    "    print(df[['anger','disgust','fear','joy','sad','surprise']].describe())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集、验证集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T16:14:59.326842Z",
     "start_time": "2017-10-18T16:14:58.991104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe retain trophy with big win</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Words (split by space)  anger  disgust  fear     joy  sad  \\\n",
       "0  europe retain trophy with big win    0.0      0.0   0.0  0.8721  0.0   \n",
       "\n",
       "   surprise  \n",
       "0    0.1279  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "            anger     disgust        fear         joy         sad    surprise\n",
      "count  623.000000  623.000000  623.000000  623.000000  623.000000  623.000000\n",
      "mean     0.086573    0.052949    0.157176    0.281344    0.191442    0.230517\n",
      "std      0.123334    0.090709    0.174959    0.317420    0.206464    0.199993\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.090100\n",
      "50%      0.022700    0.000000    0.115400    0.130800    0.142900    0.176500\n",
      "75%      0.144950    0.083300    0.255450    0.566950    0.293450    0.326750\n",
      "max      0.753400    0.571400    0.895800    1.000000    1.000000    1.000000\n",
      "【number of all words】:  2087\n",
      "【number of texts】:  623\n"
     ]
    }
   ],
   "source": [
    "dataPath2 = '.\\\\data\\\\regression_dataset\\\\'\n",
    "trainPath = dataPath2+'train_set.csv'\n",
    "trainSet2, trainSet_label2, allWords_trainSet2 = loadDataSet2(trainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T16:15:19.318831Z",
     "start_time": "2017-10-18T16:15:19.261792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marijuana helps ease hiv nerve pain study says</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>0.5537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words (split by space)  anger  disgust    fear  \\\n",
       "0  marijuana helps ease hiv nerve pain study says    0.0      0.0  0.0744   \n",
       "\n",
       "      joy     sad  surprise  \n",
       "0  0.2727  0.0992    0.5537  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "            anger     disgust        fear         joy         sad    surprise\n",
      "count  311.000000  311.000000  311.000000  311.000000  311.000000  311.000000\n",
      "mean     0.085478    0.062534    0.151173    0.287755    0.194680    0.218382\n",
      "std      0.125672    0.110057    0.175016    0.310162    0.208836    0.189515\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.073650\n",
      "50%      0.012200    0.000000    0.088900    0.177800    0.138900    0.181800\n",
      "75%      0.150600    0.098400    0.245550    0.553650    0.300900    0.320900\n",
      "max      0.777800    0.785700    0.815400    1.000000    0.903200    1.000000\n",
      "【number of all words】:  1235\n",
      "【number of texts】:  311\n"
     ]
    }
   ],
   "source": [
    "validatePath = dataPath2+'validation_set.csv'\n",
    "validateSet2, validateSet_label2, allWords_validateSet2 = loadDataSet2(validatePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T16:15:24.074317Z",
     "start_time": "2017-10-18T16:15:23.951233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【one line's data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textid</th>\n",
       "      <th>Words (split by space)</th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>senator carl krueger thinks ipods can kill you</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   textid                          Words (split by space) anger disgust fear  \\\n",
       "0       1  senator carl krueger thinks ipods can kill you     ?       ?    ?   \n",
       "\n",
       "  joy sad surprise  \n",
       "0   ?   ?        ?  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【some summary statistics of labels】:\n",
      "       anger disgust fear  joy  sad surprise\n",
      "count    312     312  312  312  312      312\n",
      "unique     1       1    1    1    1        1\n",
      "top        ?       ?    ?    ?    ?        ?\n",
      "freq     312     312  312  312  312      312\n",
      "【number of all words】:  1273\n",
      "【number of texts】:  312\n"
     ]
    }
   ],
   "source": [
    "testSet2, _ , allWords_testSet2 = loadDataSet2(dataPath2+'test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T16:15:27.505539Z",
     "start_time": "2017-10-18T16:15:27.496536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722, 2771)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords_train_validate2 = list(set(allWords_trainSet2).union(allWords_validateSet2))\n",
    "allWords_train_test2 = list(set(allWords_trainSet2).union(allWords_testSet2))\n",
    "len(allWords_train_validate2), len(allWords_train_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn回归算法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  得到3个数据集的onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:28:28.293897Z",
     "start_time": "2017-10-13T18:28:26.570353Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#得到训练集、验证集、测试集的onehot矩阵\n",
    "oneHot_trainSet2 = getOneHot(trainSet2, allWords_train_validate2)\n",
    "oneHot_validateSet2 = getOneHot(validateSet2, allWords_train_validate2)\n",
    "\n",
    "oneHot_trainSet2_ = getOneHot(trainSet2, allWords_train_test2)\n",
    "oneHot_testSet2 = getOneHot(testSet2, allWords_train_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到3个数据集的TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T18:29:18.409108Z",
     "start_time": "2017-10-13T18:29:15.981280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    TF=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(doc)\n",
    "        for word in allWords:\n",
    "            TF[index].append(wordCounter.get(word,0)/len(doc))\n",
    "    return TF\n",
    "\n",
    "#得到训练集、验证集、测试集的TF矩阵\n",
    "TF_trainSet2 = getTF(trainSet2, allWords_train_validate2)\n",
    "TF_validateSet2 = getTF(validateSet2, allWords_train_validate2)\n",
    "\n",
    "TF_trainSet2_ = getTF(trainSet2, allWords_train_test2)\n",
    "TF_testSet2 = getTF(testSet2, allWords_train_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 权值归一化函数实现\n",
    "\n",
    "不同意PPT里的权值归一化的说法，下面这个函数暂时不会使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T21:38:44.674179Z",
     "start_time": "2017-10-12T21:38:44.608632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0. ,  0.5,  1. ])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1.22474487,  0.        ,  1.22474487])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weightNormalize(weight, method='min-max'):\n",
    "    '''权值归一化函数，输入权值类型为numpy.array'''\n",
    "    if len(weight) == 1:\n",
    "        return weight\n",
    "    elif method == 'min-max':\n",
    "        return (weight-weight.min())/(weight.max()-weight.min())\n",
    "    elif method == 'z-score':\n",
    "        return (weight-weight.mean())/weight.std()\n",
    "\n",
    "weightNormalize(np.array([1,2,3]))\n",
    "weightNormalize(np.array([1,2,3]),'z-score')\n",
    "\n",
    "weightNormalize(np.array([5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T17:02:43.842385Z",
     "start_time": "2017-10-18T17:02:43.664259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'calm': 0.20758311990313899,\n",
       " 'happy': 0.50670259438257537,\n",
       " 'sad': 0.28571428571428575}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_regress(dataSet, labels, k, inputVector):\n",
    "    '''使用knn对输入的向量进行回归，先默认使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    \n",
    "    #要输出的label\n",
    "    outputLabel = dict() \n",
    "    #label中每个分量的概率值\n",
    "    probs = np.zeros((1,len(labels.keys())))\n",
    "    #若距离中存在0，则直接拷贝距离为0对应元素的label\n",
    "    if 0 in distances:\n",
    "        zeroIndex = distances.tolist().index(0)\n",
    "        for index, i in enumerate(labels.keys()):\n",
    "            outputLabel[i] = labels[i][zeroIndex]\n",
    "            probs[0,index] = outputLabel[i]\n",
    "    else:\n",
    "        #得到 K个近邻的下标\n",
    "        kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "        #用label值除以距离并求和，更新输出的 label\n",
    "        weight = 1/distances[kNeighborsIndex]\n",
    "        \n",
    "        for index, i in enumerate(labels.keys()):\n",
    "            #得到 K个近邻的标签\n",
    "            topKLabel = np.array(labels[i])[kNeighborsIndex]\n",
    "            outputLabel[i] = (topKLabel*weight).sum()\n",
    "            #保存当前概率值，用于后续归一化\n",
    "            probs[0,index] = outputLabel[i]\n",
    "    \n",
    "    #将所有概率值的和调整为1\n",
    "    for i in outputLabel.keys():\n",
    "        outputLabel[i] = outputLabel[i] / probs.sum()\n",
    "    return outputLabel\n",
    "\n",
    "knn_regress([[1,1,0,0],[0,1,1,1],[1,0,0,1]],\n",
    "            {'happy':[0.4,0.5,0.1], \n",
    "             'sad':[0.2,0.3,0.2], \n",
    "             'calm':[0.1,0.25,0.8]}, 2, [0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参\n",
    "#### 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T19:06:32.699829Z",
     "start_time": "2017-10-13T18:31:08.420320Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1：\n",
      "disgust:0.06974 fear:0.20246 anger:0.17641 surprise:0.26274 sad:0.23562 joy:0.22842 \n",
      "average:0.19590\n",
      "k = 2：\n",
      "disgust:0.14951 fear:0.18935 anger:0.21867 surprise:0.26140 sad:0.25384 joy:0.21249 \n",
      "average:0.21421\n",
      "k = 3：\n",
      "disgust:0.17165 fear:0.30999 anger:0.26360 surprise:0.30961 sad:0.27188 joy:0.36031 \n",
      "average:0.28117\n",
      "k = 4：\n",
      "disgust:0.12803 fear:0.25003 anger:0.23949 surprise:0.29278 sad:0.30006 joy:0.26669 \n",
      "average:0.24618\n",
      "k = 5：\n",
      "disgust:0.18701 fear:0.27019 anger:0.21457 surprise:0.26512 sad:0.28487 joy:0.27987 \n",
      "average:0.25027\n",
      "k = 6：\n",
      "disgust:0.15457 fear:0.25380 anger:0.20465 surprise:0.26812 sad:0.29012 joy:0.25840 \n",
      "average:0.23828\n",
      "k = 7：\n",
      "disgust:0.12378 fear:0.23897 anger:0.20549 surprise:0.25716 sad:0.28532 joy:0.24048 \n",
      "average:0.22520\n",
      "k = 8：\n",
      "disgust:0.13491 fear:0.27800 anger:0.18004 surprise:0.25414 sad:0.30558 joy:0.27249 \n",
      "average:0.23753\n",
      "k = 9：\n",
      "disgust:0.10519 fear:0.28046 anger:0.18512 surprise:0.26503 sad:0.32458 joy:0.27891 \n",
      "average:0.23988\n",
      "k =10：\n",
      "disgust:0.14604 fear:0.26491 anger:0.18036 surprise:0.26319 sad:0.33416 joy:0.27371 \n",
      "average:0.24373\n",
      "k =11：\n",
      "disgust:0.12069 fear:0.25838 anger:0.17312 surprise:0.24188 sad:0.33632 joy:0.26551 \n",
      "average:0.23265\n",
      "k =12：\n",
      "disgust:0.13303 fear:0.26830 anger:0.18226 surprise:0.24049 sad:0.33809 joy:0.27549 \n",
      "average:0.23961\n",
      "k =13：\n",
      "disgust:0.14771 fear:0.28021 anger:0.20547 surprise:0.25149 sad:0.34059 joy:0.30852 \n",
      "average:0.25567\n",
      "k =14：\n",
      "disgust:0.17787 fear:0.29880 anger:0.21852 surprise:0.24553 sad:0.32591 joy:0.30625 \n",
      "average:0.26215\n",
      "k =15：\n",
      "disgust:0.18321 fear:0.28714 anger:0.20825 surprise:0.25253 sad:0.31663 joy:0.31423 \n",
      "average:0.26033\n",
      "k =16：\n",
      "disgust:0.18352 fear:0.27125 anger:0.21662 surprise:0.24447 sad:0.31119 joy:0.30215 \n",
      "average:0.25487\n",
      "k =17：\n",
      "disgust:0.17434 fear:0.26840 anger:0.20811 surprise:0.25672 sad:0.30391 joy:0.30852 \n",
      "average:0.25333\n",
      "k =18：\n",
      "disgust:0.17026 fear:0.26193 anger:0.21566 surprise:0.23840 sad:0.29903 joy:0.31063 \n",
      "average:0.24932\n",
      "k =19：\n",
      "disgust:0.14440 fear:0.24877 anger:0.22231 surprise:0.23795 sad:0.29679 joy:0.30395 \n",
      "average:0.24236\n",
      "k =20：\n",
      "disgust:0.12379 fear:0.25170 anger:0.22080 surprise:0.23335 sad:0.30211 joy:0.30940 \n",
      "average:0.24019\n",
      "k =21：\n",
      "disgust:0.13172 fear:0.26511 anger:0.22674 surprise:0.24319 sad:0.31045 joy:0.31716 \n",
      "average:0.24906\n",
      "k =22：\n",
      "disgust:0.11053 fear:0.26269 anger:0.23088 surprise:0.24042 sad:0.31800 joy:0.31700 \n",
      "average:0.24659\n",
      "k =23：\n",
      "disgust:0.11181 fear:0.25776 anger:0.23960 surprise:0.24342 sad:0.30892 joy:0.31787 \n",
      "average:0.24656\n",
      "k =24：\n",
      "disgust:0.13780 fear:0.27675 anger:0.23277 surprise:0.25330 sad:0.30897 joy:0.32873 \n",
      "average:0.25639\n",
      "k =25：\n",
      "disgust:0.13924 fear:0.27147 anger:0.23281 surprise:0.25188 sad:0.31253 joy:0.33053 \n",
      "average:0.25641\n",
      "k =26：\n",
      "disgust:0.13132 fear:0.27424 anger:0.23270 surprise:0.26380 sad:0.31902 joy:0.33972 \n",
      "average:0.26013\n",
      "k =27：\n",
      "disgust:0.13480 fear:0.26516 anger:0.22610 surprise:0.25945 sad:0.29808 joy:0.32687 \n",
      "average:0.25174\n",
      "k =28：\n",
      "disgust:0.15239 fear:0.26506 anger:0.23298 surprise:0.25688 sad:0.28799 joy:0.32463 \n",
      "average:0.25332\n",
      "k =29：\n",
      "disgust:0.14241 fear:0.26210 anger:0.23696 surprise:0.25915 sad:0.27620 joy:0.31128 \n",
      "average:0.24802\n",
      "k =30：\n",
      "disgust:0.14487 fear:0.25611 anger:0.23294 surprise:0.25589 sad:0.27433 joy:0.30574 \n",
      "average:0.24498\n",
      "k =31：\n",
      "disgust:0.13798 fear:0.25449 anger:0.22702 surprise:0.24404 sad:0.27141 joy:0.31168 \n",
      "average:0.24110\n",
      "k =32：\n",
      "disgust:0.15149 fear:0.24303 anger:0.23097 surprise:0.24139 sad:0.28192 joy:0.30589 \n",
      "average:0.24245\n",
      "k =33：\n",
      "disgust:0.14559 fear:0.23594 anger:0.23410 surprise:0.23694 sad:0.28398 joy:0.30202 \n",
      "average:0.23976\n",
      "k =34：\n",
      "disgust:0.15633 fear:0.25141 anger:0.23918 surprise:0.24600 sad:0.27389 joy:0.30310 \n",
      "average:0.24498\n",
      "k =35：\n",
      "disgust:0.16521 fear:0.26447 anger:0.24355 surprise:0.24567 sad:0.27818 joy:0.30084 \n",
      "average:0.24965\n",
      "k =36：\n",
      "disgust:0.16416 fear:0.26248 anger:0.24097 surprise:0.23507 sad:0.27152 joy:0.30028 \n",
      "average:0.24574\n",
      "k =37：\n",
      "disgust:0.15127 fear:0.26217 anger:0.23531 surprise:0.23579 sad:0.27359 joy:0.30238 \n",
      "average:0.24342\n",
      "k =38：\n",
      "disgust:0.15499 fear:0.25994 anger:0.23565 surprise:0.23620 sad:0.26823 joy:0.29764 \n",
      "average:0.24211\n",
      "k =39：\n",
      "disgust:0.14609 fear:0.24547 anger:0.24308 surprise:0.23382 sad:0.27316 joy:0.29228 \n",
      "average:0.23898\n",
      "k =40：\n",
      "disgust:0.14838 fear:0.23823 anger:0.24573 surprise:0.23284 sad:0.26781 joy:0.28697 \n",
      "average:0.23666\n",
      "k =41：\n",
      "disgust:0.14685 fear:0.24121 anger:0.25098 surprise:0.23420 sad:0.25767 joy:0.28516 \n",
      "average:0.23601\n",
      "k =42：\n",
      "disgust:0.15952 fear:0.24534 anger:0.24943 surprise:0.22791 sad:0.25550 joy:0.28665 \n",
      "average:0.23739\n",
      "k =43：\n",
      "disgust:0.15962 fear:0.24832 anger:0.25031 surprise:0.22975 sad:0.25109 joy:0.28496 \n",
      "average:0.23734\n",
      "k =44：\n",
      "disgust:0.17003 fear:0.25118 anger:0.25259 surprise:0.23880 sad:0.25591 joy:0.29057 \n",
      "average:0.24318\n",
      "k =45：\n",
      "disgust:0.17973 fear:0.24789 anger:0.25296 surprise:0.23730 sad:0.25757 joy:0.29613 \n",
      "average:0.24526\n",
      "k =46：\n",
      "disgust:0.17483 fear:0.25017 anger:0.25492 surprise:0.23657 sad:0.25955 joy:0.29655 \n",
      "average:0.24543\n",
      "k =47：\n",
      "disgust:0.17927 fear:0.24926 anger:0.25616 surprise:0.23688 sad:0.25590 joy:0.29043 \n",
      "average:0.24465\n",
      "k =48：\n",
      "disgust:0.18261 fear:0.24154 anger:0.25702 surprise:0.23231 sad:0.25492 joy:0.28719 \n",
      "average:0.24260\n",
      "k =49：\n",
      "disgust:0.17860 fear:0.24498 anger:0.25382 surprise:0.23462 sad:0.25527 joy:0.29083 \n",
      "average:0.24302\n"
     ]
    }
   ],
   "source": [
    "def run_knn_regress1(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    ansLabel = dict()\n",
    "    for i in validateSet_label2.keys():\n",
    "        ansLabel[i]=[]\n",
    "    for index, wordVector in enumerate(oneHot_validateSet2):\n",
    "        ans = knn_regress(oneHot_trainSet2, trainSet_label2, k, wordVector)\n",
    "        ######### nan 值的debug代码#########################\n",
    "#         flag = False\n",
    "#         for i in validateSet_label2.keys():\n",
    "#             if  np.isnan(ans[i]):\n",
    "#                 print('nan value found in %d' % (index))\n",
    "#                 print('terminate..')\n",
    "#                 flag = True\n",
    "#         if flag: break\n",
    "        ########## nan 值的debug代码#########################\n",
    "        for i in ans.keys():\n",
    "            ansLabel[i].append(ans[i])\n",
    "    \n",
    "    print('k =%2d：' % k)\n",
    "    tot = 0\n",
    "    for i in ansLabel.keys():\n",
    "        corr = np.corrcoef(ansLabel[i],validateSet_label2[i])[0,1]\n",
    "        tot += corr\n",
    "        print('%s:%.5f' % (i, corr), end=' ')\n",
    "    print('\\naverage:%.5f' % (tot/len(ansLabel.keys())))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_regress1(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T19:28:12.789947Z",
     "start_time": "2017-10-13T19:07:28.832198Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1：\n",
      "disgust:0.18534 fear:0.18922 anger:0.19106 surprise:0.25044 sad:0.33920 joy:0.29835 \n",
      "average:0.24227\n",
      "k = 2：\n",
      "disgust:0.15857 fear:0.24805 anger:0.20038 surprise:0.28051 sad:0.35063 joy:0.32682 \n",
      "average:0.26083\n",
      "k = 3：\n",
      "disgust:0.15783 fear:0.23621 anger:0.26758 surprise:0.33853 sad:0.36212 joy:0.32767 \n",
      "average:0.28165\n",
      "k = 4：\n",
      "disgust:0.16518 fear:0.28809 anger:0.27425 surprise:0.32473 sad:0.35045 joy:0.32369 \n",
      "average:0.28773\n",
      "k = 5：\n",
      "disgust:0.17754 fear:0.26132 anger:0.28459 surprise:0.34263 sad:0.33851 joy:0.32733 \n",
      "average:0.28865\n",
      "k = 6：\n",
      "disgust:0.19088 fear:0.27623 anger:0.24732 surprise:0.33194 sad:0.34177 joy:0.33144 \n",
      "average:0.28660\n",
      "k = 7：\n",
      "disgust:0.20926 fear:0.28102 anger:0.24311 surprise:0.33335 sad:0.34708 joy:0.31564 \n",
      "average:0.28824\n",
      "k = 8：\n",
      "disgust:0.19627 fear:0.27130 anger:0.23438 surprise:0.32511 sad:0.35790 joy:0.32447 \n",
      "average:0.28490\n",
      "k = 9：\n",
      "disgust:0.21269 fear:0.27335 anger:0.24752 surprise:0.32384 sad:0.35081 joy:0.32749 \n",
      "average:0.28928\n",
      "k =10：\n",
      "disgust:0.19288 fear:0.27461 anger:0.24724 surprise:0.31550 sad:0.33523 joy:0.31900 \n",
      "average:0.28074\n",
      "k =11：\n",
      "disgust:0.18964 fear:0.29131 anger:0.23958 surprise:0.30956 sad:0.32721 joy:0.31837 \n",
      "average:0.27928\n",
      "k =12：\n",
      "disgust:0.16947 fear:0.28306 anger:0.24940 surprise:0.30983 sad:0.31694 joy:0.31065 \n",
      "average:0.27323\n",
      "k =13：\n",
      "disgust:0.18577 fear:0.28743 anger:0.26604 surprise:0.29785 sad:0.32257 joy:0.32204 \n",
      "average:0.28028\n",
      "k =14：\n",
      "disgust:0.17002 fear:0.29364 anger:0.26618 surprise:0.30549 sad:0.32675 joy:0.32791 \n",
      "average:0.28167\n",
      "k =15：\n",
      "disgust:0.16540 fear:0.29973 anger:0.26534 surprise:0.31255 sad:0.32741 joy:0.31663 \n",
      "average:0.28118\n",
      "k =16：\n",
      "disgust:0.17166 fear:0.28516 anger:0.27079 surprise:0.31289 sad:0.33741 joy:0.31690 \n",
      "average:0.28247\n",
      "k =17：\n",
      "disgust:0.17032 fear:0.27181 anger:0.27278 surprise:0.31076 sad:0.33908 joy:0.29951 \n",
      "average:0.27738\n",
      "k =18：\n",
      "disgust:0.18575 fear:0.26559 anger:0.27210 surprise:0.30462 sad:0.34055 joy:0.30999 \n",
      "average:0.27977\n",
      "k =19：\n",
      "disgust:0.18367 fear:0.26340 anger:0.27021 surprise:0.30281 sad:0.33211 joy:0.31722 \n",
      "average:0.27824\n",
      "k =20：\n",
      "disgust:0.20621 fear:0.27713 anger:0.27287 surprise:0.30982 sad:0.33821 joy:0.31765 \n",
      "average:0.28698\n",
      "k =21：\n",
      "disgust:0.19134 fear:0.27912 anger:0.27795 surprise:0.29953 sad:0.34413 joy:0.32254 \n",
      "average:0.28577\n",
      "k =22：\n",
      "disgust:0.21967 fear:0.27313 anger:0.28345 surprise:0.28847 sad:0.33642 joy:0.32631 \n",
      "average:0.28791\n",
      "k =23：\n",
      "disgust:0.22100 fear:0.26195 anger:0.29026 surprise:0.29078 sad:0.32646 joy:0.32644 \n",
      "average:0.28615\n",
      "k =24：\n",
      "disgust:0.22382 fear:0.26590 anger:0.29625 surprise:0.28852 sad:0.31377 joy:0.32572 \n",
      "average:0.28566\n",
      "k =25：\n",
      "disgust:0.21399 fear:0.26786 anger:0.28809 surprise:0.28388 sad:0.32208 joy:0.31883 \n",
      "average:0.28246\n",
      "k =26：\n",
      "disgust:0.21410 fear:0.26656 anger:0.28437 surprise:0.29108 sad:0.31328 joy:0.31250 \n",
      "average:0.28031\n",
      "k =27：\n",
      "disgust:0.21882 fear:0.26169 anger:0.28700 surprise:0.28846 sad:0.30809 joy:0.31379 \n",
      "average:0.27964\n",
      "k =28：\n",
      "disgust:0.21160 fear:0.26333 anger:0.28639 surprise:0.28145 sad:0.30255 joy:0.31633 \n",
      "average:0.27694\n",
      "k =29：\n",
      "disgust:0.21019 fear:0.25321 anger:0.28122 surprise:0.27712 sad:0.28511 joy:0.30134 \n",
      "average:0.26803\n",
      "k =30：\n",
      "disgust:0.21913 fear:0.26201 anger:0.27731 surprise:0.27046 sad:0.27149 joy:0.29420 \n",
      "average:0.26577\n",
      "k =31：\n",
      "disgust:0.22719 fear:0.24256 anger:0.28155 surprise:0.26815 sad:0.27209 joy:0.28262 \n",
      "average:0.26236\n",
      "k =32：\n",
      "disgust:0.21553 fear:0.23836 anger:0.28311 surprise:0.26966 sad:0.27145 joy:0.27819 \n",
      "average:0.25938\n",
      "k =33：\n",
      "disgust:0.21268 fear:0.24321 anger:0.27654 surprise:0.26488 sad:0.26678 joy:0.27931 \n",
      "average:0.25723\n",
      "k =34：\n",
      "disgust:0.21120 fear:0.24191 anger:0.27545 surprise:0.26684 sad:0.26155 joy:0.27552 \n",
      "average:0.25541\n",
      "k =35：\n",
      "disgust:0.20637 fear:0.24336 anger:0.27306 surprise:0.26691 sad:0.26872 joy:0.27324 \n",
      "average:0.25528\n",
      "k =36：\n",
      "disgust:0.19254 fear:0.23706 anger:0.27030 surprise:0.26356 sad:0.26836 joy:0.27034 \n",
      "average:0.25036\n",
      "k =37：\n",
      "disgust:0.19890 fear:0.22780 anger:0.26768 surprise:0.26318 sad:0.25999 joy:0.26775 \n",
      "average:0.24755\n",
      "k =38：\n",
      "disgust:0.19446 fear:0.22835 anger:0.26538 surprise:0.26584 sad:0.26196 joy:0.27377 \n",
      "average:0.24830\n",
      "k =39：\n",
      "disgust:0.18809 fear:0.22919 anger:0.26343 surprise:0.25839 sad:0.25387 joy:0.26923 \n",
      "average:0.24370\n",
      "k =40：\n",
      "disgust:0.17962 fear:0.22148 anger:0.26457 surprise:0.25227 sad:0.24856 joy:0.26547 \n",
      "average:0.23866\n",
      "k =41：\n",
      "disgust:0.17006 fear:0.21835 anger:0.26415 surprise:0.25287 sad:0.25578 joy:0.26388 \n",
      "average:0.23751\n",
      "k =42：\n",
      "disgust:0.15801 fear:0.21880 anger:0.26097 surprise:0.24771 sad:0.25195 joy:0.26232 \n",
      "average:0.23329\n",
      "k =43：\n",
      "disgust:0.14234 fear:0.21473 anger:0.26562 surprise:0.24707 sad:0.25037 joy:0.26535 \n",
      "average:0.23091\n",
      "k =44：\n",
      "disgust:0.15409 fear:0.21492 anger:0.26659 surprise:0.24348 sad:0.25321 joy:0.26308 \n",
      "average:0.23256\n",
      "k =45：\n",
      "disgust:0.15830 fear:0.21713 anger:0.26703 surprise:0.24651 sad:0.25338 joy:0.26342 \n",
      "average:0.23430\n",
      "k =46：\n",
      "disgust:0.17373 fear:0.21054 anger:0.27107 surprise:0.25346 sad:0.25595 joy:0.26105 \n",
      "average:0.23763\n",
      "k =47：\n",
      "disgust:0.17440 fear:0.20601 anger:0.26483 surprise:0.24243 sad:0.25372 joy:0.26030 \n",
      "average:0.23362\n",
      "k =48：\n",
      "disgust:0.17422 fear:0.20178 anger:0.26568 surprise:0.24070 sad:0.24882 joy:0.26760 \n",
      "average:0.23313\n",
      "k =49：\n",
      "disgust:0.17920 fear:0.20812 anger:0.26922 surprise:0.24406 sad:0.25016 joy:0.27180 \n",
      "average:0.23709\n"
     ]
    }
   ],
   "source": [
    "def run_knn_regress2(k):\n",
    "    '''使用验证集得到分类准确率，进行调参'''\n",
    "    ansLabel = dict()\n",
    "    for i in validateSet_label2.keys():\n",
    "        ansLabel[i]=[]\n",
    "    for index, wordVector in enumerate(TF_validateSet2):\n",
    "        ans = knn_regress(TF_trainSet2, trainSet_label2, k, wordVector)\n",
    "        ######### nan 值的debug代码#########################\n",
    "#         flag = False\n",
    "#         for i in validateSet_label2.keys():\n",
    "#             if  np.isnan(ans[i]):\n",
    "#                 print('nan value found in %d' % (index))\n",
    "#                 print('terminate..')\n",
    "#                 flag = True\n",
    "#         if flag: break\n",
    "        ########## nan 值的debug代码#########################\n",
    "        for i in ans.keys():\n",
    "            ansLabel[i].append(ans[i])\n",
    "    \n",
    "    print('k =%2d：' % k)\n",
    "    tot = 0\n",
    "    for i in ansLabel.keys():\n",
    "        corr = np.corrcoef(ansLabel[i],validateSet_label2[i])[0,1]\n",
    "        tot += corr\n",
    "        print('%s:%.5f' % (i, corr), end=' ')\n",
    "    print('\\naverage:%.5f' % (tot/len(ansLabel.keys())))\n",
    "    \n",
    "for k in range(1,50):\n",
    "    run_knn_regress2(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB回归算法\n",
    "\n",
    "### 得到三个数据集的类TF矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T16:55:40.386338Z",
     "start_time": "2017-10-18T16:55:40.328296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['a', 'b'], ['b', 'c']], 3, [['e', 'a'], ['c', 'f']])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(['e', 'b', 'f', 'c', 'a'], {'bad': [0.2, 0.8], 'good': [0.8, 0.2]})"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  0. ,  0. ,  0.5],\n",
       "       [ 0. ,  0.5,  0. ,  0.5,  0. ]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.2,  0.4,  0.2,  0.2,  0.4],\n",
       "       [ 0.2,  0.4,  0.2,  0.4,  0.2]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def getSimilarTF(trainSet_, allWordsNum_train, allWords_train_other, lambda_):\n",
    "    '''得到输入训练集的类TF矩阵、所有可能的标签'''\n",
    "    def calcProbs(numerator, denominator):\n",
    "        '''根据输入的分子和分母计算先验概率值'''\n",
    "        return (numerator+lambda_) / (denominator+lambda_*allWordsNum_train)\n",
    "    #预分配内存\n",
    "    similarTF = np.zeros((len(trainSet_), len(allWords_train_other)))\n",
    "    #遍历整个数据集\n",
    "    for rowIdx, doc in enumerate(trainSet_):\n",
    "        #得到所有词的词频统计\n",
    "        wordCounter = Counter(doc)\n",
    "        #遍历每个词\n",
    "        for colIdx, word in enumerate(allWords_train_other):\n",
    "            #得到矩阵每个元素的概率值\n",
    "            similarTF[rowIdx, colIdx] = calcProbs(wordCounter.get(word,0), len(doc))\n",
    "    \n",
    "    return similarTF\n",
    "\n",
    "####################测试程序#################\n",
    "a = [['a','b'], ['b','c']]              #trainSet_\n",
    "b = len(set([j for i in a for j in i])) #allWordsNum_train\n",
    "c = [['e','a'], ['c','f']]              #otherSet\n",
    "                                        #allWords_train_other\n",
    "d = list(set([j for i in a for j in i]).union([j for i in c for j in i]))\n",
    "e = {'good':[0.8, 0.2],'bad':[0.2, 0.8]}#trainSet_label\n",
    "a, b, c\n",
    "d, e\n",
    "getSimilarTF(a, b, d, lambda_=0)        #lambda 为 0时\n",
    "getSimilarTF(a, b, d, lambda_=1)        #lambda 为 1时\n",
    "####################测试程序#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "下面来根据上面例子的输出来说明该函数的实现正确性。\n",
    "\n",
    "当 $\\lambda=0$ 时， 所求的即是TF矩阵，因此输出结果应为：\n",
    "\n",
    "```\n",
    "           'e'  'b'  'f'  'c'  'a'             'e'  'b'  'f'  'c'  'a'\n",
    "第一行数据  0/2  1/2  0/2  0/2  1/2  ---化简-->  0   0.5   0    0    1\n",
    "第二行数据  0/2  1/2  0/2  1/2  0/2              0   0.5   0   0.5   0\n",
    "```\n",
    "和结果相符。\n",
    "\n",
    "当 $\\lambda=1$ 时， 所求的即是使用拉普拉斯平滑的类TF矩阵，因此输出结果应为：\n",
    "\n",
    "```\n",
    "               'e'           'b'          'f'          'c'        'a'         \n",
    "第一行数据  (0+1)/(2+3)  (1+1)/(2+3)  (0+1)/(2+3)  (0+1)/(2+3)  (1+1)/(2+3)\n",
    "第二行数据  (0+1)/(2+3)  (1+1)/(2+3)  (0+1)/(2+3)  (1+1)/(2+3)  (0+1)/(2+3)    \n",
    "\n",
    "---化简-->\n",
    "\n",
    "               'e'           'b'          'f'          'c'        'a'         \n",
    "第一行数据      0.2           0.4          0.2          0.2        0.4\n",
    "第二行数据      0.2           0.4          0.2          0.4        0.2 \n",
    "```\n",
    "\n",
    "和结果相符。因此该函数的实现是正确的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归函数实现及简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T19:41:26.382991Z",
     "start_time": "2017-10-18T19:41:26.291446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['a', 'b'], ['b', 'c']], 3, [['e', 'a'], ['c', 'f']])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(['e', 'b', 'f', 'c', 'a'], {'bad': [0.2, 0.8], 'good': [0.8, 0.2]})"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bad': array([ 0.,  0.]), 'good': array([ 0.,  0.])}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'bad': array([ 0.4,  0.6]), 'good': array([ 0.6,  0.4])}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def NB_regress(trainSet_, trainSet_label_, allWordsNum_train, allWords_train_other,\n",
    "               otherSet, lambda_):\n",
    "    '''使用NB进行回归，返回每个数据对应的类标签概率'''\n",
    "    #得到类TF矩阵\n",
    "    similarTF = getSimilarTF(trainSet_, allWordsNum_train, allWords_train_other,\n",
    "                            lambda_)\n",
    "    #要输出的label\n",
    "    outputLabel = dict() \n",
    "    #得到所有可能的标签\n",
    "    allLabels = list(trainSet_label_.keys())\n",
    "    #预分配内存\n",
    "    for label in allLabels:\n",
    "        outputLabel[label] = np.zeros(len(otherSet))\n",
    "    \n",
    "    similarTF = np.array(similarTF)\n",
    "    allWords_ = np.array(allWords_train_other)\n",
    "    for index, data in enumerate(otherSet):\n",
    "        #得到当前的一行数据中词在所有词向量allWords_的下标\n",
    "        matchIndex = np.array([np.argwhere(allWords_ == word)[0][0] \n",
    "                                                    for word in data])\n",
    "        #得到 P(data|d_i, class)的列向量\n",
    "        probs = similarTF[:, matchIndex].prod(axis=1)\n",
    "        #得到基于每个类的概率值\n",
    "        temp = np.zeros(len(allLabels))\n",
    "        for i, label in enumerate(allLabels):\n",
    "            #对应元素相乘再相加\n",
    "            temp[i] = (probs * np.array(trainSet_label_[label])).sum()\n",
    "        \n",
    "        #进行归一化\n",
    "        for i, label in enumerate(allLabels):\n",
    "            if temp.sum() != 0:\n",
    "                outputLabel[label][index] = temp[i] / temp.sum()\n",
    "    \n",
    "    return outputLabel\n",
    "\n",
    "####################测试程序#################\n",
    "a = [['a','b'], ['b','c']]              #trainSet_\n",
    "b = len(set([j for i in a for j in i])) #allWordsNum_train\n",
    "c = [['e','a'], ['c','f']]              #otherSet\n",
    "                                        #allWords_train_other\n",
    "d = list(set([j for i in a for j in i]).union([j for i in c for j in i]))\n",
    "e = {'good':[0.8, 0.2],'bad':[0.2, 0.8]}#trainSet_label\n",
    "a, b, c\n",
    "d, e\n",
    "NB_regress(a, e, b, d, c, lambda_ = 0)  #lambda 为 0时\n",
    "NB_regress(a, e, b, d, c, lambda_ = 1)  #lambda 为 1时\n",
    "####################测试程序#################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面来根据上面的输出来说明该函数的实现正确性。\n",
    "\n",
    "首先，根据该数据集得到的类TF矩阵和对应的标签为为：\n",
    "\n",
    "```\n",
    "               'e'    'b'   'f'   'c'   'a'   | 'bad' 'good'     \n",
    "第一行数据 d1   0.2    0.4   0.2   0.2   0.4   |  0.2   0.8\n",
    "第二行数据 d2   0.2    0.4   0.2   0.4   0.2   |  0.8   0.2\n",
    "```\n",
    "\n",
    "则：\n",
    "\n",
    "```\n",
    "P('good'|['e', 'a']) = P('e'|d1,'good')*P('a'|d1,'good')*P(d1,'good') +\n",
    "                       P('e'|d2,'good')*P('a'|d2,'good')*P(d2,'good')\n",
    "                     = 0.2*0.4*0.8 + 0.2*0.2*0.2 = 0.072\n",
    "                     \n",
    "P('bad'|['e', 'a'])  = P('e'|d1,'bad')*P('a'|d1,'bad')*P(d1,'bad') +\n",
    "                       P('e'|d2,'bad')*P('a'|d2,'bad')*P(d2,'bad')\n",
    "                     = 0.2*0.4*0.2 + 0.2*0.2*0.8 = 0.048   \n",
    "                     \n",
    "P('good'|['c', 'f']) = P('c'|d1,'good')*P('f'|d1,'good')*P(d1,'good') +\n",
    "                       P('c'|d2,'good')*P('f'|d2,'good')*P(d2,'good')\n",
    "                     = 0.2*0.2*0.8 + 0.4*0.2*0.2 = 0.048   \n",
    "                     \n",
    "P('bad'|['c', 'f'])  = P('c'|d1,'bad')*P('f'|d1,'bad')*P(d1,'bad') +\n",
    "                       P('c'|d2,'bad')*P('f'|d2,'bad')*P(d2,'bad')\n",
    "                     = 0.2*0.2*0.2 + 0.4*0.2*0.8 = 0.072                       \n",
    "```\n",
    "\n",
    "归一化之后，有：\n",
    "\n",
    "```\n",
    "P('good'|['e', 'a']) = 0.72/(0.72+0.48) = 0.6\n",
    "P('bad'|['e', 'a'])  = 0.48/(0.72+0.48) = 0.4\n",
    "P('good'|['c', 'f']) = 0.48/(0.72+0.48) = 0.4\n",
    "P('bad'|['c', 'f'])  = 0.72/(0.72+0.48) = 0.6\n",
    "```\n",
    "\n",
    "与输出的结果：\n",
    "\n",
    "```\n",
    "{'bad': array([ 0.4,  0.6]), 'good': array([ 0.6,  0.4])}\n",
    "```\n",
    "\n",
    "一致，因此该函数的实现正确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用验证集调参\n",
    "\n",
    "和NB分类一样，这里需要调参的地方也是：平滑系数 $\\lambda$ 的选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T20:04:55.428988Z",
     "start_time": "2017-10-18T19:49:44.464930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max correlation coefficient is 35.92402% when lambda is 0.03000\n"
     ]
    }
   ],
   "source": [
    "def run_NB_regress(lambda_):\n",
    "    '''使用验证集得到回归准确率，进行调参''' \n",
    "    #调用 NB 回归函数\n",
    "    predictLabel = NB_regress(trainSet2, trainSet_label2, len(allWords_trainSet2),\n",
    "                               allWords_train_validate2, validateSet2, lambda_)\n",
    "    #计算每一个label的相关系数\n",
    "    temp = []\n",
    "    for label, val in validateSet_label2.items():\n",
    "        checkPair = (predictLabel[label], validateSet_label2[label])\n",
    "        temp.append(np.corrcoef(checkPair)[0][1])\n",
    "    #得到平均的相关系数\n",
    "    averageCorrcoef = np.average(temp)\n",
    "    #print('lambda: %.5f --> corrcoeff: %.5f%%' % (lambda_, averageCorrcoef*100))\n",
    "    return averageCorrcoef\n",
    "    \n",
    "bestResult = (0, 0)\n",
    "testRange =  np.arange(0,3.1,0.01)\n",
    "corrcoefs = np.zeros(len(testRange))\n",
    "\n",
    "for index, lambda_ in enumerate(testRange):\n",
    "    corrcoef_ = run_NB_regress(lambda_) * 100\n",
    "    corrcoefs[index] = corrcoef_\n",
    "    bestResult = max(bestResult, (corrcoef_, lambda_))\n",
    "\n",
    "print('max correlation coefficient is %.5f%% when lambda is %.5f' % (bestResult))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，在 $\\lambda$ 为0.03时，分类率最高，为35.92402%。 下面来绘制随着 $\\lambda$ 改变，NB回归相关系数的变化图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-18T20:05:21.004569Z",
     "start_time": "2017-10-18T20:05:20.700403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAGHCAYAAAD7t4thAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20ad2a11048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.plot(testRange, corrcoefs)\n",
    "_ = plt.xlabel('lambda')\n",
    "_ = plt.ylabel('correlation coefficient(%)')\n",
    "_ = plt.title(\"NB regression accuracy versus correlation coefficient\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 附录\n",
    "\n",
    "## 参考资料\n",
    "\n",
    "1.[stackoverflow : how-to-get-indices-of-n-maximum-values-in-a-numpy-array][1]\n",
    "\n",
    "2.[stackoverflow : show-dataframe-as-table-in-ipython-notebook][2]\n",
    "\n",
    "3.[Machine Learning-Normalization][3]\n",
    "\n",
    "4.[为什么一些机器学习模型需要对数据进行归一化？][4]\n",
    "\n",
    "5.[stackexchange : Standardizing some features in K-Means][5]\n",
    "\n",
    "[1]:https://stackoverflow.com/questions/6910641/how-to-get-indices-of-n-maximum-values-in-a-numpy-array\n",
    "[2]:https://stackoverflow.com/questions/26873127/show-dataframe-as-table-in-ipython-notebook\n",
    "[3]:http://www.csuldw.com/2015/11/15/2015-11-15%20normalization/?utm_source=tuicool&utm_medium=referral\n",
    "[4]:http://www.cnblogs.com/LBSer/p/4440590.html\n",
    "[5]:https://stats.stackexchange.com/questions/223289/standardizing-some-features-in-k-means/223355#223355\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T11:51:36.355116Z",
     "start_time": "2017-10-12T11:51:36.351113Z"
    }
   },
   "source": [
    "## 相关函数测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **-------------------------------------------平台配置代码--------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-17T22:39:35.790893Z",
     "start_time": "2017-10-17T22:39:35.783887Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# from IPython.display import Image\n",
    "# 其对应的三元顺序表为=Image(\"./images/1.jpg\")\n",
    "# 稀疏矩阵例子为=Image(\"./images/2.jpg\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "636px",
    "left": "0px",
    "right": "916px",
    "top": "66px",
    "width": "356px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
