{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要求：\n",
    "\n",
    "0、只验收NB分类\n",
    "\n",
    "1、只需要实现多项式模型。\n",
    "\n",
    "2、必须实现拉普拉斯平滑且平滑的分母加V表示为训练集词典的词个数。\n",
    "\n",
    "3、输出标准为：两个情感的概率(可以用直接算出来的，不需要加起来为1)以及最终的prediction。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T14:11:43.301172Z",
     "start_time": "2017-10-20T14:11:43.295168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T14:12:18.565498Z",
     "start_time": "2017-10-20T14:12:18.542481Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def loadDataSet(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = list(df['label'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【data preview】:')\n",
    "    display(df)\n",
    "    #输出所有label的分布\n",
    "    print('【count of all kind of labels】:\\n')\n",
    "    print(df['label'].value_counts())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T14:12:20.650553Z",
     "start_time": "2017-10-20T14:12:20.625535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>easy to finish the AI homework for you</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hard to finish the other homework for you</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many homework you should do</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>few AI homework</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>next week have new AI homework</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Words label\n",
       "0     easy to finish the AI homework for you   joy\n",
       "1  hard to finish the other homework for you   sad\n",
       "2                many homework you should do   joy\n",
       "3                            few AI homework   sad\n",
       "4             next week have new AI homework   joy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "joy    3\n",
      "sad    2\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  18\n",
      "【number of texts】:  5\n"
     ]
    }
   ],
   "source": [
    "trainSet, trainSet_label, allWords_trainSet = loadDataSet('train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T14:15:35.362694Z",
     "start_time": "2017-10-20T14:15:35.343681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you like AI homework</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Words label\n",
       "0  you like AI homework     ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "?    1\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  4\n",
      "【number of texts】:  1\n"
     ]
    }
   ],
   "source": [
    "testSet, _ , allWords_testSet = loadDataSet('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T14:15:49.256766Z",
     "start_time": "2017-10-20T14:15:49.251763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have', 'new', 'few', 'other', 'AI', 'like', 'week', 'finish', 'next', 'should', 'easy', 'the', 'you', 'homework', 'do', 'to', 'for', 'hard', 'many']\n"
     ]
    }
   ],
   "source": [
    "allWords_train_test = list(set(allWords_trainSet).union(allWords_testSet))\n",
    "print(allWords_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T14:32:44.753689Z",
     "start_time": "2017-10-20T14:32:44.598757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有词：\n",
      " ['have' 'new' 'few' 'other' 'AI' 'like' 'week' 'finish' 'next' 'should'\n",
      " 'easy' 'the' 'you' 'homework' 'do' 'to' 'for' 'hard' 'many']\n",
      "当前测试文本： ['you', 'like', 'AI', 'homework']\n",
      "在所有词中下标： [12  5  4 13]\n",
      "\n",
      "分为不同类的概率： [(6.7865530107552721e-06, 'sad'), (1.1525157123640927e-05, 'joy')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['joy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def getFreq(trainSet, trainSet_label, allWordsNum_train,\n",
    "            allWords_train_other, lambda_):\n",
    "    '''得到输入训练集的频次矩阵、所有可能的标签、对应的标签的概率'''\n",
    "    def calcProbs(numerator, denominator):\n",
    "        '''根据输入的分子和分母计算先验概率值'''\n",
    "        return (numerator+lambda_) / (denominator+lambda_*allWordsNum_train)\n",
    "    #先将数据类型转为numpy.array\n",
    "    trainSet = np.array(trainSet)\n",
    "    trainSet_label = np.array(trainSet_label)\n",
    "    \n",
    "    #得到所有可能的标签\n",
    "    allLabels = list(set(trainSet_label))\n",
    "    freqMat = dict() #要返回的频次矩阵\n",
    "    labelPros = dict() #要返回的标签的概率\n",
    "    #遍历所有标签\n",
    "    for label in allLabels:\n",
    "        #找到所有标签为 label 的 documents\n",
    "        allDocs_with_label = trainSet[np.argwhere(trainSet_label==label)[:,0]]\n",
    "        #计算每个 label 出现的概率\n",
    "        labelPros[label] = len(allDocs_with_label)/len(trainSet)\n",
    "        #得到上面的所有 documents 中的所有词\n",
    "        allWords_with_label = [j for i in list(allDocs_with_label) for j in i]\n",
    "        #词频统计\n",
    "        wordCounter = Counter(allWords_with_label)\n",
    "        #预分配内存\n",
    "        freqMat[label] = [0]*len(allWords_train_other)\n",
    "        #求先验概率时的分母\n",
    "        denominator_ = len(allWords_with_label)\n",
    "        #遍历所有词，计算在标签为label的前提下词出现的概率\n",
    "        for index, word in enumerate(allWords_train_other):\n",
    "            freqMat[label][index] = calcProbs(wordCounter.get(word,0), denominator_)\n",
    "            \n",
    "    return freqMat, allLabels, labelPros\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def NB_classify(trainSet, trainSet_label, allWordsNum_train, allWords_train_other,\n",
    "                otherSet, lambda_):\n",
    "    #得到频次矩阵、所有可能的标签、标签概率\n",
    "    freqMat_, allLabels_, labelPros_ = getFreq(trainSet, trainSet_label, \n",
    "                    allWordsNum_train,allWords_train_other, lambda_=lambda_)\n",
    "    ans = [] #存储每行数据对应的最终预测分类\n",
    "    allWords_ = np.array(allWords_train_other)\n",
    "    print(\"所有词：\\n\", allWords_)\n",
    "    for data in otherSet:\n",
    "        #得到当前的一行数据中词在所有词向量allWords_的下标\n",
    "        matchIndex = np.array([np.argwhere(allWords_ == word)[0][0] \n",
    "                                                    for word in data])\n",
    "        temp = []\n",
    "        print(\"当前测试文本：\", data)\n",
    "        print(\"在所有词中下标：\", matchIndex)\n",
    "        for label in allLabels_:\n",
    "            #得到对应label的所有词的概率列表\n",
    "            probs = np.array(freqMat_[label])\n",
    "            #print(probs)\n",
    "            #得到基于label的概率值\n",
    "            p = reduce(lambda x,y:x*y, probs[matchIndex]) * labelPros_[label]\n",
    "            #保存概率结果和对应的label值\n",
    "            temp.append((p, label))\n",
    "        #得到概率值最大时对应的label值\n",
    "        print(\"\\n分为不同类的概率：\", temp)\n",
    "        ans.append(max(temp)[1])\n",
    "    #返回结果\n",
    "    return ans\n",
    "\n",
    "#调用 NB 分类函数\n",
    "predictLabel = NB_classify(trainSet, trainSet_label, len(allWords_trainSet),\n",
    "                           allWords_train_test, testSet, lambda_ = 1)\n",
    "predictLabel   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
