{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:51:26.670937Z",
     "start_time": "2017-10-13T13:51:26.664931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:56:11.401308Z",
     "start_time": "2017-10-13T13:56:11.337752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loadDataSet(filePath):\n",
    "    '''读取数据集函数'''\n",
    "    #读取CSV文件\n",
    "    df = pd.read_csv(filePath)\n",
    "    #得到数据集标签\n",
    "    label = list(df['label'].values)  \n",
    "    #得到数据集\n",
    "    dataSet = [i.strip().split(' ') for i in list(df['Words'].values)]\n",
    "    #得到数据集的所有不重复的词\n",
    "    allWords = list(set([j for i in dataSet for j in i]))\n",
    "    \n",
    "    ############输出数据集相关信息###########################\n",
    "    #输出第一行数据\n",
    "    print('【data preview】:')\n",
    "    display(df)\n",
    "    #输出所有label的分布\n",
    "    print('【count of all kind of labels】:\\n')\n",
    "    print(df['label'].value_counts())\n",
    "    #输出所有的词的个数\n",
    "    print('【number of all words】: ', len(allWords))\n",
    "    print('【number of texts】: ', len(df))\n",
    "    ############输出数据集相关信息###########################\n",
    "    \n",
    "    return dataSet, label, allWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:51:26.948790Z",
     "start_time": "2017-10-13T13:51:26.838462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can not find test</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hello this is my girlfriend</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She is luhan's girlfriend</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am not his girfriend</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can not stand his girlfriend</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Words  label\n",
       "0             I can not find test    sad\n",
       "1     hello this is my girlfriend    sad\n",
       "2       She is luhan's girlfriend    sad\n",
       "3          I am not his girfriend    sad\n",
       "4  I can not stand his girlfriend  anger"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "sad      4\n",
      "anger    1\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  16\n",
      "【number of texts】:  5\n"
     ]
    }
   ],
   "source": [
    "trainSet, trainSet_label, allWords_trainSet = loadDataSet('.\\\\data\\\\train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:51:27.041932Z",
     "start_time": "2017-10-13T13:51:26.953792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【data preview】:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can not stand I am not luhan's grilfriend</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Words label\n",
       "0  I can not stand I am not luhan's grilfriend     ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【count of all kind of labels】:\n",
      "\n",
      "?    1\n",
      "Name: label, dtype: int64\n",
      "【number of all words】:  7\n",
      "【number of texts】:  1\n"
     ]
    }
   ],
   "source": [
    "testSet, _ , allWords_testSet = loadDataSet('.\\\\data\\\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:52:11.139966Z",
     "start_time": "2017-10-13T13:52:11.129958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'can',\n",
       " 'girfriend',\n",
       " 'girlfriend',\n",
       " 'my',\n",
       " 'She',\n",
       " \"luhan's\",\n",
       " 'stand',\n",
       " 'grilfriend',\n",
       " 'this',\n",
       " 'test',\n",
       " 'find',\n",
       " 'am',\n",
       " 'hello',\n",
       " 'his',\n",
       " 'not',\n",
       " 'I']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords_train_test = list(set(allWords_trainSet).union(allWords_testSet))\n",
    "allWords_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:52:58.456533Z",
     "start_time": "2017-10-13T13:52:58.441522Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getTF(dataSet, allWords):\n",
    "    '''得到输入数据集的TF矩阵'''\n",
    "    TF=[]\n",
    "    for index, doc in enumerate(dataSet):\n",
    "        TF.append([])\n",
    "        wordCounter = Counter(doc)\n",
    "        for word in allWords:\n",
    "            TF[index].append(wordCounter.get(word,0)/len(doc))\n",
    "    return TF\n",
    "\n",
    "#得到训练集、测试集的TF矩阵\n",
    "TF_trainSet = getTF(trainSet, allWords_train_test)\n",
    "TF_testSet = getTF(testSet, allWords_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T13:55:50.189867Z",
     "start_time": "2017-10-13T13:55:50.184863Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.array(TF_trainSet)\n",
    "# np.array(TF_testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T14:02:18.207354Z",
     "start_time": "2017-10-13T14:02:18.179335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: [1 0 2]\n",
      "dis:  [ 1.          1.41421356  2.        ]\n",
      "label: ['negative' 'positive' 'positive']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_classify(dataSet, labels, k, inputVector, printTopK=True):\n",
    "    '''使用knn对输入的向量进行分类，使用欧式距离'''\n",
    "    #得到输入向量与数据集的差值的平方\n",
    "    diffMat = (np.array(dataSet) - np.array(inputVector))**2\n",
    "    #计算每一行上元素的和并开方，得到距离向量\n",
    "    distances = np.sqrt(diffMat.sum(axis=1))\n",
    "    #得到 K个近邻的下标\n",
    "    kNeighborsIndex  = distances.argpartition(k-1)[0:k]\n",
    "    if printTopK:\n",
    "        print('index:', kNeighborsIndex)\n",
    "        print('dis: ', distances[kNeighborsIndex])\n",
    "        print('label:', np.array(labels)[kNeighborsIndex])\n",
    "    #返回分类结果\n",
    "    return Counter(np.array(labels)[kNeighborsIndex]).most_common(1)[0][0]\n",
    "\n",
    "knn_classify([[1,1,0,0],\n",
    "              [0,1,1,1],\n",
    "              [1,0,0,1]],['positive','negative','positive'], 3, [0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-13T14:02:23.726423Z",
     "start_time": "2017-10-13T14:02:23.714414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: [4 3 0]\n",
      "dis:  [ 0.32394177  0.3718489   0.3718489 ]\n",
      "label: ['anger' 'sad' 'sad']\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "def run_knn_classify(k):\n",
    "    '''输出基于【欧式距离】+【TF矩阵】的3NN分类的3个最近样本，并输出最终预测结果'''\n",
    "    for index, wordVector in enumerate(TF_testSet):\n",
    "        ans = knn_classify(TF_trainSet, trainSet_label, k, wordVector)\n",
    "        print(ans)\n",
    "run_knn_classify(3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
